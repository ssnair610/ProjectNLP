{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca2025a",
   "metadata": {},
   "source": [
    "# Random Forest - Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cf4234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tushar/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import os\n",
    "import optuna\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74225cf",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c7b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_train_track_a_00001</td>\n",
       "      <td>Colorado, middle of nowhere.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_train_track_a_00002</td>\n",
       "      <td>This involved swimming a pretty large lake tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_train_track_a_00003</td>\n",
       "      <td>It was one of my most shameful experiences.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_train_track_a_00004</td>\n",
       "      <td>After all, I had vegetables coming out my ears...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_train_track_a_00005</td>\n",
       "      <td>Then the screaming started.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0  eng_train_track_a_00001                       Colorado, middle of nowhere.   \n",
       "1  eng_train_track_a_00002  This involved swimming a pretty large lake tha...   \n",
       "2  eng_train_track_a_00003        It was one of my most shameful experiences.   \n",
       "3  eng_train_track_a_00004  After all, I had vegetables coming out my ears...   \n",
       "4  eng_train_track_a_00005                        Then the screaming started.   \n",
       "\n",
       "   anger  fear  joy  sadness  surprise  \n",
       "0      0     1    0        0         1  \n",
       "1      0     1    0        0         0  \n",
       "2      0     1    0        1         0  \n",
       "3      0     0    0        0         0  \n",
       "4      0     1    0        1         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(\"Data\", \"track-a.csv\")\n",
    "dataframe = pd.read_csv(file_path)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb59e57",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830e598",
   "metadata": {},
   "source": [
    "### Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d347afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tushar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "dataframe['text'] = dataframe['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd43d6",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "# TODO: Lot of punctuations (remove)\n",
    "\n",
    "def lemmatize_text(txt):\n",
    "    out = \"\"\n",
    "    for word in word_tokenizer.tokenize(txt):\n",
    "        out = out + lemmatizer.lemmatize(word) + \" \"\n",
    "    return out\n",
    "\n",
    "dataframe[\"text\"] = dataframe.text.apply(lemmatize_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6728b7b",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12150869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "X_texts = dataframe['text']\n",
    "vectorizer = CountVectorizer()\n",
    "X_texts_vec = vectorizer.fit_transform(X_texts)\n",
    "\n",
    "\n",
    "emotions = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "Y_emotions = dataframe[emotions]\n",
    "\n",
    "\n",
    "X_train_text, X_test_text, Y_train_labels, Y_test_labels = train_test_split(X_texts_vec, Y_emotions, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8be120",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23362638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad6d1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 25, 500, step = 25)\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 64, step = 2)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "    random_state = trial.suggest_int(\"random_state\", 0, 100, step = 20)\n",
    "    warm_start = trial.suggest_categorical(\"warm_start\", [False, True])\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators = n_estimators, \n",
    "                                   criterion = criterion, \n",
    "                                   max_depth = max_depth, \n",
    "                                   max_features = max_features, \n",
    "                                   random_state = random_state, \n",
    "                                   warm_start = warm_start)\n",
    "\n",
    "    model.fit(X_train_text,Y_train_labels)\n",
    "\n",
    "    yPred = model.predict(X_test_text)\n",
    "    \n",
    "    confusionMatrix = multilabel_confusion_matrix(Y_test_labels, yPred)  \n",
    "    f1s = []\n",
    "\n",
    "    for i in range(len(confusionMatrix)):\n",
    "        tn, fp = confusionMatrix[i][0]\n",
    "        fn, tp = confusionMatrix[i][1]\n",
    "\n",
    "        if (tp + fp) == 0 or (tp + fn) == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            prec = tp / (tp + fp)\n",
    "            rec = tp / (tp + fn)\n",
    "            if (prec + rec) == 0:\n",
    "                f1 = 0\n",
    "            else:\n",
    "                f1 = 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "        f1s.append(f1)\n",
    "        trial.set_user_attr(f\"f1_{emotions[i]}\", f1)\n",
    "\n",
    "    macro_f1 = np.mean(f1s)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b926ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicatedStudyError",
     "evalue": "Another study with name 'RFC' already exists. Please specify a different name, or reuse the existing one by setting `load_if_exists` (for Python API) or `--skip-if-exists` flag (for CLI).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1963\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py:943\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 943\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: UNIQUE constraint failed: studies.study_name",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/optuna/storages/_rdb/storage.py:266\u001b[0m, in \u001b[0;36mRDBStorage.create_new_study\u001b[0;34m(self, directions, study_name)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _create_scoped_session(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoped_session) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m study_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py:142\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/optuna/storages/_rdb/storage.py:77\u001b[0m, in \u001b[0;36m_create_scoped_session\u001b[0;34m(scoped_session, ignore_integrity_error)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m session\n\u001b[0;32m---> 77\u001b[0m     \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy_exc\u001b[38;5;241m.\u001b[39mIntegrityError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py:2032\u001b[0m, in \u001b[0;36mSession.commit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2030\u001b[0m     trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autobegin_t()\n\u001b[0;32m-> 2032\u001b[0m \u001b[43mtrans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcommit\u001b[0;34m(self, _to_root)\u001b[0m\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:139\u001b[0m, in \u001b[0;36m_StateChange.declare_states.<locals>._go\u001b[0;34m(fn, self, *arg, **kw)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     ret_value \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1313\u001b[0m, in \u001b[0;36mSessionTransaction.commit\u001b[0;34m(self, _to_root)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expect_state(SessionTransactionState\u001b[38;5;241m.\u001b[39mPREPARED):\n\u001b[0;32m-> 1313\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnested:\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36m_prepare_impl\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/state_changes.py:139\u001b[0m, in \u001b[0;36m_StateChange.declare_states.<locals>._go\u001b[0;34m(fn, self, *arg, **kw)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     ret_value \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py:1288\u001b[0m, in \u001b[0;36mSessionTransaction._prepare_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1288\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4345\u001b[0m, in \u001b[0;36mSession.flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   4344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flushing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 4345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4346\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4480\u001b[0m, in \u001b[0;36mSession._flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   4479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m-> 4480\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m   4481\u001b[0m         transaction\u001b[38;5;241m.\u001b[39mrollback(_capture_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py:4441\u001b[0m, in \u001b[0;36mSession._flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   4440\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4441\u001b[0m     \u001b[43mflush_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4442\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:466\u001b[0m, in \u001b[0;36mUOWTransaction.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m topological\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies, postsort_actions):\n\u001b[0;32m--> 466\u001b[0m     \u001b[43mrec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py:642\u001b[0m, in \u001b[0;36mSaveUpdateAll.execute\u001b[0;34m(self, uow)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;129m@util\u001b[39m\u001b[38;5;241m.\u001b[39mpreload_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlalchemy.orm.persistence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, uow):\n\u001b[0;32m--> 642\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreloaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morm_persistence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43muow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstates_for_mapper_hierarchy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43muow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:93\u001b[0m, in \u001b[0;36msave_obj\u001b[0;34m(base_mapper, states, uowtransaction, single)\u001b[0m\n\u001b[1;32m     85\u001b[0m     _emit_update_statements(\n\u001b[1;32m     86\u001b[0m         base_mapper,\n\u001b[1;32m     87\u001b[0m         uowtransaction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m         update,\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 93\u001b[0m     \u001b[43m_emit_insert_statements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_mapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43muowtransaction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43minsert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m _finalize_insert_update_commands(\n\u001b[1;32m    102\u001b[0m     base_mapper,\n\u001b[1;32m    103\u001b[0m     uowtransaction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m     ),\n\u001b[1;32m    120\u001b[0m )\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py:1233\u001b[0m, in \u001b[0;36m_emit_insert_statements\u001b[0;34m(base_mapper, uowtransaction, mapper, table, insert, bookkeeping, use_orm_insert_stmt, execution_options)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1233\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m primary_key \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39minserted_primary_key\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1415\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:523\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1637\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1629\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1630\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1631\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1635\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1636\u001b[0m )\n\u001b[0;32m-> 1637\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1842\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1982\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1982\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1983\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2351\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2350\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1963\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1963\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py:943\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 943\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (sqlite3.IntegrityError) UNIQUE constraint failed: studies.study_name\n[SQL: INSERT INTO studies (study_name) VALUES (?)]\n[parameters: ('RFC',)]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDuplicatedStudyError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m studyRFC \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRFC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTPESampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msqlite:///db.sqlite3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/optuna/_convert_positional_args.py:134\u001b[0m, in \u001b[0;36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    132\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(inferred_kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/optuna/study/study.py:1280\u001b[0m, in \u001b[0;36mcreate_study\u001b[0;34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[0m\n\u001b[1;32m   1278\u001b[0m storage \u001b[38;5;241m=\u001b[39m storages\u001b[38;5;241m.\u001b[39mget_storage(storage)\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1280\u001b[0m     study_id \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_new_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirection_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDuplicatedStudyError:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_if_exists:\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/optuna/storages/_cached_storage.py:78\u001b[0m, in \u001b[0;36m_CachedStorage.create_new_study\u001b[0;34m(self, directions, study_name)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_new_study\u001b[39m(\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m, directions: Sequence[StudyDirection], study_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     77\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m---> 78\u001b[0m     study_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_new_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m     80\u001b[0m         study \u001b[38;5;241m=\u001b[39m _StudyInfo()\n",
      "File \u001b[0;32m~/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/optuna/storages/_rdb/storage.py:278\u001b[0m, in \u001b[0;36mRDBStorage.create_new_study\u001b[0;34m(self, directions, study_name)\u001b[0m\n\u001b[1;32m    275\u001b[0m         session\u001b[38;5;241m.\u001b[39madd(models\u001b[38;5;241m.\u001b[39mStudyModel(study_name\u001b[38;5;241m=\u001b[39mstudy_name, directions\u001b[38;5;241m=\u001b[39mdirection_models))\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy_exc\u001b[38;5;241m.\u001b[39mIntegrityError:\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m optuna\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mDuplicatedStudyError(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnother study with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease specify a different name, or reuse the existing one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby setting `load_if_exists` (for Python API) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`--skip-if-exists` flag (for CLI).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study_name)\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    285\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA new study created in RDB with name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study_name))\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_study_id_from_name(study_name)\n",
      "\u001b[0;31mDuplicatedStudyError\u001b[0m: Another study with name 'RFC' already exists. Please specify a different name, or reuse the existing one by setting `load_if_exists` (for Python API) or `--skip-if-exists` flag (for CLI)."
     ]
    }
   ],
   "source": [
    "studyRFC = optuna.create_study(study_name = \"RFC\", \n",
    "                               direction = \"maximize\", \n",
    "                               sampler = optuna.samplers.TPESampler(seed = 42), \n",
    "                               storage = \"sqlite:///db.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.delete_study(study_name=\"RFC\", storage = \"sqlite:///db.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _objective(trial):\n",
    "    return objective(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyRFC.optimize(_objective, n_trials = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOptuna Best Trial:\")\n",
    "best = studyRFC.best_trial\n",
    "print(f\"Validation Loss: {best.value:.4f}\")\n",
    "for key, val in best.params.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "best_n_estimators = best.params[\"n_estimators\"]\n",
    "best_criterion = best.params[\"criterion\"]\n",
    "best_max_depth = best.params[\"max_depth\"]\n",
    "best_max_features = best.params[\"max_features\"]\n",
    "best_random_state = best.params[\"random_state\"]\n",
    "best_warm_start = best.params[\"warm_start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd594af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = RandomForestClassifier(n_estimators = best_n_estimators,\n",
    "                                    criterion = best_criterion,\n",
    "                                    max_depth = best_max_depth,\n",
    "                                    max_features = best_max_features,\n",
    "                                    random_state = best_random_state, \n",
    "                                    warm_start = best_warm_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987999a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(finalModel, \"savedModel/rfcmodel.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 10, max_features = 4, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ca57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_text,Y_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3153ac",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27162e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = multilabel_confusion_matrix(Y_test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tp, tn, fp, fn):\n",
    "    return (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "\n",
    "def precision(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(tp,fp,fn):\n",
    "    precision_val = precision(tp,fp)\n",
    "    recall_val = recall(tp,fn)\n",
    "    return 2 * (precision_val * recall_val) / (precision_val + recall_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(title, accuracy, precision, recall, f1_score):\n",
    "    print(f\"{title}\\n\")\n",
    "    print(f\"accuracy: {round(accuracy,2)}\")\n",
    "    print(f\"precision: {round(precision,2)}\")\n",
    "    print(f\"recall: {round(recall,2)}\")\n",
    "    print(f\"f1 Score: {round(f1_score,2)}\")\n",
    "    print(\"=======\\n\")\n",
    "\n",
    "\n",
    "def present_data(log_level):\n",
    "    total_accuracy = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "\n",
    "    for i in range(0, len(confusion_mat)):\n",
    "        tp, fp = confusion_mat[i][0]\n",
    "        fn, tn = confusion_mat[i][1]\n",
    "\n",
    "        accuracy_val = accuracy(tp, tn, fp, fn)\n",
    "        precision_val = precision(tp, fp)\n",
    "        recall_val = recall(tp, fn)\n",
    "        f1_score_val = f1_score(tp, fp, fn)\n",
    "\n",
    "        total_accuracy += accuracy_val\n",
    "        total_precision += precision_val\n",
    "        total_recall += recall_val\n",
    "        total_f1_score += f1_score_val\n",
    "\n",
    "        if(log_level == \"emotions\"):\n",
    "            print_eval(\n",
    "            f\"Emotion: {emotions[i]}\",\n",
    "                accuracy_val,\n",
    "                precision_val,\n",
    "                recall_val,\n",
    "                f1_score_val,\n",
    "            )\n",
    "\n",
    "    avg_accuracy = total_accuracy / len(confusion_mat)\n",
    "    avg_precision = total_precision / len(confusion_mat)\n",
    "    avg_recall = total_recall / len(confusion_mat)\n",
    "    avg_f1_score = total_f1_score / len(confusion_mat)\n",
    "\n",
    "    if(log_level==\"macro\"):\n",
    "        print_eval(\"Macro Average:\", avg_accuracy, avg_precision, avg_recall, avg_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_data(\"emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca845a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_data(\"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
