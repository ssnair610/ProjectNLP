{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3c0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c74e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"Data\\\\track-a.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a55cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a615c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpModel = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc80a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "textColumn = \"text\"\n",
    "labelColumns = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aafa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanerFunction(text: str) -> str:\n",
    "    tempDoc = nlpModel(text)\n",
    "    tokens = [\n",
    "        tok.lemma_.lower()\n",
    "        for tok in tempDoc\n",
    "        if not tok.is_stop and not tok.is_punct and tok.lemma_ != \"-PRON-\"\n",
    "    ]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142be880",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Spacy_text\"] = dataFrame[\"text\"].astype(str).apply(cleanerFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912e6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "userDevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "599ae6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelColumns = [col for col in [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"] if col in dataFrame]\n",
    "yData = dataFrame[labelColumns].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b5b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "xAll = dataFrame[\"Spacy_text\"].tolist()\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(xAll, yData, test_size = 0.1, random_state = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "526aae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.copy()\n",
    "xVal = xVal.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de8cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLabels = yTrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b2f1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Number of train examples: {len(xTrain)}, number of val examples: {len(xVal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0c9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_PATTERN = re.compile(r\"\\b\\w+\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc526de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleTokenize(text: str) -> list:\n",
    "    return TOKEN_PATTERN.findall(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dab582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabularyBuilder(texts: list, vocabsize: int = 20000):\n",
    "    counter = Counter()\n",
    "    for t in texts:\n",
    "        tokens = simpleTokenize(t)\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    mostCommon = counter.most_common(vocabsize - 2)\n",
    "    indextoword = [\"<pad>\", \"<unk>\"] + [token for token, _ in mostCommon]\n",
    "    wordtoindex = {w: i for i, w in enumerate(indextoword)}\n",
    "\n",
    "    return wordtoindex, indextoword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c34acf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 20000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n",
    "wordtoindex, indextoword = vocabularyBuilder(xTrain, vocabsize = MAX_VOCAB_SIZE)\n",
    "vocabSize = len(indextoword)\n",
    "\n",
    "padIndex = wordtoindex[\"<pad>\"]\n",
    "unkIndex = wordtoindex[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5359bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodePadFunction(texts: list, wordtoindex: dict, sequenceLength: int = 100) -> np.ndarray:\n",
    "    encodings = []\n",
    "\n",
    "    for t in texts:\n",
    "        tokens = simpleTokenize(t)\n",
    "        tokenIDs = [wordtoindex.get(tok, unkIndex) for tok in tokens]\n",
    "        if len(tokenIDs) > sequenceLength:\n",
    "            tokenIDs = tokenIDs[:sequenceLength]\n",
    "        else:\n",
    "            tokenIDs = tokenIDs + [padIndex] * (sequenceLength - len(tokenIDs))\n",
    "        encodings.append(tokenIDs)\n",
    "\n",
    "    return np.array(encodings, dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d23f9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEncode = encodePadFunction(xTrain, wordtoindex, sequenceLength = 100)\n",
    "valEncode = encodePadFunction(xVal, wordtoindex, sequenceLength = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc47c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"train_encodings shape: {trainEncode.shape}, val_encodings shape: {valEncode.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fce8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings: np.ndarray, labels: np.ndarray) -> None:\n",
    "        self.encodings = torch.from_numpy(encodings)\n",
    "        self.labels = torch.from_numpy(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings.size(0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encodings[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41285389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainDataset = TextDataset(trainEncode, yTrain)\n",
    "# valDataset = TextDataset(valEncode, yVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95f07725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Train dataset size: {len(trainDataset)}, Val dataset size: {len(valDataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a52a06",
   "metadata": {},
   "source": [
    "## Feed-forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feedforwardNeuralNetwork(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocabSize: int,\n",
    "            embeddingDim: int,\n",
    "            hiddenUnit1: int,\n",
    "            hiddenUnit2: int,\n",
    "            dropoutRate: float,\n",
    "            numLabels: int,\n",
    "            padIndex: int\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocabSize, embeddingDim, padding_idx = padIndex)\n",
    "        self.dropout1 = nn.Dropout(dropoutRate)\n",
    "        self.fc1 = nn.Linear(embeddingDim, hiddenUnit1)\n",
    "        self.bn1 = nn.BatchNorm1d(hiddenUnit1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropoutRate)\n",
    "        self.fc2 = nn.Linear(hiddenUnit1, hiddenUnit2)\n",
    "        self.bn2 = nn.BatchNorm1d(hiddenUnit2)\n",
    "        self.dropout3 = nn.Dropout(dropoutRate)\n",
    "        self.fc_out = nn.Linear(hiddenUnit2, numLabels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)             \n",
    "        avgEmb = emb.mean(dim = 1) \n",
    "        h1 = self.fc1(avgEmb)\n",
    "        h1 = self.bn1(h1)\n",
    "        h1 = self.relu(h1)\n",
    "        h1 = self.dropout2(h1)\n",
    "        h2 = self.fc2(h1)\n",
    "        h2 = self.bn2(h2)\n",
    "        h2 = self.relu(h2)\n",
    "        h2 = self.dropout3(h2)\n",
    "        return self.fc_out(h2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1127454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochTrain(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    totalLoss = 0.0\n",
    "    for batchInputs, batchLabels in dataloader:\n",
    "        batchInputs = batchInputs.to(device)\n",
    "        batchLabels = batchLabels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batchInputs)\n",
    "        loss = criterion(logits, batchLabels)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        totalLoss += loss.item() * batchInputs.size(0)\n",
    "    \n",
    "    return totalLoss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5df36a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    totalLoss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batchInputs, batchLabels in dataloader:\n",
    "            batchInputs = batchInputs.to(device)\n",
    "            batchLabels = batchLabels.to(device)\n",
    "\n",
    "            logits = model(batchInputs)\n",
    "            loss = criterion(logits, batchLabels)\n",
    "            totalLoss += loss.item() * batchInputs.size(0)\n",
    "\n",
    "    return totalLoss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65fffcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = np.maximum(yTrain.sum(axis = 0) / len(yTrain), 1e-4)\n",
    "class_weights = 1.0 / freq\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "weight_tensor = torch.FloatTensor(class_weights).to(userDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    embeddingDim = trial.suggest_categorical(\"embeddingDim\", [32, 64, 128, 256, 512,])\n",
    "    hiddenUnit1 = trial.suggest_int(\"hiddenUnit1\", 32, 256, step = 16)\n",
    "    hiddenUnit2 = trial.suggest_int(\"hiddenUnit2\", 32, 256, step = 16)\n",
    "    dropoutRate = trial.suggest_float(\"dropoutRate\", 0.2, 0.6, step = 0.1)\n",
    "    learnRate = trial.suggest_float(\"learnRate\", 1e-4, 1e-2, log = True)\n",
    "    weightDecay = trial.suggest_float(\"weightDecay\", 1e-6, 1e-2, log = True)\n",
    "    batchSize = trial.suggest_categorical(\"batchSize\", [32, 64, 128, 256])\n",
    "    epochs = trial.suggest_categorical(\"epochs\", [3, 5, 7, 9, 11, 13, 15])\n",
    "    optName = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    use_scheduler = trial.suggest_categorical(\"use_scheduler\", [True, False])\n",
    "    if optName == \"SGD\":\n",
    "        sgdvar = trial.suggest_float(\"momentum\", 0.1, 0.9)\n",
    "\n",
    "    trainDataset = TextDataset(trainEncode, yTrain)\n",
    "    valDataset = TextDataset(valEncode, yVal)\n",
    "\n",
    "    trainLoader = DataLoader(trainDataset, batch_size = batchSize, shuffle = True)\n",
    "    valLoader = DataLoader(valDataset, batch_size = batchSize, shuffle = True)\n",
    "\n",
    "    model = feedforwardNeuralNetwork(vocabSize, embeddingDim, hiddenUnit1, hiddenUnit2, dropoutRate, numLabels, padIndex).to(userDevice)\n",
    "\n",
    "    if optName == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr = learnRate, weight_decay = weightDecay)\n",
    "    elif optName == \"RMSprop\":\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr = learnRate, weight_decay = weightDecay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr = learnRate, momentum = sgdvar) # type: ignore\n",
    "\n",
    "    # optimizer = optim.Adam(model.parameters(), lr = learnRate, weight_decay = weightDecay)\n",
    "    criterionOption = nn.BCEWithLogitsLoss(pos_weight = weight_tensor)\n",
    "\n",
    "    bestvalLoss = float(\"inf\")\n",
    "    counterVar = 0\n",
    "    bestState = None\n",
    "\n",
    "    if use_scheduler:\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\", factor = 0.5, patience = 1)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        trainLoss = epochTrain(model, trainLoader, optimizer, criterionOption, userDevice)\n",
    "        valLoss = evaluateModel(model, valLoader, criterionOption, userDevice)\n",
    "\n",
    "        if use_scheduler:\n",
    "            scheduler.step(valLoss) # type: ignore\n",
    "\n",
    "        trial.report(valLoss, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        if valLoss < bestvalLoss:\n",
    "            bestvalLoss = valLoss\n",
    "            counterVar = 0\n",
    "            bestState = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            counterVar += 1\n",
    "            if counterVar >=2:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(bestState) # type: ignore\n",
    "    return bestvalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff976c4a",
   "metadata": {},
   "source": [
    ", trainEncoded: np.ndarray, yTrain: np.ndarray, valEncoded: np.ndarray, yVal: np.ndarray, vocabSize: int, padIndex: int\n",
    "              , numLabels: int, userDevice: torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bef7c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Using device:\", userDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "089355b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _objective(trial):\n",
    "    return objective(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcf69fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:09:41,923] A new study created in memory with name: no-name-3b394a1e-da78-4d2c-8459-9310492bce65\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"minimize\", sampler = optuna.samplers.TPESampler(seed = 42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76ec32aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:09:44,946] Trial 0 finished with value: 0.4907416483985818 and parameters: {'embeddingDim': 64, 'hiddenUnit1': 64, 'hiddenUnit2': 32, 'dropoutRate': 0.6, 'learnRate': 0.0015930522616241021, 'weightDecay': 0.0006796578090758161, 'batchSize': 64, 'epochs': 15, 'optimizer': 'SGD', 'use_scheduler': False, 'momentum': 0.25973902572668783}. Best is trial 0 with value: 0.4907416483985818.\n",
      "[I 2025-06-05 17:09:46,711] Trial 1 finished with value: 0.23524697071163234 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 32, 'hiddenUnit2': 256, 'dropoutRate': 0.6, 'learnRate': 0.004138040112561018, 'weightDecay': 1.6536937182824424e-05, 'batchSize': 64, 'epochs': 7, 'optimizer': 'SGD', 'use_scheduler': False, 'momentum': 0.815861880342119}. Best is trial 1 with value: 0.23524697071163234.\n",
      "[I 2025-06-05 17:09:46,937] Trial 2 finished with value: 0.18099571086654595 and parameters: {'embeddingDim': 64, 'hiddenUnit1': 96, 'hiddenUnit2': 112, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.004544383960336014, 'weightDecay': 2.67308831078167e-05, 'batchSize': 256, 'epochs': 5, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 2 with value: 0.18099571086654595.\n",
      "[I 2025-06-05 17:09:47,237] Trial 3 finished with value: 0.19027998241922056 and parameters: {'embeddingDim': 32, 'hiddenUnit1': 96, 'hiddenUnit2': 192, 'dropoutRate': 0.5, 'learnRate': 0.0059487468132197715, 'weightDecay': 7.742116473996259e-05, 'batchSize': 128, 'epochs': 3, 'optimizer': 'Adam', 'use_scheduler': True}. Best is trial 2 with value: 0.18099571086654595.\n",
      "[I 2025-06-05 17:09:47,817] Trial 4 finished with value: 0.18135019733372149 and parameters: {'embeddingDim': 64, 'hiddenUnit1': 64, 'hiddenUnit2': 240, 'dropoutRate': 0.6, 'learnRate': 0.0018484491720988621, 'weightDecay': 0.0030608522106722507, 'batchSize': 128, 'epochs': 5, 'optimizer': 'Adam', 'use_scheduler': True}. Best is trial 2 with value: 0.18099571086654595.\n",
      "[I 2025-06-05 17:09:49,701] Trial 5 finished with value: 0.1722171376005407 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 112, 'dropoutRate': 0.6, 'learnRate': 0.008411909465645722, 'weightDecay': 1.0165510266418738e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 5 with value: 0.1722171376005407.\n",
      "[I 2025-06-05 17:09:49,802] Trial 6 pruned. \n",
      "[I 2025-06-05 17:09:49,893] Trial 7 pruned. \n",
      "[I 2025-06-05 17:09:52,923] Trial 8 finished with value: 0.17565799205957336 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 96, 'hiddenUnit2': 208, 'dropoutRate': 0.5, 'learnRate': 0.004993980255757072, 'weightDecay': 0.00042702329684055453, 'batchSize': 32, 'epochs': 5, 'optimizer': 'Adam', 'use_scheduler': True}. Best is trial 5 with value: 0.1722171376005407.\n",
      "[I 2025-06-05 17:09:53,570] Trial 9 pruned. \n",
      "[I 2025-06-05 17:09:53,932] Trial 10 pruned. \n",
      "[I 2025-06-05 17:09:56,420] Trial 11 finished with value: 0.17915195156736063 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 160, 'hiddenUnit2': 192, 'dropoutRate': 0.5, 'learnRate': 0.009837517340558053, 'weightDecay': 0.005523921577573478, 'batchSize': 32, 'epochs': 9, 'optimizer': 'Adam', 'use_scheduler': False}. Best is trial 5 with value: 0.1722171376005407.\n",
      "[I 2025-06-05 17:09:58,091] Trial 12 pruned. \n",
      "[I 2025-06-05 17:10:00,170] Trial 13 pruned. \n",
      "[I 2025-06-05 17:10:01,145] Trial 14 pruned. \n",
      "[I 2025-06-05 17:10:04,644] Trial 15 finished with value: 0.17626320078484847 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 128, 'hiddenUnit2': 224, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.0011871715451817265, 'weightDecay': 1.2593966891684362e-05, 'batchSize': 32, 'epochs': 3, 'optimizer': 'Adam', 'use_scheduler': False}. Best is trial 5 with value: 0.1722171376005407.\n",
      "[I 2025-06-05 17:10:06,469] Trial 16 finished with value: 0.16892512540739796 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 80, 'dropoutRate': 0.5, 'learnRate': 0.009632222493623693, 'weightDecay': 1.2438890537144472e-06, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 16 with value: 0.16892512540739796.\n",
      "[I 2025-06-05 17:10:06,720] Trial 17 pruned. \n",
      "[I 2025-06-05 17:10:06,853] Trial 18 pruned. \n",
      "[I 2025-06-05 17:10:08,279] Trial 19 pruned. \n",
      "[I 2025-06-05 17:10:09,967] Trial 20 finished with value: 0.17729984562749898 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 160, 'hiddenUnit2': 128, 'dropoutRate': 0.4, 'learnRate': 0.00290180571170854, 'weightDecay': 2.1154752088278004e-06, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 16 with value: 0.16892512540739796.\n",
      "[I 2025-06-05 17:10:10,611] Trial 21 pruned. \n",
      "[I 2025-06-05 17:10:14,297] Trial 22 finished with value: 0.1679749829351687 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 128, 'hiddenUnit2': 176, 'dropoutRate': 0.5, 'learnRate': 0.008216291574612825, 'weightDecay': 2.832815938717314e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 22 with value: 0.1679749829351687.\n",
      "[I 2025-06-05 17:10:16,692] Trial 23 finished with value: 0.1691955450639828 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 128, 'hiddenUnit2': 160, 'dropoutRate': 0.6, 'learnRate': 0.009336008097911498, 'weightDecay': 3.182428758054558e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 22 with value: 0.1679749829351687.\n",
      "[I 2025-06-05 17:10:17,627] Trial 24 pruned. \n",
      "[I 2025-06-05 17:10:19,042] Trial 25 finished with value: 0.1734288387565406 and parameters: {'embeddingDim': 32, 'hiddenUnit1': 144, 'hiddenUnit2': 160, 'dropoutRate': 0.6, 'learnRate': 0.007072140615443141, 'weightDecay': 0.00013896406747619102, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 22 with value: 0.1679749829351687.\n",
      "[I 2025-06-05 17:10:19,376] Trial 26 pruned. \n",
      "[I 2025-06-05 17:10:19,960] Trial 27 pruned. \n",
      "[I 2025-06-05 17:10:20,677] Trial 28 pruned. \n",
      "[I 2025-06-05 17:10:20,842] Trial 29 pruned. \n",
      "[I 2025-06-05 17:10:20,989] Trial 30 pruned. \n",
      "[I 2025-06-05 17:10:21,371] Trial 31 pruned. \n",
      "[I 2025-06-05 17:10:21,733] Trial 32 pruned. \n",
      "[I 2025-06-05 17:10:22,116] Trial 33 pruned. \n",
      "[I 2025-06-05 17:10:22,320] Trial 34 pruned. \n",
      "[I 2025-06-05 17:10:22,532] Trial 35 pruned. \n",
      "[I 2025-06-05 17:10:22,951] Trial 36 pruned. \n",
      "[I 2025-06-05 17:10:23,057] Trial 37 pruned. \n",
      "[I 2025-06-05 17:10:23,329] Trial 38 pruned. \n",
      "[I 2025-06-05 17:10:23,731] Trial 39 pruned. \n",
      "[I 2025-06-05 17:10:25,457] Trial 40 finished with value: 0.17287398664959933 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 240, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.006080358938219766, 'weightDecay': 5.7278819932453086e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 22 with value: 0.1679749829351687.\n",
      "[I 2025-06-05 17:10:27,577] Trial 41 finished with value: 0.17130915115886647 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 256, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.006031260972346149, 'weightDecay': 6.786422923993293e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 22 with value: 0.1679749829351687.\n",
      "[I 2025-06-05 17:10:29,642] Trial 42 finished with value: 0.16719449572399636 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 256, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008051412019582352, 'weightDecay': 8.547021304396046e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 42 with value: 0.16719449572399636.\n",
      "[I 2025-06-05 17:10:31,020] Trial 43 pruned. \n",
      "[I 2025-06-05 17:10:32,377] Trial 44 pruned. \n",
      "[I 2025-06-05 17:10:33,434] Trial 45 pruned. \n",
      "[I 2025-06-05 17:10:33,720] Trial 46 pruned. \n",
      "[I 2025-06-05 17:10:34,285] Trial 47 pruned. \n",
      "[I 2025-06-05 17:10:34,425] Trial 48 pruned. \n",
      "[I 2025-06-05 17:10:35,125] Trial 49 finished with value: 0.17936833159803053 and parameters: {'embeddingDim': 32, 'hiddenUnit1': 96, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.004532330412312846, 'weightDecay': 0.009526059549680936, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 42 with value: 0.16719449572399636.\n",
      "[I 2025-06-05 17:10:35,582] Trial 50 pruned. \n",
      "[I 2025-06-05 17:10:37,837] Trial 51 finished with value: 0.16703141069154018 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 128, 'hiddenUnit2': 48, 'dropoutRate': 0.5, 'learnRate': 0.008576929741929602, 'weightDecay': 4.9908753029106936e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:10:38,196] Trial 52 pruned. \n",
      "[I 2025-06-05 17:10:39,857] Trial 53 finished with value: 0.17075710622627382 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 144, 'hiddenUnit2': 48, 'dropoutRate': 0.5, 'learnRate': 0.006694251189166105, 'weightDecay': 2.6660421337610542e-05, 'batchSize': 32, 'epochs': 5, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:10:40,213] Trial 54 pruned. \n",
      "[I 2025-06-05 17:10:44,643] Trial 55 finished with value: 0.1684648779755465 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 112, 'hiddenUnit2': 32, 'dropoutRate': 0.5, 'learnRate': 0.008551080300635523, 'weightDecay': 6.697801636129452e-06, 'batchSize': 32, 'epochs': 5, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:10:45,710] Trial 56 pruned. \n",
      "[I 2025-06-05 17:10:46,288] Trial 57 pruned. \n",
      "[I 2025-06-05 17:10:47,223] Trial 58 pruned. \n",
      "[I 2025-06-05 17:10:48,160] Trial 59 pruned. \n",
      "[I 2025-06-05 17:10:48,841] Trial 60 pruned. \n",
      "[I 2025-06-05 17:10:50,476] Trial 61 finished with value: 0.16978657966486382 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 160, 'hiddenUnit2': 48, 'dropoutRate': 0.5, 'learnRate': 0.006979902807790509, 'weightDecay': 3.116228089678293e-05, 'batchSize': 32, 'epochs': 5, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:10:50,847] Trial 62 pruned. \n",
      "[I 2025-06-05 17:10:51,396] Trial 63 pruned. \n",
      "[I 2025-06-05 17:10:51,751] Trial 64 pruned. \n",
      "[I 2025-06-05 17:10:51,973] Trial 65 pruned. \n",
      "[I 2025-06-05 17:10:52,393] Trial 66 pruned. \n",
      "[I 2025-06-05 17:10:53,376] Trial 67 pruned. \n",
      "[I 2025-06-05 17:10:53,750] Trial 68 pruned. \n",
      "[I 2025-06-05 17:10:54,091] Trial 69 pruned. \n",
      "[I 2025-06-05 17:10:54,265] Trial 70 pruned. \n",
      "[I 2025-06-05 17:10:54,614] Trial 71 pruned. \n",
      "[I 2025-06-05 17:10:56,266] Trial 72 finished with value: 0.17054335412565982 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 128, 'hiddenUnit2': 64, 'dropoutRate': 0.5, 'learnRate': 0.006380656190848781, 'weightDecay': 2.666888970217926e-05, 'batchSize': 32, 'epochs': 5, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:10:56,633] Trial 73 pruned. \n",
      "[I 2025-06-05 17:10:57,001] Trial 74 pruned. \n",
      "[I 2025-06-05 17:10:57,379] Trial 75 pruned. \n",
      "[I 2025-06-05 17:11:01,954] Trial 76 finished with value: 0.17144964812895022 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 160, 'hiddenUnit2': 64, 'dropoutRate': 0.5, 'learnRate': 0.005714899264880127, 'weightDecay': 3.792540760771744e-05, 'batchSize': 32, 'epochs': 5, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:11:02,317] Trial 77 pruned. \n",
      "[I 2025-06-05 17:11:02,704] Trial 78 pruned. \n",
      "[I 2025-06-05 17:11:02,837] Trial 79 pruned. \n",
      "[I 2025-06-05 17:11:03,122] Trial 80 pruned. \n",
      "[I 2025-06-05 17:11:03,475] Trial 81 pruned. \n",
      "[I 2025-06-05 17:11:04,179] Trial 82 pruned. \n",
      "[I 2025-06-05 17:11:04,552] Trial 83 pruned. \n",
      "[I 2025-06-05 17:11:04,915] Trial 84 pruned. \n",
      "[I 2025-06-05 17:11:05,290] Trial 85 pruned. \n",
      "[I 2025-06-05 17:11:05,575] Trial 86 pruned. \n",
      "[I 2025-06-05 17:11:05,789] Trial 87 pruned. \n",
      "[I 2025-06-05 17:11:07,633] Trial 88 pruned. \n",
      "[I 2025-06-05 17:11:09,215] Trial 89 pruned. \n",
      "[I 2025-06-05 17:11:13,784] Trial 90 finished with value: 0.17201214243358653 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 96, 'hiddenUnit2': 160, 'dropoutRate': 0.5, 'learnRate': 0.006247200778746956, 'weightDecay': 2.3729309500524826e-06, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:11:15,186] Trial 91 finished with value: 0.17189296655061012 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 256, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.009152605421517222, 'weightDecay': 9.650759546904883e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:11:16,938] Trial 92 finished with value: 0.17097820438417716 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 224, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.005814537661514335, 'weightDecay': 4.3897795280453474e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:11:19,369] Trial 93 finished with value: 0.16848224197053738 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.007121863472674131, 'weightDecay': 4.3765611255694076e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 51 with value: 0.16703141069154018.\n",
      "[I 2025-06-05 17:11:21,386] Trial 94 finished with value: 0.16600880677734473 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.007236979142074381, 'weightDecay': 2.7632200353354037e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:23,437] Trial 95 finished with value: 0.1709236644665687 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007451806628988603, 'weightDecay': 1.0621116224181694e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:23,706] Trial 96 pruned. \n",
      "[I 2025-06-05 17:11:25,763] Trial 97 finished with value: 0.1683691161741849 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008891820702591495, 'weightDecay': 3.730550997130394e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:26,169] Trial 98 pruned. \n",
      "[I 2025-06-05 17:11:26,514] Trial 99 pruned. \n",
      "[I 2025-06-05 17:11:27,088] Trial 100 pruned. \n",
      "[I 2025-06-05 17:11:28,784] Trial 101 finished with value: 0.16973887997198622 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008022790728367398, 'weightDecay': 1.9568432303649485e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:30,809] Trial 102 finished with value: 0.1690596706815575 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.008086470805591417, 'weightDecay': 1.838209242915074e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:31,200] Trial 103 pruned. \n",
      "[I 2025-06-05 17:11:32,623] Trial 104 pruned. \n",
      "[I 2025-06-05 17:11:33,087] Trial 105 pruned. \n",
      "[I 2025-06-05 17:11:33,507] Trial 106 pruned. \n",
      "[I 2025-06-05 17:11:34,189] Trial 107 pruned. \n",
      "[I 2025-06-05 17:11:34,387] Trial 108 pruned. \n",
      "[I 2025-06-05 17:11:34,581] Trial 109 pruned. \n",
      "[I 2025-06-05 17:11:36,312] Trial 110 finished with value: 0.1697552203056184 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 176, 'hiddenUnit2': 160, 'dropoutRate': 0.4, 'learnRate': 0.008579047906309213, 'weightDecay': 2.3679717082417044e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:36,707] Trial 111 pruned. \n",
      "[I 2025-06-05 17:11:37,116] Trial 112 pruned. \n",
      "[I 2025-06-05 17:11:37,501] Trial 113 pruned. \n",
      "[I 2025-06-05 17:11:38,289] Trial 114 pruned. \n",
      "[I 2025-06-05 17:11:38,992] Trial 115 pruned. \n",
      "[I 2025-06-05 17:11:39,666] Trial 116 pruned. \n",
      "[I 2025-06-05 17:11:41,342] Trial 117 pruned. \n",
      "[I 2025-06-05 17:11:42,082] Trial 118 pruned. \n",
      "[I 2025-06-05 17:11:43,449] Trial 119 pruned. \n",
      "[I 2025-06-05 17:11:43,604] Trial 120 pruned. \n",
      "[I 2025-06-05 17:11:44,314] Trial 121 pruned. \n",
      "[I 2025-06-05 17:11:46,371] Trial 122 finished with value: 0.16833272011486633 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 160, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.006891277196744268, 'weightDecay': 3.378242693696188e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:46,755] Trial 123 pruned. \n",
      "[I 2025-06-05 17:11:47,487] Trial 124 pruned. \n",
      "[I 2025-06-05 17:11:49,552] Trial 125 finished with value: 0.1685121231023155 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 240, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.008659872919581646, 'weightDecay': 5.407333678998506e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:49,916] Trial 126 pruned. \n",
      "[I 2025-06-05 17:11:50,176] Trial 127 pruned. \n",
      "[I 2025-06-05 17:11:51,135] Trial 128 pruned. \n",
      "[I 2025-06-05 17:11:52,258] Trial 129 pruned. \n",
      "[I 2025-06-05 17:11:52,637] Trial 130 pruned. \n",
      "[I 2025-06-05 17:11:53,032] Trial 131 pruned. \n",
      "[I 2025-06-05 17:11:53,400] Trial 132 pruned. \n",
      "[I 2025-06-05 17:11:54,137] Trial 133 pruned. \n",
      "[I 2025-06-05 17:11:55,860] Trial 134 finished with value: 0.17053395369853352 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.00998122361751661, 'weightDecay': 3.349154507669067e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:57,580] Trial 135 finished with value: 0.1690775986074971 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 160, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.0077911672072521546, 'weightDecay': 2.4025926525062366e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:11:57,942] Trial 136 pruned. \n",
      "[I 2025-06-05 17:11:58,648] Trial 137 pruned. \n",
      "[I 2025-06-05 17:11:58,804] Trial 138 pruned. \n",
      "[I 2025-06-05 17:11:59,170] Trial 139 pruned. \n",
      "[I 2025-06-05 17:12:00,902] Trial 140 finished with value: 0.17022058082616717 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.2, 'learnRate': 0.007884333993708994, 'weightDecay': 1.1892710346132888e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:01,596] Trial 141 pruned. \n",
      "[I 2025-06-05 17:12:01,965] Trial 142 pruned. \n",
      "[I 2025-06-05 17:12:02,668] Trial 143 pruned. \n",
      "[I 2025-06-05 17:12:04,727] Trial 144 finished with value: 0.169804931709052 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.008953433998318938, 'weightDecay': 4.519566173891092e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:05,427] Trial 145 pruned. \n",
      "[I 2025-06-05 17:12:08,189] Trial 146 pruned. \n",
      "[I 2025-06-05 17:12:09,361] Trial 147 pruned. \n",
      "[I 2025-06-05 17:12:09,862] Trial 148 pruned. \n",
      "[I 2025-06-05 17:12:10,021] Trial 149 pruned. \n",
      "[I 2025-06-05 17:12:10,428] Trial 150 pruned. \n",
      "[I 2025-06-05 17:12:10,788] Trial 151 pruned. \n",
      "[I 2025-06-05 17:12:11,259] Trial 152 pruned. \n",
      "[I 2025-06-05 17:12:11,641] Trial 153 pruned. \n",
      "[I 2025-06-05 17:12:12,013] Trial 154 pruned. \n",
      "[I 2025-06-05 17:12:12,376] Trial 155 pruned. \n",
      "[I 2025-06-05 17:12:14,469] Trial 156 finished with value: 0.1671390003568429 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 240, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.00565041438699419, 'weightDecay': 4.038559275490669e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:15,222] Trial 157 pruned. \n",
      "[I 2025-06-05 17:12:16,148] Trial 158 finished with value: 0.17115262166902906 and parameters: {'embeddingDim': 32, 'hiddenUnit1': 240, 'hiddenUnit2': 80, 'dropoutRate': 0.4, 'learnRate': 0.009974146231428185, 'weightDecay': 5.593916150282554e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:17,126] Trial 159 pruned. \n",
      "[I 2025-06-05 17:12:17,332] Trial 160 pruned. \n",
      "[I 2025-06-05 17:12:17,713] Trial 161 pruned. \n",
      "[I 2025-06-05 17:12:18,110] Trial 162 pruned. \n",
      "[I 2025-06-05 17:12:18,484] Trial 163 pruned. \n",
      "[I 2025-06-05 17:12:19,537] Trial 164 pruned. \n",
      "[I 2025-06-05 17:12:20,137] Trial 165 pruned. \n",
      "[I 2025-06-05 17:12:20,305] Trial 166 pruned. \n",
      "[I 2025-06-05 17:12:20,554] Trial 167 pruned. \n",
      "[I 2025-06-05 17:12:20,939] Trial 168 pruned. \n",
      "[I 2025-06-05 17:12:21,314] Trial 169 pruned. \n",
      "[I 2025-06-05 17:12:21,734] Trial 170 pruned. \n",
      "[I 2025-06-05 17:12:22,448] Trial 171 pruned. \n",
      "[I 2025-06-05 17:12:22,838] Trial 172 pruned. \n",
      "[I 2025-06-05 17:12:24,963] Trial 173 finished with value: 0.16855731203022417 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008086319217168016, 'weightDecay': 2.549860801708588e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:25,668] Trial 174 pruned. \n",
      "[I 2025-06-05 17:12:26,045] Trial 175 pruned. \n",
      "[I 2025-06-05 17:12:26,420] Trial 176 pruned. \n",
      "[I 2025-06-05 17:12:26,836] Trial 177 pruned. \n",
      "[I 2025-06-05 17:12:27,774] Trial 178 pruned. \n",
      "[I 2025-06-05 17:12:29,860] Trial 179 finished with value: 0.1689576468420373 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 160, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.005595722813852624, 'weightDecay': 3.786678420712375e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:30,005] Trial 180 pruned. \n",
      "[I 2025-06-05 17:12:31,013] Trial 181 pruned. \n",
      "[I 2025-06-05 17:12:31,402] Trial 182 pruned. \n",
      "[I 2025-06-05 17:12:31,776] Trial 183 pruned. \n",
      "[I 2025-06-05 17:12:32,335] Trial 184 pruned. \n",
      "[I 2025-06-05 17:12:34,045] Trial 185 finished with value: 0.16977308163358848 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 160, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.007144632810734328, 'weightDecay': 3.924013930960043e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:34,413] Trial 186 pruned. \n",
      "[I 2025-06-05 17:12:34,774] Trial 187 pruned. \n",
      "[I 2025-06-05 17:12:35,165] Trial 188 pruned. \n",
      "[I 2025-06-05 17:12:35,527] Trial 189 pruned. \n",
      "[I 2025-06-05 17:12:36,590] Trial 190 finished with value: 0.17147041319294526 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 176, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.007985502176336012, 'weightDecay': 2.347398137062308e-05, 'batchSize': 32, 'epochs': 3, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:36,965] Trial 191 pruned. \n",
      "[I 2025-06-05 17:12:37,349] Trial 192 pruned. \n",
      "[I 2025-06-05 17:12:37,743] Trial 193 pruned. \n",
      "[I 2025-06-05 17:12:38,117] Trial 194 pruned. \n",
      "[I 2025-06-05 17:12:38,380] Trial 195 pruned. \n",
      "[I 2025-06-05 17:12:38,763] Trial 196 pruned. \n",
      "[I 2025-06-05 17:12:39,835] Trial 197 pruned. \n",
      "[I 2025-06-05 17:12:40,426] Trial 198 pruned. \n",
      "[I 2025-06-05 17:12:40,586] Trial 199 pruned. \n",
      "[I 2025-06-05 17:12:41,150] Trial 200 pruned. \n",
      "[I 2025-06-05 17:12:41,877] Trial 201 pruned. \n",
      "[I 2025-06-05 17:12:42,246] Trial 202 pruned. \n",
      "[I 2025-06-05 17:12:43,968] Trial 203 finished with value: 0.1692782972909053 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.009171081394201556, 'weightDecay': 3.183095504827687e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:44,362] Trial 204 pruned. \n",
      "[I 2025-06-05 17:12:44,762] Trial 205 pruned. \n",
      "[I 2025-06-05 17:12:45,147] Trial 206 pruned. \n",
      "[I 2025-06-05 17:12:45,423] Trial 207 pruned. \n",
      "[I 2025-06-05 17:12:45,808] Trial 208 pruned. \n",
      "[I 2025-06-05 17:12:46,248] Trial 209 pruned. \n",
      "[I 2025-06-05 17:12:46,623] Trial 210 pruned. \n",
      "[I 2025-06-05 17:12:48,953] Trial 211 finished with value: 0.16634041307635256 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.009331708368449055, 'weightDecay': 4.4010670195857944e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:51,039] Trial 212 finished with value: 0.16971538078698872 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.009566361484002028, 'weightDecay': 4.27663700223387e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:53,120] Trial 213 finished with value: 0.16775361359764954 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.0095506308300277, 'weightDecay': 5.0610088407196696e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:12:53,824] Trial 214 pruned. \n",
      "[I 2025-06-05 17:12:54,213] Trial 215 pruned. \n",
      "[I 2025-06-05 17:12:54,938] Trial 216 pruned. \n",
      "[I 2025-06-05 17:12:55,359] Trial 217 pruned. \n",
      "[I 2025-06-05 17:12:55,788] Trial 218 pruned. \n",
      "[I 2025-06-05 17:12:56,248] Trial 219 pruned. \n",
      "[I 2025-06-05 17:13:02,174] Trial 220 finished with value: 0.16705402215465312 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.00801173496256358, 'weightDecay': 3.533294508818979e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:13:03,258] Trial 221 pruned. \n",
      "[I 2025-06-05 17:13:04,314] Trial 222 pruned. \n",
      "[I 2025-06-05 17:13:10,310] Trial 223 finished with value: 0.16806705166932048 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.007859777439880493, 'weightDecay': 4.0951555979251524e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 94 with value: 0.16600880677734473.\n",
      "[I 2025-06-05 17:13:11,318] Trial 224 pruned. \n",
      "[I 2025-06-05 17:13:12,331] Trial 225 pruned. \n",
      "[I 2025-06-05 17:13:12,668] Trial 226 pruned. \n",
      "[I 2025-06-05 17:13:13,750] Trial 227 pruned. \n",
      "[I 2025-06-05 17:13:15,863] Trial 228 pruned. \n",
      "[I 2025-06-05 17:13:24,272] Trial 229 finished with value: 0.16586360507493414 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.007453746926316008, 'weightDecay': 2.918709204959085e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:13:32,914] Trial 230 finished with value: 0.16955812528245284 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.0074533074628008655, 'weightDecay': 2.911350642447143e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:13:40,449] Trial 231 finished with value: 0.16681471359428515 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.0075744095922561615, 'weightDecay': 2.8657466567061695e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:13:45,324] Trial 232 finished with value: 0.1692685293914609 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.007609978746968064, 'weightDecay': 2.7547877955394643e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:13:46,359] Trial 233 pruned. \n",
      "[I 2025-06-05 17:13:47,431] Trial 234 pruned. \n",
      "[I 2025-06-05 17:13:53,907] Trial 235 finished with value: 0.16761126226681664 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.00770803270929005, 'weightDecay': 3.822620614787595e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:13:55,109] Trial 236 pruned. \n",
      "[I 2025-06-05 17:14:01,613] Trial 237 finished with value: 0.16987574869760108 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.006804407357121542, 'weightDecay': 2.5818955177356107e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:14:02,684] Trial 238 pruned. \n",
      "[I 2025-06-05 17:14:03,344] Trial 239 pruned. \n",
      "[I 2025-06-05 17:14:04,107] Trial 240 pruned. \n",
      "[I 2025-06-05 17:14:05,193] Trial 241 pruned. \n",
      "[I 2025-06-05 17:14:06,306] Trial 242 pruned. \n",
      "[I 2025-06-05 17:14:07,391] Trial 243 pruned. \n",
      "[I 2025-06-05 17:14:08,502] Trial 244 pruned. \n",
      "[I 2025-06-05 17:14:09,577] Trial 245 pruned. \n",
      "[I 2025-06-05 17:14:10,693] Trial 246 pruned. \n",
      "[I 2025-06-05 17:14:11,180] Trial 247 pruned. \n",
      "[I 2025-06-05 17:14:12,247] Trial 248 pruned. \n",
      "[I 2025-06-05 17:14:12,915] Trial 249 pruned. \n",
      "[I 2025-06-05 17:14:14,036] Trial 250 pruned. \n",
      "[I 2025-06-05 17:14:14,336] Trial 251 pruned. \n",
      "[I 2025-06-05 17:14:15,762] Trial 252 pruned. \n",
      "[I 2025-06-05 17:14:16,997] Trial 253 pruned. \n",
      "[I 2025-06-05 17:14:17,351] Trial 254 pruned. \n",
      "[I 2025-06-05 17:14:20,385] Trial 255 finished with value: 0.16702297394456417 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.009271925811006056, 'weightDecay': 2.1523062168240957e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:14:21,050] Trial 256 pruned. \n",
      "[I 2025-06-05 17:14:21,681] Trial 257 pruned. \n",
      "[I 2025-06-05 17:14:22,331] Trial 258 pruned. \n",
      "[I 2025-06-05 17:14:24,130] Trial 259 pruned. \n",
      "[I 2025-06-05 17:14:24,741] Trial 260 pruned. \n",
      "[I 2025-06-05 17:14:31,482] Trial 261 finished with value: 0.16835280268416078 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 128, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008440818161671151, 'weightDecay': 2.742331354626599e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:14:31,799] Trial 262 pruned. \n",
      "[I 2025-06-05 17:14:32,417] Trial 263 pruned. \n",
      "[I 2025-06-05 17:14:39,202] Trial 264 finished with value: 0.16600502290450278 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 128, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008473752837459587, 'weightDecay': 5.2647569633850986e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:14:40,206] Trial 265 pruned. \n",
      "[I 2025-06-05 17:14:41,276] Trial 266 pruned. \n",
      "[I 2025-06-05 17:14:42,324] Trial 267 pruned. \n",
      "[I 2025-06-05 17:14:43,094] Trial 268 pruned. \n",
      "[I 2025-06-05 17:14:43,752] Trial 269 pruned. \n",
      "[I 2025-06-05 17:14:44,870] Trial 270 pruned. \n",
      "[I 2025-06-05 17:14:45,977] Trial 271 pruned. \n",
      "[I 2025-06-05 17:14:46,272] Trial 272 pruned. \n",
      "[I 2025-06-05 17:14:46,484] Trial 273 pruned. \n",
      "[I 2025-06-05 17:14:51,680] Trial 274 finished with value: 0.1700165691896466 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.006785322109573069, 'weightDecay': 3.973676602799833e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:14:52,462] Trial 275 pruned. \n",
      "[I 2025-06-05 17:14:52,905] Trial 276 pruned. \n",
      "[I 2025-06-05 17:14:53,364] Trial 277 pruned. \n",
      "[I 2025-06-05 17:14:54,436] Trial 278 pruned. \n",
      "[I 2025-06-05 17:14:54,866] Trial 279 pruned. \n",
      "[I 2025-06-05 17:14:55,651] Trial 280 pruned. \n",
      "[I 2025-06-05 17:14:56,002] Trial 281 pruned. \n",
      "[I 2025-06-05 17:14:57,125] Trial 282 pruned. \n",
      "[I 2025-06-05 17:14:57,573] Trial 283 pruned. \n",
      "[I 2025-06-05 17:14:58,044] Trial 284 pruned. \n",
      "[I 2025-06-05 17:14:58,381] Trial 285 pruned. \n",
      "[I 2025-06-05 17:14:58,996] Trial 286 pruned. \n",
      "[I 2025-06-05 17:14:59,410] Trial 287 pruned. \n",
      "[I 2025-06-05 17:14:59,832] Trial 288 pruned. \n",
      "[I 2025-06-05 17:15:00,913] Trial 289 pruned. \n",
      "[I 2025-06-05 17:15:01,240] Trial 290 pruned. \n",
      "[I 2025-06-05 17:15:01,675] Trial 291 pruned. \n",
      "[I 2025-06-05 17:15:02,696] Trial 292 pruned. \n",
      "[I 2025-06-05 17:15:03,114] Trial 293 pruned. \n",
      "[I 2025-06-05 17:15:03,355] Trial 294 pruned. \n",
      "[I 2025-06-05 17:15:04,341] Trial 295 pruned. \n",
      "[I 2025-06-05 17:15:04,992] Trial 296 pruned. \n",
      "[I 2025-06-05 17:15:05,193] Trial 297 pruned. \n",
      "[I 2025-06-05 17:15:05,523] Trial 298 pruned. \n",
      "[I 2025-06-05 17:15:08,436] Trial 299 pruned. \n",
      "[I 2025-06-05 17:15:08,937] Trial 300 pruned. \n",
      "[I 2025-06-05 17:15:10,906] Trial 301 finished with value: 0.17029694787862068 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008566260237574829, 'weightDecay': 6.927849797647851e-06, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:15:11,910] Trial 302 pruned. \n",
      "[I 2025-06-05 17:15:12,348] Trial 303 pruned. \n",
      "[I 2025-06-05 17:15:12,664] Trial 304 pruned. \n",
      "[I 2025-06-05 17:15:13,073] Trial 305 pruned. \n",
      "[I 2025-06-05 17:15:16,058] Trial 306 finished with value: 0.16976436778956802 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008971098649181415, 'weightDecay': 1.6613953781265493e-05, 'batchSize': 32, 'epochs': 5, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:15:17,196] Trial 307 pruned. \n",
      "[I 2025-06-05 17:15:18,042] Trial 308 pruned. \n",
      "[I 2025-06-05 17:15:18,249] Trial 309 pruned. \n",
      "[I 2025-06-05 17:15:19,445] Trial 310 pruned. \n",
      "[I 2025-06-05 17:15:19,885] Trial 311 pruned. \n",
      "[I 2025-06-05 17:15:20,671] Trial 312 pruned. \n",
      "[I 2025-06-05 17:15:21,146] Trial 313 pruned. \n",
      "[I 2025-06-05 17:15:22,014] Trial 314 pruned. \n",
      "[I 2025-06-05 17:15:22,626] Trial 315 pruned. \n",
      "[I 2025-06-05 17:15:26,408] Trial 316 pruned. \n",
      "[I 2025-06-05 17:15:26,797] Trial 317 pruned. \n",
      "[I 2025-06-05 17:15:27,035] Trial 318 pruned. \n",
      "[I 2025-06-05 17:15:27,981] Trial 319 pruned. \n",
      "[I 2025-06-05 17:15:28,404] Trial 320 pruned. \n",
      "[I 2025-06-05 17:15:28,793] Trial 321 pruned. \n",
      "[I 2025-06-05 17:15:29,773] Trial 322 pruned. \n",
      "[I 2025-06-05 17:15:30,150] Trial 323 pruned. \n",
      "[I 2025-06-05 17:15:30,742] Trial 324 pruned. \n",
      "[I 2025-06-05 17:15:33,119] Trial 325 pruned. \n",
      "[I 2025-06-05 17:15:34,126] Trial 326 pruned. \n",
      "[I 2025-06-05 17:15:34,505] Trial 327 pruned. \n",
      "[I 2025-06-05 17:15:34,952] Trial 328 pruned. \n",
      "[I 2025-06-05 17:15:35,921] Trial 329 pruned. \n",
      "[I 2025-06-05 17:15:36,643] Trial 330 pruned. \n",
      "[I 2025-06-05 17:15:37,034] Trial 331 pruned. \n",
      "[I 2025-06-05 17:15:37,310] Trial 332 pruned. \n",
      "[I 2025-06-05 17:15:39,183] Trial 333 pruned. \n",
      "[I 2025-06-05 17:15:39,564] Trial 334 pruned. \n",
      "[I 2025-06-05 17:15:39,989] Trial 335 pruned. \n",
      "[I 2025-06-05 17:15:40,764] Trial 336 pruned. \n",
      "[I 2025-06-05 17:15:41,068] Trial 337 pruned. \n",
      "[I 2025-06-05 17:15:41,476] Trial 338 pruned. \n",
      "[I 2025-06-05 17:15:46,134] Trial 339 finished with value: 0.16983767101265462 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.005907374690162471, 'weightDecay': 4.117540116714613e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:15:48,153] Trial 340 finished with value: 0.16780730398768554 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 112, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.00998655898015174, 'weightDecay': 2.844241541654372e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:15:48,543] Trial 341 pruned. \n",
      "[I 2025-06-05 17:15:48,992] Trial 342 pruned. \n",
      "[I 2025-06-05 17:15:49,989] Trial 343 pruned. \n",
      "[I 2025-06-05 17:15:50,219] Trial 344 pruned. \n",
      "[I 2025-06-05 17:15:50,767] Trial 345 pruned. \n",
      "[I 2025-06-05 17:15:52,408] Trial 346 finished with value: 0.17045283554263063 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 112, 'hiddenUnit2': 32, 'dropoutRate': 0.4, 'learnRate': 0.009877719650662437, 'weightDecay': 5.400672542792304e-06, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:15:53,377] Trial 347 pruned. \n",
      "[I 2025-06-05 17:15:53,590] Trial 348 pruned. \n",
      "[I 2025-06-05 17:15:55,486] Trial 349 pruned. \n",
      "[I 2025-06-05 17:15:55,862] Trial 350 pruned. \n",
      "[I 2025-06-05 17:15:56,147] Trial 351 pruned. \n",
      "[I 2025-06-05 17:15:57,876] Trial 352 finished with value: 0.1673594110171287 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00998270497917641, 'weightDecay': 5.035396720277575e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:15:58,931] Trial 353 pruned. \n",
      "[I 2025-06-05 17:15:59,986] Trial 354 pruned. \n",
      "[I 2025-06-05 17:16:00,621] Trial 355 pruned. \n",
      "[I 2025-06-05 17:16:01,025] Trial 356 pruned. \n",
      "[I 2025-06-05 17:16:07,896] Trial 357 finished with value: 0.16730993345971573 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008599912296919572, 'weightDecay': 4.300985786039942e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:16:09,677] Trial 358 pruned. \n",
      "[I 2025-06-05 17:16:10,061] Trial 359 pruned. \n",
      "[I 2025-06-05 17:16:18,265] Trial 360 finished with value: 0.16854562849774687 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009979241485061083, 'weightDecay': 4.248793421913812e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:16:24,944] Trial 361 finished with value: 0.16686455050100057 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00997110695638743, 'weightDecay': 4.4513324439093794e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:16:31,155] Trial 362 finished with value: 0.16761733015952127 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009852075631712958, 'weightDecay': 5.055262161537586e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:16:33,198] Trial 363 pruned. \n",
      "[I 2025-06-05 17:16:38,190] Trial 364 finished with value: 0.16979474555499288 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00889246686963179, 'weightDecay': 4.742149535324705e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:16:41,271] Trial 365 pruned. \n",
      "[I 2025-06-05 17:16:42,329] Trial 366 pruned. \n",
      "[I 2025-06-05 17:16:44,336] Trial 367 pruned. \n",
      "[I 2025-06-05 17:16:45,520] Trial 368 pruned. \n",
      "[I 2025-06-05 17:16:46,537] Trial 369 pruned. \n",
      "[I 2025-06-05 17:16:47,571] Trial 370 pruned. \n",
      "[I 2025-06-05 17:16:52,344] Trial 371 finished with value: 0.16859669692895043 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007988972387414835, 'weightDecay': 3.77520183557953e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:16:52,971] Trial 372 pruned. \n",
      "[I 2025-06-05 17:16:54,918] Trial 373 pruned. \n",
      "[I 2025-06-05 17:16:55,358] Trial 374 pruned. \n",
      "[I 2025-06-05 17:16:56,375] Trial 375 pruned. \n",
      "[I 2025-06-05 17:16:57,402] Trial 376 pruned. \n",
      "[I 2025-06-05 17:16:58,409] Trial 377 pruned. \n",
      "[I 2025-06-05 17:16:58,723] Trial 378 pruned. \n",
      "[I 2025-06-05 17:16:59,723] Trial 379 pruned. \n",
      "[I 2025-06-05 17:17:00,741] Trial 380 pruned. \n",
      "[I 2025-06-05 17:17:01,345] Trial 381 pruned. \n",
      "[I 2025-06-05 17:17:02,386] Trial 382 pruned. \n",
      "[I 2025-06-05 17:17:09,052] Trial 383 finished with value: 0.16824316262983674 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009997346408926716, 'weightDecay': 5.245052442504034e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:17:09,808] Trial 384 pruned. \n",
      "[I 2025-06-05 17:17:12,674] Trial 385 pruned. \n",
      "[I 2025-06-05 17:17:13,027] Trial 386 pruned. \n",
      "[I 2025-06-05 17:17:15,901] Trial 387 pruned. \n",
      "[I 2025-06-05 17:17:22,588] Trial 388 finished with value: 0.16733788093720103 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008925225835133707, 'weightDecay': 4.5538652763014896e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:17:24,587] Trial 389 pruned. \n",
      "[I 2025-06-05 17:17:25,627] Trial 390 pruned. \n",
      "[I 2025-06-05 17:17:26,789] Trial 391 pruned. \n",
      "[I 2025-06-05 17:17:27,808] Trial 392 pruned. \n",
      "[I 2025-06-05 17:17:34,350] Trial 393 finished with value: 0.17038075486029958 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 128, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008038230709689818, 'weightDecay': 3.527938861988468e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:17:41,624] Trial 394 finished with value: 0.16604650203501706 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008986468445125304, 'weightDecay': 5.877336321310208e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:17:42,619] Trial 395 pruned. \n",
      "[I 2025-06-05 17:17:45,606] Trial 396 pruned. \n",
      "[I 2025-06-05 17:17:46,253] Trial 397 pruned. \n",
      "[I 2025-06-05 17:17:47,275] Trial 398 pruned. \n",
      "[I 2025-06-05 17:17:53,012] Trial 399 finished with value: 0.16784763185556184 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008462751522842711, 'weightDecay': 4.325912623110975e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:17:54,020] Trial 400 pruned. \n",
      "[I 2025-06-05 17:17:55,055] Trial 401 pruned. \n",
      "[I 2025-06-05 17:17:55,506] Trial 402 pruned. \n",
      "[I 2025-06-05 17:17:57,504] Trial 403 pruned. \n",
      "[I 2025-06-05 17:17:58,507] Trial 404 pruned. \n",
      "[I 2025-06-05 17:18:04,537] Trial 405 finished with value: 0.16684229758026797 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 256, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008968306677032923, 'weightDecay': 3.7949646362252375e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:18:08,754] Trial 406 pruned. \n",
      "[I 2025-06-05 17:18:09,425] Trial 407 pruned. \n",
      "[I 2025-06-05 17:18:10,251] Trial 408 pruned. \n",
      "[I 2025-06-05 17:18:11,317] Trial 409 pruned. \n",
      "[I 2025-06-05 17:18:11,639] Trial 410 pruned. \n",
      "[I 2025-06-05 17:18:14,738] Trial 411 pruned. \n",
      "[I 2025-06-05 17:18:16,807] Trial 412 pruned. \n",
      "[I 2025-06-05 17:18:19,690] Trial 413 finished with value: 0.1665544236072134 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 240, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008610408112746864, 'weightDecay': 3.8574595401654466e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:18:21,700] Trial 414 pruned. \n",
      "[I 2025-06-05 17:18:22,318] Trial 415 pruned. \n",
      "[I 2025-06-05 17:18:22,556] Trial 416 pruned. \n",
      "[I 2025-06-05 17:18:23,271] Trial 417 pruned. \n",
      "[I 2025-06-05 17:18:24,972] Trial 418 pruned. \n",
      "[I 2025-06-05 17:18:25,600] Trial 419 pruned. \n",
      "[I 2025-06-05 17:18:26,810] Trial 420 pruned. \n",
      "[I 2025-06-05 17:18:29,171] Trial 421 finished with value: 0.16967592417978639 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007902839730549688, 'weightDecay': 2.8232965917215532e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:18:31,194] Trial 422 pruned. \n",
      "[I 2025-06-05 17:18:31,446] Trial 423 pruned. \n",
      "[I 2025-06-05 17:18:32,466] Trial 424 pruned. \n",
      "[I 2025-06-05 17:18:35,388] Trial 425 pruned. \n",
      "[I 2025-06-05 17:18:36,031] Trial 426 pruned. \n",
      "[I 2025-06-05 17:18:38,998] Trial 427 pruned. \n",
      "[I 2025-06-05 17:18:41,047] Trial 428 pruned. \n",
      "[I 2025-06-05 17:18:41,530] Trial 429 pruned. \n",
      "[I 2025-06-05 17:18:47,495] Trial 430 finished with value: 0.16904365607547417 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009127814070105832, 'weightDecay': 2.859441965123033e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:18:48,225] Trial 431 pruned. \n",
      "[I 2025-06-05 17:18:49,059] Trial 432 pruned. \n",
      "[I 2025-06-05 17:18:56,140] Trial 433 finished with value: 0.16704582135169516 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009025922587611137, 'weightDecay': 3.3243642457191965e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:18:56,518] Trial 434 pruned. \n",
      "[I 2025-06-05 17:18:57,811] Trial 435 pruned. \n",
      "[I 2025-06-05 17:19:02,739] Trial 436 finished with value: 0.17042426759585577 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00731796915990338, 'weightDecay': 2.753830223977301e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:19:03,504] Trial 437 pruned. \n",
      "[I 2025-06-05 17:19:03,873] Trial 438 pruned. \n",
      "[I 2025-06-05 17:19:04,514] Trial 439 pruned. \n",
      "[I 2025-06-05 17:19:06,583] Trial 440 pruned. \n",
      "[I 2025-06-05 17:19:13,297] Trial 441 finished with value: 0.16782503776817115 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008327519916505682, 'weightDecay': 3.382072187928149e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:19:15,427] Trial 442 pruned. \n",
      "[I 2025-06-05 17:19:16,147] Trial 443 pruned. \n",
      "[I 2025-06-05 17:19:18,195] Trial 444 pruned. \n",
      "[I 2025-06-05 17:19:23,567] Trial 445 finished with value: 0.16932852797559883 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 64, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008475460598374054, 'weightDecay': 3.2369450957759295e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:19:24,665] Trial 446 pruned. \n",
      "[I 2025-06-05 17:19:25,736] Trial 447 pruned. \n",
      "[I 2025-06-05 17:19:26,166] Trial 448 pruned. \n",
      "[I 2025-06-05 17:19:27,256] Trial 449 pruned. \n",
      "[I 2025-06-05 17:19:28,338] Trial 450 pruned. \n",
      "[I 2025-06-05 17:19:35,707] Trial 451 finished with value: 0.16737214440903508 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 256, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009141812916168593, 'weightDecay': 5.3779885631608226e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:19:38,950] Trial 452 pruned. \n",
      "[I 2025-06-05 17:19:39,458] Trial 453 pruned. \n",
      "[I 2025-06-05 17:19:40,312] Trial 454 pruned. \n",
      "[I 2025-06-05 17:19:42,434] Trial 455 pruned. \n",
      "[I 2025-06-05 17:19:47,517] Trial 456 finished with value: 0.16912275364467813 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 256, 'hiddenUnit2': 64, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008089241859320768, 'weightDecay': 4.171338449919953e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:19:48,602] Trial 457 pruned. \n",
      "[I 2025-06-05 17:19:50,560] Trial 458 pruned. \n",
      "[I 2025-06-05 17:19:51,585] Trial 459 pruned. \n",
      "[I 2025-06-05 17:19:52,571] Trial 460 pruned. \n",
      "[I 2025-06-05 17:19:53,727] Trial 461 pruned. \n",
      "[I 2025-06-05 17:19:54,006] Trial 462 pruned. \n",
      "[I 2025-06-05 17:19:55,970] Trial 463 pruned. \n",
      "[I 2025-06-05 17:19:56,544] Trial 464 pruned. \n",
      "[I 2025-06-05 17:19:56,856] Trial 465 pruned. \n",
      "[I 2025-06-05 17:19:57,848] Trial 466 pruned. \n",
      "[I 2025-06-05 17:20:03,539] Trial 467 finished with value: 0.16652550545625308 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009007540046989226, 'weightDecay': 3.55702841088609e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:20:06,585] Trial 468 pruned. \n",
      "[I 2025-06-05 17:20:13,143] Trial 469 finished with value: 0.16621561617412292 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009063113031199922, 'weightDecay': 3.549148268150007e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:20:14,145] Trial 470 pruned. \n",
      "[I 2025-06-05 17:20:18,797] Trial 471 finished with value: 0.16802061965104045 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00918521298677336, 'weightDecay': 2.6431058035890355e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:20:19,761] Trial 472 pruned. \n",
      "[I 2025-06-05 17:20:21,674] Trial 473 pruned. \n",
      "[I 2025-06-05 17:20:22,641] Trial 474 pruned. \n",
      "[I 2025-06-05 17:20:23,245] Trial 475 pruned. \n",
      "[I 2025-06-05 17:20:23,499] Trial 476 pruned. \n",
      "[I 2025-06-05 17:20:24,501] Trial 477 pruned. \n",
      "[I 2025-06-05 17:20:24,936] Trial 478 pruned. \n",
      "[I 2025-06-05 17:20:26,851] Trial 479 pruned. \n",
      "[I 2025-06-05 17:20:27,155] Trial 480 pruned. \n",
      "[I 2025-06-05 17:20:32,701] Trial 481 finished with value: 0.16659580176487726 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 256, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008511970942806178, 'weightDecay': 3.0325901256163458e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:20:33,736] Trial 482 pruned. \n",
      "[I 2025-06-05 17:20:34,895] Trial 483 pruned. \n",
      "[I 2025-06-05 17:20:35,911] Trial 484 pruned. \n",
      "[I 2025-06-05 17:20:36,936] Trial 485 pruned. \n",
      "[I 2025-06-05 17:20:37,941] Trial 486 pruned. \n",
      "[I 2025-06-05 17:20:38,926] Trial 487 pruned. \n",
      "[I 2025-06-05 17:20:41,789] Trial 488 pruned. \n",
      "[I 2025-06-05 17:20:42,127] Trial 489 pruned. \n",
      "[I 2025-06-05 17:20:44,073] Trial 490 pruned. \n",
      "[I 2025-06-05 17:20:46,008] Trial 491 pruned. \n",
      "[I 2025-06-05 17:20:48,940] Trial 492 finished with value: 0.16897886813977994 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007772707713967108, 'weightDecay': 2.1382155471205564e-05, 'batchSize': 32, 'epochs': 3, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:20:49,937] Trial 493 pruned. \n",
      "[I 2025-06-05 17:20:50,938] Trial 494 pruned. \n",
      "[I 2025-06-05 17:20:53,770] Trial 495 pruned. \n",
      "[I 2025-06-05 17:20:59,330] Trial 496 finished with value: 0.169840516488905 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007129581773694087, 'weightDecay': 3.0829886244669806e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:21:02,165] Trial 497 pruned. \n",
      "[I 2025-06-05 17:21:03,171] Trial 498 pruned. \n",
      "[I 2025-06-05 17:21:03,877] Trial 499 pruned. \n",
      "[I 2025-06-05 17:21:05,810] Trial 500 pruned. \n",
      "[I 2025-06-05 17:21:06,001] Trial 501 pruned. \n",
      "[I 2025-06-05 17:21:06,435] Trial 502 pruned. \n",
      "[I 2025-06-05 17:21:07,425] Trial 503 pruned. \n",
      "[I 2025-06-05 17:21:08,402] Trial 504 pruned. \n",
      "[I 2025-06-05 17:21:08,734] Trial 505 pruned. \n",
      "[I 2025-06-05 17:21:09,883] Trial 506 pruned. \n",
      "[I 2025-06-05 17:21:16,455] Trial 507 finished with value: 0.16910006079002407 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 256, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.00803392835075141, 'weightDecay': 2.26983984827959e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:21:17,051] Trial 508 pruned. \n",
      "[I 2025-06-05 17:21:18,063] Trial 509 pruned. \n",
      "[I 2025-06-05 17:21:19,037] Trial 510 pruned. \n",
      "[I 2025-06-05 17:21:20,021] Trial 511 pruned. \n",
      "[I 2025-06-05 17:21:22,860] Trial 512 pruned. \n",
      "[I 2025-06-05 17:21:23,255] Trial 513 pruned. \n",
      "[I 2025-06-05 17:21:23,590] Trial 514 pruned. \n",
      "[I 2025-06-05 17:21:24,731] Trial 515 pruned. \n",
      "[I 2025-06-05 17:21:26,657] Trial 516 pruned. \n",
      "[I 2025-06-05 17:21:27,545] Trial 517 pruned. \n",
      "[I 2025-06-05 17:21:29,656] Trial 518 pruned. \n",
      "[I 2025-06-05 17:21:30,643] Trial 519 pruned. \n",
      "[I 2025-06-05 17:21:31,033] Trial 520 pruned. \n",
      "[I 2025-06-05 17:21:32,011] Trial 521 pruned. \n",
      "[I 2025-06-05 17:21:32,636] Trial 522 pruned. \n",
      "[I 2025-06-05 17:21:32,901] Trial 523 pruned. \n",
      "[I 2025-06-05 17:21:33,693] Trial 524 pruned. \n",
      "[I 2025-06-05 17:21:34,719] Trial 525 pruned. \n",
      "[I 2025-06-05 17:21:35,903] Trial 526 pruned. \n",
      "[I 2025-06-05 17:21:36,363] Trial 527 pruned. \n",
      "[I 2025-06-05 17:21:36,866] Trial 528 pruned. \n",
      "[I 2025-06-05 17:21:37,219] Trial 529 pruned. \n",
      "[I 2025-06-05 17:21:38,228] Trial 530 pruned. \n",
      "[I 2025-06-05 17:21:39,253] Trial 531 pruned. \n",
      "[I 2025-06-05 17:21:40,016] Trial 532 pruned. \n",
      "[I 2025-06-05 17:21:41,035] Trial 533 pruned. \n",
      "[I 2025-06-05 17:21:42,074] Trial 534 pruned. \n",
      "[I 2025-06-05 17:21:42,716] Trial 535 pruned. \n",
      "[I 2025-06-05 17:21:43,847] Trial 536 pruned. \n",
      "[I 2025-06-05 17:21:44,192] Trial 537 pruned. \n",
      "[I 2025-06-05 17:21:45,223] Trial 538 pruned. \n",
      "[I 2025-06-05 17:21:47,105] Trial 539 finished with value: 0.16690272297239475 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009960930307975105, 'weightDecay': 3.254463773476767e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:21:48,138] Trial 540 pruned. \n",
      "[I 2025-06-05 17:21:48,553] Trial 541 pruned. \n",
      "[I 2025-06-05 17:21:53,374] Trial 542 finished with value: 0.1699042864654899 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009998918220212327, 'weightDecay': 2.3374082847482398e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:21:54,192] Trial 543 pruned. \n",
      "[I 2025-06-05 17:21:54,675] Trial 544 pruned. \n",
      "[I 2025-06-05 17:21:55,350] Trial 545 pruned. \n",
      "[I 2025-06-05 17:22:01,179] Trial 546 finished with value: 0.16770107269502288 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009993465184356395, 'weightDecay': 2.469779143791e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:22:01,840] Trial 547 pruned. \n",
      "[I 2025-06-05 17:22:02,170] Trial 548 pruned. \n",
      "[I 2025-06-05 17:22:02,627] Trial 549 pruned. \n",
      "[I 2025-06-05 17:22:03,821] Trial 550 pruned. \n",
      "[I 2025-06-05 17:22:05,853] Trial 551 pruned. \n",
      "[I 2025-06-05 17:22:06,076] Trial 552 pruned. \n",
      "[I 2025-06-05 17:22:09,114] Trial 553 pruned. \n",
      "[I 2025-06-05 17:22:10,214] Trial 554 pruned. \n",
      "[I 2025-06-05 17:22:13,065] Trial 555 finished with value: 0.1693559075413198 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 256, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009973343808565937, 'weightDecay': 2.6293519889789236e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:22:13,458] Trial 556 pruned. \n",
      "[I 2025-06-05 17:22:14,312] Trial 557 pruned. \n",
      "[I 2025-06-05 17:22:16,427] Trial 558 pruned. \n",
      "[I 2025-06-05 17:22:17,553] Trial 559 pruned. \n",
      "[I 2025-06-05 17:22:18,024] Trial 560 pruned. \n",
      "[I 2025-06-05 17:22:19,095] Trial 561 pruned. \n",
      "[I 2025-06-05 17:22:19,455] Trial 562 pruned. \n",
      "[I 2025-06-05 17:22:25,413] Trial 563 finished with value: 0.16629329872475634 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 64, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00894372136419434, 'weightDecay': 4.614982886980632e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:22:25,838] Trial 564 pruned. \n",
      "[I 2025-06-05 17:22:28,762] Trial 565 finished with value: 0.16874711586680222 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 256, 'hiddenUnit2': 80, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007754088694665483, 'weightDecay': 2.0631263868409134e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:22:29,573] Trial 566 pruned. \n",
      "[I 2025-06-05 17:22:30,591] Trial 567 pruned. \n",
      "[I 2025-06-05 17:22:31,074] Trial 568 pruned. \n",
      "[I 2025-06-05 17:22:32,207] Trial 569 pruned. \n",
      "[I 2025-06-05 17:22:33,325] Trial 570 pruned. \n",
      "[I 2025-06-05 17:22:33,787] Trial 571 pruned. \n",
      "[I 2025-06-05 17:22:34,573] Trial 572 pruned. \n",
      "[I 2025-06-05 17:22:37,656] Trial 573 pruned. \n",
      "[I 2025-06-05 17:22:38,343] Trial 574 pruned. \n",
      "[I 2025-06-05 17:22:38,665] Trial 575 pruned. \n",
      "[I 2025-06-05 17:22:39,115] Trial 576 pruned. \n",
      "[I 2025-06-05 17:22:41,213] Trial 577 pruned. \n",
      "[I 2025-06-05 17:22:43,309] Trial 578 pruned. \n",
      "[I 2025-06-05 17:22:43,544] Trial 579 pruned. \n",
      "[I 2025-06-05 17:22:44,571] Trial 580 pruned. \n",
      "[I 2025-06-05 17:22:45,626] Trial 581 pruned. \n",
      "[I 2025-06-05 17:22:45,956] Trial 582 pruned. \n",
      "[I 2025-06-05 17:22:46,384] Trial 583 pruned. \n",
      "[I 2025-06-05 17:22:47,383] Trial 584 pruned. \n",
      "[I 2025-06-05 17:22:50,781] Trial 585 finished with value: 0.16723442039980355 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 240, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007359013121192714, 'weightDecay': 4.602621723667067e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 229 with value: 0.16586360507493414.\n",
      "[I 2025-06-05 17:22:51,477] Trial 586 pruned. \n",
      "[I 2025-06-05 17:22:55,487] Trial 587 finished with value: 0.1653921995244732 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 240, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00859760754531183, 'weightDecay': 5.9852669423916286e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:22:55,709] Trial 588 pruned. \n",
      "[I 2025-06-05 17:22:56,346] Trial 589 pruned. \n",
      "[I 2025-06-05 17:22:57,010] Trial 590 pruned. \n",
      "[I 2025-06-05 17:22:57,643] Trial 591 pruned. \n",
      "[I 2025-06-05 17:22:58,281] Trial 592 pruned. \n",
      "[I 2025-06-05 17:22:58,939] Trial 593 pruned. \n",
      "[I 2025-06-05 17:22:59,558] Trial 594 pruned. \n",
      "[I 2025-06-05 17:23:00,295] Trial 595 pruned. \n",
      "[I 2025-06-05 17:23:00,972] Trial 596 pruned. \n",
      "[I 2025-06-05 17:23:01,368] Trial 597 pruned. \n",
      "[I 2025-06-05 17:23:01,968] Trial 598 pruned. \n",
      "[I 2025-06-05 17:23:02,624] Trial 599 pruned. \n",
      "[I 2025-06-05 17:23:03,306] Trial 600 pruned. \n",
      "[I 2025-06-05 17:23:03,628] Trial 601 pruned. \n",
      "[I 2025-06-05 17:23:04,306] Trial 602 pruned. \n",
      "[I 2025-06-05 17:23:04,962] Trial 603 pruned. \n",
      "[I 2025-06-05 17:23:05,615] Trial 604 pruned. \n",
      "[I 2025-06-05 17:23:06,257] Trial 605 pruned. \n",
      "[I 2025-06-05 17:23:06,687] Trial 606 pruned. \n",
      "[I 2025-06-05 17:23:07,324] Trial 607 pruned. \n",
      "[I 2025-06-05 17:23:07,737] Trial 608 pruned. \n",
      "[I 2025-06-05 17:23:08,178] Trial 609 pruned. \n",
      "[I 2025-06-05 17:23:08,641] Trial 610 pruned. \n",
      "[I 2025-06-05 17:23:09,079] Trial 611 pruned. \n",
      "[I 2025-06-05 17:23:09,382] Trial 612 pruned. \n",
      "[I 2025-06-05 17:23:10,159] Trial 613 pruned. \n",
      "[I 2025-06-05 17:23:11,385] Trial 614 pruned. \n",
      "[I 2025-06-05 17:23:12,606] Trial 615 pruned. \n",
      "[I 2025-06-05 17:23:12,952] Trial 616 pruned. \n",
      "[I 2025-06-05 17:23:13,685] Trial 617 pruned. \n",
      "[I 2025-06-05 17:23:14,094] Trial 618 pruned. \n",
      "[I 2025-06-05 17:23:15,011] Trial 619 pruned. \n",
      "[I 2025-06-05 17:23:16,856] Trial 620 pruned. \n",
      "[I 2025-06-05 17:23:17,333] Trial 621 pruned. \n",
      "[I 2025-06-05 17:23:17,693] Trial 622 pruned. \n",
      "[I 2025-06-05 17:23:18,396] Trial 623 pruned. \n",
      "[I 2025-06-05 17:23:19,665] Trial 624 pruned. \n",
      "[I 2025-06-05 17:23:19,939] Trial 625 pruned. \n",
      "[I 2025-06-05 17:23:26,128] Trial 626 finished with value: 0.1694746027677068 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.0083041373783323, 'weightDecay': 3.164256479544562e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:23:26,514] Trial 627 pruned. \n",
      "[I 2025-06-05 17:23:27,255] Trial 628 pruned. \n",
      "[I 2025-06-05 17:23:28,357] Trial 629 pruned. \n",
      "[I 2025-06-05 17:23:28,835] Trial 630 pruned. \n",
      "[I 2025-06-05 17:23:29,959] Trial 631 pruned. \n",
      "[I 2025-06-05 17:23:30,765] Trial 632 pruned. \n",
      "[I 2025-06-05 17:23:31,219] Trial 633 pruned. \n",
      "[I 2025-06-05 17:23:35,759] Trial 634 finished with value: 0.16789787173916718 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009428963316366426, 'weightDecay': 5.4760550751409564e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:23:37,173] Trial 635 finished with value: 0.16949634598265487 and parameters: {'embeddingDim': 64, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007319438178082337, 'weightDecay': 2.9778274593607237e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:23:37,535] Trial 636 pruned. \n",
      "[I 2025-06-05 17:23:37,978] Trial 637 pruned. \n",
      "[I 2025-06-05 17:23:39,945] Trial 638 pruned. \n",
      "[I 2025-06-05 17:23:41,147] Trial 639 pruned. \n",
      "[I 2025-06-05 17:23:41,776] Trial 640 pruned. \n",
      "[I 2025-06-05 17:23:42,210] Trial 641 pruned. \n",
      "[I 2025-06-05 17:23:43,274] Trial 642 pruned. \n",
      "[I 2025-06-05 17:23:45,281] Trial 643 pruned. \n",
      "[I 2025-06-05 17:23:46,062] Trial 644 pruned. \n",
      "[I 2025-06-05 17:23:46,708] Trial 645 pruned. \n",
      "[I 2025-06-05 17:23:47,354] Trial 646 pruned. \n",
      "[I 2025-06-05 17:23:48,373] Trial 647 pruned. \n",
      "[I 2025-06-05 17:23:48,811] Trial 648 pruned. \n",
      "[I 2025-06-05 17:23:49,832] Trial 649 pruned. \n",
      "[I 2025-06-05 17:23:50,660] Trial 650 pruned. \n",
      "[I 2025-06-05 17:23:51,091] Trial 651 pruned. \n",
      "[I 2025-06-05 17:23:52,283] Trial 652 pruned. \n",
      "[I 2025-06-05 17:23:53,331] Trial 653 pruned. \n",
      "[I 2025-06-05 17:23:54,356] Trial 654 pruned. \n",
      "[I 2025-06-05 17:23:54,617] Trial 655 pruned. \n",
      "[I 2025-06-05 17:23:55,063] Trial 656 pruned. \n",
      "[I 2025-06-05 17:24:00,804] Trial 657 finished with value: 0.16847485201668652 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009983926342211544, 'weightDecay': 3.606399816975486e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:24:02,021] Trial 658 pruned. \n",
      "[I 2025-06-05 17:24:03,040] Trial 659 pruned. \n",
      "[I 2025-06-05 17:24:03,477] Trial 660 pruned. \n",
      "[I 2025-06-05 17:24:03,653] Trial 661 pruned. \n",
      "[I 2025-06-05 17:24:04,713] Trial 662 pruned. \n",
      "[I 2025-06-05 17:24:06,692] Trial 663 pruned. \n",
      "[I 2025-06-05 17:24:07,500] Trial 664 pruned. \n",
      "[I 2025-06-05 17:24:08,153] Trial 665 pruned. \n",
      "[I 2025-06-05 17:24:11,274] Trial 666 pruned. \n",
      "[I 2025-06-05 17:24:12,135] Trial 667 pruned. \n",
      "[I 2025-06-05 17:24:13,186] Trial 668 pruned. \n",
      "[I 2025-06-05 17:24:14,223] Trial 669 pruned. \n",
      "[I 2025-06-05 17:24:14,651] Trial 670 pruned. \n",
      "[I 2025-06-05 17:24:15,078] Trial 671 pruned. \n",
      "[I 2025-06-05 17:24:16,116] Trial 672 pruned. \n",
      "[I 2025-06-05 17:24:16,576] Trial 673 pruned. \n",
      "[I 2025-06-05 17:24:17,037] Trial 674 pruned. \n",
      "[I 2025-06-05 17:24:19,052] Trial 675 pruned. \n",
      "[I 2025-06-05 17:24:20,882] Trial 676 pruned. \n",
      "[I 2025-06-05 17:24:21,618] Trial 677 pruned. \n",
      "[I 2025-06-05 17:24:22,063] Trial 678 pruned. \n",
      "[I 2025-06-05 17:24:24,047] Trial 679 pruned. \n",
      "[I 2025-06-05 17:24:25,111] Trial 680 pruned. \n",
      "[I 2025-06-05 17:24:25,571] Trial 681 pruned. \n",
      "[I 2025-06-05 17:24:25,881] Trial 682 pruned. \n",
      "[I 2025-06-05 17:24:26,605] Trial 683 pruned. \n",
      "[I 2025-06-05 17:24:29,538] Trial 684 pruned. \n",
      "[I 2025-06-05 17:24:30,558] Trial 685 pruned. \n",
      "[I 2025-06-05 17:24:30,764] Trial 686 pruned. \n",
      "[I 2025-06-05 17:24:31,381] Trial 687 pruned. \n",
      "[I 2025-06-05 17:24:34,293] Trial 688 pruned. \n",
      "[I 2025-06-05 17:24:34,923] Trial 689 pruned. \n",
      "[I 2025-06-05 17:24:36,937] Trial 690 pruned. \n",
      "[I 2025-06-05 17:24:37,389] Trial 691 pruned. \n",
      "[I 2025-06-05 17:24:38,433] Trial 692 pruned. \n",
      "[I 2025-06-05 17:24:38,723] Trial 693 pruned. \n",
      "[I 2025-06-05 17:24:40,735] Trial 694 pruned. \n",
      "[I 2025-06-05 17:24:41,378] Trial 695 pruned. \n",
      "[I 2025-06-05 17:24:42,406] Trial 696 pruned. \n",
      "[I 2025-06-05 17:24:42,866] Trial 697 pruned. \n",
      "[I 2025-06-05 17:24:43,255] Trial 698 pruned. \n",
      "[I 2025-06-05 17:24:45,280] Trial 699 pruned. \n",
      "[I 2025-06-05 17:24:47,042] Trial 700 pruned. \n",
      "[I 2025-06-05 17:24:47,508] Trial 701 pruned. \n",
      "[I 2025-06-05 17:24:48,602] Trial 702 pruned. \n",
      "[I 2025-06-05 17:24:49,649] Trial 703 pruned. \n",
      "[I 2025-06-05 17:24:50,467] Trial 704 pruned. \n",
      "[I 2025-06-05 17:24:51,687] Trial 705 pruned. \n",
      "[I 2025-06-05 17:24:52,322] Trial 706 pruned. \n",
      "[I 2025-06-05 17:24:53,360] Trial 707 pruned. \n",
      "[I 2025-06-05 17:24:53,677] Trial 708 pruned. \n",
      "[I 2025-06-05 17:24:53,861] Trial 709 pruned. \n",
      "[I 2025-06-05 17:24:54,910] Trial 710 pruned. \n",
      "[I 2025-06-05 17:24:55,954] Trial 711 pruned. \n",
      "[I 2025-06-05 17:24:56,603] Trial 712 pruned. \n",
      "[I 2025-06-05 17:24:57,428] Trial 713 pruned. \n",
      "[I 2025-06-05 17:24:57,779] Trial 714 pruned. \n",
      "[I 2025-06-05 17:24:58,819] Trial 715 pruned. \n",
      "[I 2025-06-05 17:24:59,887] Trial 716 pruned. \n",
      "[I 2025-06-05 17:25:00,350] Trial 717 pruned. \n",
      "[I 2025-06-05 17:25:00,743] Trial 718 pruned. \n",
      "[I 2025-06-05 17:25:01,853] Trial 719 pruned. \n",
      "[I 2025-06-05 17:25:02,217] Trial 720 pruned. \n",
      "[I 2025-06-05 17:25:04,283] Trial 721 pruned. \n",
      "[I 2025-06-05 17:25:05,436] Trial 722 pruned. \n",
      "[I 2025-06-05 17:25:05,671] Trial 723 pruned. \n",
      "[I 2025-06-05 17:25:06,293] Trial 724 pruned. \n",
      "[I 2025-06-05 17:25:08,274] Trial 725 pruned. \n",
      "[I 2025-06-05 17:25:09,320] Trial 726 pruned. \n",
      "[I 2025-06-05 17:25:09,827] Trial 727 pruned. \n",
      "[I 2025-06-05 17:25:10,872] Trial 728 pruned. \n",
      "[I 2025-06-05 17:25:11,534] Trial 729 pruned. \n",
      "[I 2025-06-05 17:25:13,502] Trial 730 pruned. \n",
      "[I 2025-06-05 17:25:14,317] Trial 731 pruned. \n",
      "[I 2025-06-05 17:25:17,216] Trial 732 pruned. \n",
      "[I 2025-06-05 17:25:17,554] Trial 733 pruned. \n",
      "[I 2025-06-05 17:25:18,609] Trial 734 pruned. \n",
      "[I 2025-06-05 17:25:18,813] Trial 735 pruned. \n",
      "[I 2025-06-05 17:25:21,711] Trial 736 finished with value: 0.1686781178958149 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 240, 'hiddenUnit2': 64, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007276537069109225, 'weightDecay': 3.752151826698888e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:25:22,732] Trial 737 pruned. \n",
      "[I 2025-06-05 17:25:23,785] Trial 738 pruned. \n",
      "[I 2025-06-05 17:25:24,231] Trial 739 pruned. \n",
      "[I 2025-06-05 17:25:24,631] Trial 740 pruned. \n",
      "[I 2025-06-05 17:25:25,697] Trial 741 pruned. \n",
      "[I 2025-06-05 17:25:26,045] Trial 742 pruned. \n",
      "[I 2025-06-05 17:25:27,107] Trial 743 pruned. \n",
      "[I 2025-06-05 17:25:27,558] Trial 744 pruned. \n",
      "[I 2025-06-05 17:25:29,542] Trial 745 pruned. \n",
      "[I 2025-06-05 17:25:29,785] Trial 746 pruned. \n",
      "[I 2025-06-05 17:25:37,345] Trial 747 finished with value: 0.16656759827791137 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.009198881809701052, 'weightDecay': 4.9580942022724925e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:25:38,401] Trial 748 pruned. \n",
      "[I 2025-06-05 17:25:39,449] Trial 749 pruned. \n",
      "[I 2025-06-05 17:25:40,660] Trial 750 pruned. \n",
      "[I 2025-06-05 17:25:41,696] Trial 751 pruned. \n",
      "[I 2025-06-05 17:25:43,632] Trial 752 pruned. \n",
      "[I 2025-06-05 17:25:45,608] Trial 753 pruned. \n",
      "[I 2025-06-05 17:25:47,613] Trial 754 pruned. \n",
      "[I 2025-06-05 17:25:52,419] Trial 755 finished with value: 0.1697489780639483 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 176, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.0084777672259427, 'weightDecay': 3.286702706446249e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:25:53,455] Trial 756 pruned. \n",
      "[I 2025-06-05 17:25:54,492] Trial 757 pruned. \n",
      "[I 2025-06-05 17:25:54,858] Trial 758 pruned. \n",
      "[I 2025-06-05 17:25:55,899] Trial 759 pruned. \n",
      "[I 2025-06-05 17:25:56,950] Trial 760 pruned. \n",
      "[I 2025-06-05 17:25:57,591] Trial 761 pruned. \n",
      "[I 2025-06-05 17:25:58,654] Trial 762 pruned. \n",
      "[I 2025-06-05 17:25:59,706] Trial 763 pruned. \n",
      "[I 2025-06-05 17:26:01,733] Trial 764 pruned. \n",
      "[I 2025-06-05 17:26:02,209] Trial 765 pruned. \n",
      "[I 2025-06-05 17:26:03,252] Trial 766 pruned. \n",
      "[I 2025-06-05 17:26:04,301] Trial 767 pruned. \n",
      "[I 2025-06-05 17:26:04,976] Trial 768 pruned. \n",
      "[I 2025-06-05 17:26:05,316] Trial 769 pruned. \n",
      "[I 2025-06-05 17:26:05,968] Trial 770 pruned. \n",
      "[I 2025-06-05 17:26:06,417] Trial 771 pruned. \n",
      "[I 2025-06-05 17:26:07,643] Trial 772 pruned. \n",
      "[I 2025-06-05 17:26:08,679] Trial 773 pruned. \n",
      "[I 2025-06-05 17:26:09,028] Trial 774 pruned. \n",
      "[I 2025-06-05 17:26:10,237] Trial 775 pruned. \n",
      "[I 2025-06-05 17:26:14,990] Trial 776 finished with value: 0.1680714141052983 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 128, 'hiddenUnit2': 64, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009258976941153834, 'weightDecay': 2.198575672772905e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:26:16,025] Trial 777 pruned. \n",
      "[I 2025-06-05 17:26:17,076] Trial 778 pruned. \n",
      "[I 2025-06-05 17:26:18,840] Trial 779 pruned. \n",
      "[I 2025-06-05 17:26:19,899] Trial 780 pruned. \n",
      "[I 2025-06-05 17:26:20,973] Trial 781 pruned. \n",
      "[I 2025-06-05 17:26:21,341] Trial 782 pruned. \n",
      "[I 2025-06-05 17:26:22,500] Trial 783 pruned. \n",
      "[I 2025-06-05 17:26:23,529] Trial 784 pruned. \n",
      "[I 2025-06-05 17:26:25,562] Trial 785 pruned. \n",
      "[I 2025-06-05 17:26:26,633] Trial 786 pruned. \n",
      "[I 2025-06-05 17:26:27,292] Trial 787 pruned. \n",
      "[I 2025-06-05 17:26:28,057] Trial 788 pruned. \n",
      "[I 2025-06-05 17:26:29,327] Trial 789 finished with value: 0.1701665196285351 and parameters: {'embeddingDim': 32, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009257572351114414, 'weightDecay': 4.0969284709968865e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:26:31,325] Trial 790 pruned. \n",
      "[I 2025-06-05 17:26:32,361] Trial 791 pruned. \n",
      "[I 2025-06-05 17:26:33,025] Trial 792 pruned. \n",
      "[I 2025-06-05 17:26:34,201] Trial 793 pruned. \n",
      "[I 2025-06-05 17:26:34,599] Trial 794 pruned. \n",
      "[I 2025-06-05 17:26:35,069] Trial 795 pruned. \n",
      "[I 2025-06-05 17:26:36,122] Trial 796 pruned. \n",
      "[I 2025-06-05 17:26:41,003] Trial 797 finished with value: 0.16830358355699462 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.009067356555265763, 'weightDecay': 3.2160314697234096e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:26:41,668] Trial 798 pruned. \n",
      "[I 2025-06-05 17:26:42,690] Trial 799 pruned. \n",
      "[I 2025-06-05 17:26:43,735] Trial 800 pruned. \n",
      "[I 2025-06-05 17:26:44,790] Trial 801 pruned. \n",
      "[I 2025-06-05 17:26:45,251] Trial 802 pruned. \n",
      "[I 2025-06-05 17:26:45,926] Trial 803 pruned. \n",
      "[I 2025-06-05 17:26:46,984] Trial 804 pruned. \n",
      "[I 2025-06-05 17:26:52,761] Trial 805 finished with value: 0.16816044897378998 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 64, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.006511973813905748, 'weightDecay': 5.5817873099237505e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:26:52,961] Trial 806 pruned. \n",
      "[I 2025-06-05 17:26:57,759] Trial 807 finished with value: 0.16961633481273583 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 80, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008585134679804336, 'weightDecay': 3.8914688919125354e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:26:58,242] Trial 808 pruned. \n",
      "[I 2025-06-05 17:26:59,307] Trial 809 pruned. \n",
      "[I 2025-06-05 17:26:59,771] Trial 810 pruned. \n",
      "[I 2025-06-05 17:27:00,152] Trial 811 pruned. \n",
      "[I 2025-06-05 17:27:01,271] Trial 812 pruned. \n",
      "[I 2025-06-05 17:27:02,370] Trial 813 pruned. \n",
      "[I 2025-06-05 17:27:03,037] Trial 814 pruned. \n",
      "[I 2025-06-05 17:27:03,593] Trial 815 pruned. \n",
      "[I 2025-06-05 17:27:04,656] Trial 816 pruned. \n",
      "[I 2025-06-05 17:27:05,317] Trial 817 pruned. \n",
      "[I 2025-06-05 17:27:05,699] Trial 818 pruned. \n",
      "[I 2025-06-05 17:27:05,958] Trial 819 pruned. \n",
      "[I 2025-06-05 17:27:09,881] Trial 820 finished with value: 0.16778926320024345 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.2, 'learnRate': 0.009024729216671122, 'weightDecay': 5.1335886494036106e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:27:11,621] Trial 821 pruned. \n",
      "[I 2025-06-05 17:27:12,689] Trial 822 pruned. \n",
      "[I 2025-06-05 17:27:13,738] Trial 823 pruned. \n",
      "[I 2025-06-05 17:27:14,912] Trial 824 pruned. \n",
      "[I 2025-06-05 17:27:15,973] Trial 825 pruned. \n",
      "[I 2025-06-05 17:27:16,591] Trial 826 pruned. \n",
      "[I 2025-06-05 17:27:17,664] Trial 827 pruned. \n",
      "[I 2025-06-05 17:27:18,470] Trial 828 pruned. \n",
      "[I 2025-06-05 17:27:19,523] Trial 829 pruned. \n",
      "[I 2025-06-05 17:27:19,876] Trial 830 pruned. \n",
      "[I 2025-06-05 17:27:21,102] Trial 831 pruned. \n",
      "[I 2025-06-05 17:27:21,777] Trial 832 pruned. \n",
      "[I 2025-06-05 17:27:23,770] Trial 833 pruned. \n",
      "[I 2025-06-05 17:27:24,810] Trial 834 pruned. \n",
      "[I 2025-06-05 17:27:25,257] Trial 835 pruned. \n",
      "[I 2025-06-05 17:27:27,294] Trial 836 pruned. \n",
      "[I 2025-06-05 17:27:27,709] Trial 837 pruned. \n",
      "[I 2025-06-05 17:27:30,642] Trial 838 pruned. \n",
      "[I 2025-06-05 17:27:31,031] Trial 839 pruned. \n",
      "[I 2025-06-05 17:27:32,063] Trial 840 pruned. \n",
      "[I 2025-06-05 17:27:32,648] Trial 841 pruned. \n",
      "[I 2025-06-05 17:27:33,777] Trial 842 pruned. \n",
      "[I 2025-06-05 17:27:34,157] Trial 843 pruned. \n",
      "[I 2025-06-05 17:27:34,678] Trial 844 pruned. \n",
      "[I 2025-06-05 17:27:35,336] Trial 845 pruned. \n",
      "[I 2025-06-05 17:27:35,855] Trial 846 pruned. \n",
      "[I 2025-06-05 17:27:37,044] Trial 847 pruned. \n",
      "[I 2025-06-05 17:27:38,192] Trial 848 pruned. \n",
      "[I 2025-06-05 17:27:39,222] Trial 849 pruned. \n",
      "[I 2025-06-05 17:27:40,371] Trial 850 pruned. \n",
      "[I 2025-06-05 17:27:41,065] Trial 851 pruned. \n",
      "[I 2025-06-05 17:27:41,896] Trial 852 pruned. \n",
      "[I 2025-06-05 17:27:42,418] Trial 853 pruned. \n",
      "[I 2025-06-05 17:27:43,569] Trial 854 pruned. \n",
      "[I 2025-06-05 17:27:44,701] Trial 855 pruned. \n",
      "[I 2025-06-05 17:27:44,993] Trial 856 pruned. \n",
      "[I 2025-06-05 17:27:46,104] Trial 857 pruned. \n",
      "[I 2025-06-05 17:27:46,621] Trial 858 pruned. \n",
      "[I 2025-06-05 17:27:47,736] Trial 859 pruned. \n",
      "[I 2025-06-05 17:27:48,854] Trial 860 pruned. \n",
      "[I 2025-06-05 17:27:49,448] Trial 861 pruned. \n",
      "[I 2025-06-05 17:27:50,907] Trial 862 pruned. \n",
      "[I 2025-06-05 17:27:52,220] Trial 863 pruned. \n",
      "[I 2025-06-05 17:27:52,507] Trial 864 pruned. \n",
      "[I 2025-06-05 17:27:53,711] Trial 865 pruned. \n",
      "[I 2025-06-05 17:27:54,238] Trial 866 pruned. \n",
      "[I 2025-06-05 17:27:55,330] Trial 867 pruned. \n",
      "[I 2025-06-05 17:27:55,683] Trial 868 pruned. \n",
      "[I 2025-06-05 17:27:57,759] Trial 869 pruned. \n",
      "[I 2025-06-05 17:27:58,157] Trial 870 pruned. \n",
      "[I 2025-06-05 17:27:58,671] Trial 871 pruned. \n",
      "[I 2025-06-05 17:27:59,775] Trial 872 pruned. \n",
      "[I 2025-06-05 17:28:00,909] Trial 873 pruned. \n",
      "[I 2025-06-05 17:28:01,444] Trial 874 pruned. \n",
      "[I 2025-06-05 17:28:03,560] Trial 875 pruned. \n",
      "[I 2025-06-05 17:28:04,042] Trial 876 pruned. \n",
      "[I 2025-06-05 17:28:07,154] Trial 877 pruned. \n",
      "[I 2025-06-05 17:28:08,262] Trial 878 pruned. \n",
      "[I 2025-06-05 17:28:08,489] Trial 879 pruned. \n",
      "[I 2025-06-05 17:28:09,186] Trial 880 pruned. \n",
      "[I 2025-06-05 17:28:10,440] Trial 881 pruned. \n",
      "[I 2025-06-05 17:28:11,517] Trial 882 pruned. \n",
      "[I 2025-06-05 17:28:11,974] Trial 883 pruned. \n",
      "[I 2025-06-05 17:28:18,886] Trial 884 finished with value: 0.16715214877567566 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 80, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.0073684537446831525, 'weightDecay': 7.910637643040474e-05, 'batchSize': 32, 'epochs': 7, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:28:19,961] Trial 885 pruned. \n",
      "[I 2025-06-05 17:28:20,634] Trial 886 pruned. \n",
      "[I 2025-06-05 17:28:21,742] Trial 887 pruned. \n",
      "[I 2025-06-05 17:28:22,074] Trial 888 pruned. \n",
      "[I 2025-06-05 17:28:24,183] Trial 889 pruned. \n",
      "[I 2025-06-05 17:28:25,294] Trial 890 pruned. \n",
      "[I 2025-06-05 17:28:25,808] Trial 891 pruned. \n",
      "[I 2025-06-05 17:28:27,103] Trial 892 pruned. \n",
      "[I 2025-06-05 17:28:27,479] Trial 893 pruned. \n",
      "[I 2025-06-05 17:28:27,956] Trial 894 pruned. \n",
      "[I 2025-06-05 17:28:30,099] Trial 895 pruned. \n",
      "[I 2025-06-05 17:28:30,485] Trial 896 pruned. \n",
      "[I 2025-06-05 17:28:30,875] Trial 897 pruned. \n",
      "[I 2025-06-05 17:28:31,990] Trial 898 pruned. \n",
      "[I 2025-06-05 17:28:33,237] Trial 899 pruned. \n",
      "[I 2025-06-05 17:28:34,351] Trial 900 pruned. \n",
      "[I 2025-06-05 17:28:37,633] Trial 901 pruned. \n",
      "[I 2025-06-05 17:28:38,224] Trial 902 pruned. \n",
      "[I 2025-06-05 17:28:38,720] Trial 903 pruned. \n",
      "[I 2025-06-05 17:28:39,521] Trial 904 pruned. \n",
      "[I 2025-06-05 17:28:40,711] Trial 905 pruned. \n",
      "[I 2025-06-05 17:28:43,055] Trial 906 finished with value: 0.16645703908553622 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009272678473196154, 'weightDecay': 4.3560720581873965e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:28:43,525] Trial 907 pruned. \n",
      "[I 2025-06-05 17:28:43,990] Trial 908 pruned. \n",
      "[I 2025-06-05 17:28:44,448] Trial 909 pruned. \n",
      "[I 2025-06-05 17:28:44,964] Trial 910 pruned. \n",
      "[I 2025-06-05 17:28:45,556] Trial 911 pruned. \n",
      "[I 2025-06-05 17:28:46,212] Trial 912 pruned. \n",
      "[I 2025-06-05 17:28:46,619] Trial 913 pruned. \n",
      "[I 2025-06-05 17:28:47,370] Trial 914 pruned. \n",
      "[I 2025-06-05 17:28:48,119] Trial 915 pruned. \n",
      "[I 2025-06-05 17:28:48,808] Trial 916 pruned. \n",
      "[I 2025-06-05 17:28:49,216] Trial 917 pruned. \n",
      "[I 2025-06-05 17:28:49,894] Trial 918 pruned. \n",
      "[I 2025-06-05 17:28:50,403] Trial 919 pruned. \n",
      "[I 2025-06-05 17:28:51,096] Trial 920 pruned. \n",
      "[I 2025-06-05 17:28:51,740] Trial 921 pruned. \n",
      "[I 2025-06-05 17:28:54,825] Trial 922 finished with value: 0.16704767727249367 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 192, 'hiddenUnit2': 64, 'dropoutRate': 0.4, 'learnRate': 0.008698758941392916, 'weightDecay': 5.219855364076199e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:28:55,357] Trial 923 pruned. \n",
      "[I 2025-06-05 17:28:55,944] Trial 924 pruned. \n",
      "[I 2025-06-05 17:28:56,634] Trial 925 pruned. \n",
      "[I 2025-06-05 17:28:57,435] Trial 926 pruned. \n",
      "[I 2025-06-05 17:28:58,243] Trial 927 pruned. \n",
      "[I 2025-06-05 17:28:59,590] Trial 928 pruned. \n",
      "[I 2025-06-05 17:28:59,828] Trial 929 pruned. \n",
      "[I 2025-06-05 17:29:00,328] Trial 930 pruned. \n",
      "[I 2025-06-05 17:29:00,818] Trial 931 pruned. \n",
      "[I 2025-06-05 17:29:01,516] Trial 932 pruned. \n",
      "[I 2025-06-05 17:29:02,141] Trial 933 pruned. \n",
      "[I 2025-06-05 17:29:03,857] Trial 934 pruned. \n",
      "[I 2025-06-05 17:29:04,404] Trial 935 pruned. \n",
      "[I 2025-06-05 17:29:04,930] Trial 936 pruned. \n",
      "[I 2025-06-05 17:29:05,307] Trial 937 pruned. \n",
      "[I 2025-06-05 17:29:05,924] Trial 938 pruned. \n",
      "[I 2025-06-05 17:29:06,531] Trial 939 pruned. \n",
      "[I 2025-06-05 17:29:07,075] Trial 940 pruned. \n",
      "[I 2025-06-05 17:29:07,309] Trial 941 pruned. \n",
      "[I 2025-06-05 17:29:07,822] Trial 942 pruned. \n",
      "[I 2025-06-05 17:29:08,200] Trial 943 pruned. \n",
      "[I 2025-06-05 17:29:08,719] Trial 944 pruned. \n",
      "[I 2025-06-05 17:29:09,231] Trial 945 pruned. \n",
      "[I 2025-06-05 17:29:09,688] Trial 946 pruned. \n",
      "[I 2025-06-05 17:29:10,193] Trial 947 pruned. \n",
      "[I 2025-06-05 17:29:11,287] Trial 948 pruned. \n",
      "[I 2025-06-05 17:29:12,663] Trial 949 pruned. \n",
      "[I 2025-06-05 17:29:14,222] Trial 950 pruned. \n",
      "[I 2025-06-05 17:29:15,284] Trial 951 pruned. \n",
      "[I 2025-06-05 17:29:15,747] Trial 952 pruned. \n",
      "[I 2025-06-05 17:29:15,958] Trial 953 pruned. \n",
      "[I 2025-06-05 17:29:17,063] Trial 954 pruned. \n",
      "[I 2025-06-05 17:29:18,133] Trial 955 pruned. \n",
      "[I 2025-06-05 17:29:18,585] Trial 956 pruned. \n",
      "[I 2025-06-05 17:29:19,648] Trial 957 pruned. \n",
      "[I 2025-06-05 17:29:20,778] Trial 958 pruned. \n",
      "[I 2025-06-05 17:29:21,290] Trial 959 pruned. \n",
      "[I 2025-06-05 17:29:21,822] Trial 960 pruned. \n",
      "[I 2025-06-05 17:29:22,518] Trial 961 pruned. \n",
      "[I 2025-06-05 17:29:24,673] Trial 962 pruned. \n",
      "[I 2025-06-05 17:29:25,158] Trial 963 pruned. \n",
      "[I 2025-06-05 17:29:25,955] Trial 964 pruned. \n",
      "[I 2025-06-05 17:29:27,517] Trial 965 finished with value: 0.1688333579779532 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.2, 'learnRate': 0.009964058542135506, 'weightDecay': 2.208132653568801e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:29:28,605] Trial 966 pruned. \n",
      "[I 2025-06-05 17:29:29,102] Trial 967 pruned. \n",
      "[I 2025-06-05 17:29:29,538] Trial 968 pruned. \n",
      "[I 2025-06-05 17:29:30,709] Trial 969 pruned. \n",
      "[I 2025-06-05 17:29:32,079] Trial 970 pruned. \n",
      "[I 2025-06-05 17:29:32,979] Trial 971 pruned. \n",
      "[I 2025-06-05 17:29:35,221] Trial 972 pruned. \n",
      "[I 2025-06-05 17:29:35,746] Trial 973 pruned. \n",
      "[I 2025-06-05 17:29:36,833] Trial 974 pruned. \n",
      "[I 2025-06-05 17:29:37,200] Trial 975 pruned. \n",
      "[I 2025-06-05 17:29:38,326] Trial 976 pruned. \n",
      "[I 2025-06-05 17:29:38,585] Trial 977 pruned. \n",
      "[I 2025-06-05 17:29:39,673] Trial 978 pruned. \n",
      "[I 2025-06-05 17:29:42,866] Trial 979 pruned. \n",
      "[I 2025-06-05 17:29:43,314] Trial 980 pruned. \n",
      "[I 2025-06-05 17:29:43,737] Trial 981 pruned. \n",
      "[I 2025-06-05 17:29:44,805] Trial 982 pruned. \n",
      "[I 2025-06-05 17:29:45,607] Trial 983 pruned. \n",
      "[I 2025-06-05 17:29:46,684] Trial 984 pruned. \n",
      "[I 2025-06-05 17:29:47,228] Trial 985 pruned. \n",
      "[I 2025-06-05 17:29:47,697] Trial 986 pruned. \n",
      "[I 2025-06-05 17:29:49,756] Trial 987 pruned. \n",
      "[I 2025-06-05 17:29:50,781] Trial 988 pruned. \n",
      "[I 2025-06-05 17:29:51,269] Trial 989 pruned. \n",
      "[I 2025-06-05 17:29:51,758] Trial 990 pruned. \n",
      "[I 2025-06-05 17:29:52,603] Trial 991 pruned. \n",
      "[I 2025-06-05 17:29:53,829] Trial 992 pruned. \n",
      "[I 2025-06-05 17:29:54,965] Trial 993 pruned. \n",
      "[I 2025-06-05 17:29:55,466] Trial 994 pruned. \n",
      "[I 2025-06-05 17:29:56,560] Trial 995 pruned. \n",
      "[I 2025-06-05 17:29:57,143] Trial 996 pruned. \n",
      "[I 2025-06-05 17:29:58,271] Trial 997 pruned. \n",
      "[I 2025-06-05 17:29:59,700] Trial 998 pruned. \n",
      "[I 2025-06-05 17:30:00,656] Trial 999 pruned. \n",
      "[I 2025-06-05 17:30:01,045] Trial 1000 pruned. \n",
      "[I 2025-06-05 17:30:02,548] Trial 1001 pruned. \n",
      "[I 2025-06-05 17:30:02,977] Trial 1002 pruned. \n",
      "[I 2025-06-05 17:30:03,541] Trial 1003 pruned. \n",
      "[I 2025-06-05 17:30:04,069] Trial 1004 pruned. \n",
      "[I 2025-06-05 17:30:05,472] Trial 1005 pruned. \n",
      "[I 2025-06-05 17:30:06,194] Trial 1006 pruned. \n",
      "[I 2025-06-05 17:30:07,209] Trial 1007 pruned. \n",
      "[I 2025-06-05 17:30:08,422] Trial 1008 pruned. \n",
      "[I 2025-06-05 17:30:08,973] Trial 1009 pruned. \n",
      "[I 2025-06-05 17:30:10,129] Trial 1010 pruned. \n",
      "[I 2025-06-05 17:30:10,885] Trial 1011 pruned. \n",
      "[I 2025-06-05 17:30:11,514] Trial 1012 pruned. \n",
      "[I 2025-06-05 17:30:12,918] Trial 1013 pruned. \n",
      "[I 2025-06-05 17:30:13,251] Trial 1014 pruned. \n",
      "[I 2025-06-05 17:30:14,637] Trial 1015 pruned. \n",
      "[I 2025-06-05 17:30:15,433] Trial 1016 pruned. \n",
      "[I 2025-06-05 17:30:16,660] Trial 1017 pruned. \n",
      "[I 2025-06-05 17:30:17,776] Trial 1018 pruned. \n",
      "[I 2025-06-05 17:30:18,936] Trial 1019 pruned. \n",
      "[I 2025-06-05 17:30:22,025] Trial 1020 pruned. \n",
      "[I 2025-06-05 17:30:22,500] Trial 1021 pruned. \n",
      "[I 2025-06-05 17:30:23,699] Trial 1022 pruned. \n",
      "[I 2025-06-05 17:30:24,237] Trial 1023 pruned. \n",
      "[I 2025-06-05 17:30:24,986] Trial 1024 pruned. \n",
      "[I 2025-06-05 17:30:25,548] Trial 1025 pruned. \n",
      "[I 2025-06-05 17:30:26,715] Trial 1026 pruned. \n",
      "[I 2025-06-05 17:30:27,862] Trial 1027 pruned. \n",
      "[I 2025-06-05 17:30:28,311] Trial 1028 pruned. \n",
      "[I 2025-06-05 17:30:28,544] Trial 1029 pruned. \n",
      "[I 2025-06-05 17:30:29,725] Trial 1030 pruned. \n",
      "[I 2025-06-05 17:30:30,556] Trial 1031 pruned. \n",
      "[I 2025-06-05 17:30:31,859] Trial 1032 pruned. \n",
      "[I 2025-06-05 17:30:32,458] Trial 1033 pruned. \n",
      "[I 2025-06-05 17:30:33,256] Trial 1034 pruned. \n",
      "[I 2025-06-05 17:30:33,865] Trial 1035 pruned. \n",
      "[I 2025-06-05 17:30:35,312] Trial 1036 pruned. \n",
      "[I 2025-06-05 17:30:40,873] Trial 1037 finished with value: 0.1678516301007047 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 144, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009114850707699127, 'weightDecay': 4.264191230886031e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:30:41,175] Trial 1038 pruned. \n",
      "[I 2025-06-05 17:30:42,451] Trial 1039 pruned. \n",
      "[I 2025-06-05 17:30:44,521] Trial 1040 pruned. \n",
      "[I 2025-06-05 17:30:45,748] Trial 1041 pruned. \n",
      "[I 2025-06-05 17:30:46,317] Trial 1042 pruned. \n",
      "[I 2025-06-05 17:30:48,674] Trial 1043 pruned. \n",
      "[I 2025-06-05 17:30:49,243] Trial 1044 pruned. \n",
      "[I 2025-06-05 17:30:54,823] Trial 1045 finished with value: 0.16867872018246013 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.006053424061969515, 'weightDecay': 3.8688283870479457e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:30:55,578] Trial 1046 pruned. \n",
      "[I 2025-06-05 17:30:57,811] Trial 1047 pruned. \n",
      "[I 2025-06-05 17:30:58,190] Trial 1048 pruned. \n",
      "[I 2025-06-05 17:30:58,690] Trial 1049 pruned. \n",
      "[I 2025-06-05 17:30:59,922] Trial 1050 pruned. \n",
      "[I 2025-06-05 17:31:00,290] Trial 1051 pruned. \n",
      "[I 2025-06-05 17:31:00,849] Trial 1052 pruned. \n",
      "[I 2025-06-05 17:31:01,538] Trial 1053 pruned. \n",
      "[I 2025-06-05 17:31:02,594] Trial 1054 pruned. \n",
      "[I 2025-06-05 17:31:03,063] Trial 1055 pruned. \n",
      "[I 2025-06-05 17:31:04,123] Trial 1056 pruned. \n",
      "[I 2025-06-05 17:31:07,177] Trial 1057 pruned. \n",
      "[I 2025-06-05 17:31:07,588] Trial 1058 pruned. \n",
      "[I 2025-06-05 17:31:08,005] Trial 1059 pruned. \n",
      "[I 2025-06-05 17:31:10,065] Trial 1060 pruned. \n",
      "[I 2025-06-05 17:31:11,359] Trial 1061 pruned. \n",
      "[I 2025-06-05 17:31:14,351] Trial 1062 pruned. \n",
      "[I 2025-06-05 17:31:14,599] Trial 1063 pruned. \n",
      "[I 2025-06-05 17:31:15,682] Trial 1064 pruned. \n",
      "[I 2025-06-05 17:31:16,156] Trial 1065 pruned. \n",
      "[I 2025-06-05 17:31:17,237] Trial 1066 pruned. \n",
      "[I 2025-06-05 17:31:22,701] Trial 1067 finished with value: 0.16890051751145388 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.006703913042614376, 'weightDecay': 2.2943060556467125e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:31:26,133] Trial 1068 finished with value: 0.1690931518693263 and parameters: {'embeddingDim': 256, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.007907710833214274, 'weightDecay': 1.576797065726176e-05, 'batchSize': 32, 'epochs': 5, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:31:27,140] Trial 1069 pruned. \n",
      "[I 2025-06-05 17:31:29,668] Trial 1070 pruned. \n",
      "[I 2025-06-05 17:31:31,234] Trial 1071 pruned. \n",
      "[I 2025-06-05 17:31:32,589] Trial 1072 pruned. \n",
      "[I 2025-06-05 17:31:33,010] Trial 1073 pruned. \n",
      "[I 2025-06-05 17:31:33,557] Trial 1074 pruned. \n",
      "[I 2025-06-05 17:31:34,136] Trial 1075 pruned. \n",
      "[I 2025-06-05 17:31:34,820] Trial 1076 pruned. \n",
      "[I 2025-06-05 17:31:36,971] Trial 1077 pruned. \n",
      "[I 2025-06-05 17:31:42,119] Trial 1078 finished with value: 0.16932955782336018 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009994240539726253, 'weightDecay': 2.026130017657503e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:31:42,603] Trial 1079 pruned. \n",
      "[I 2025-06-05 17:31:43,029] Trial 1080 pruned. \n",
      "[I 2025-06-05 17:31:44,142] Trial 1081 pruned. \n",
      "[I 2025-06-05 17:31:44,637] Trial 1082 pruned. \n",
      "[I 2025-06-05 17:31:46,697] Trial 1083 pruned. \n",
      "[I 2025-06-05 17:31:47,151] Trial 1084 pruned. \n",
      "[I 2025-06-05 17:31:48,298] Trial 1085 pruned. \n",
      "[I 2025-06-05 17:31:48,572] Trial 1086 pruned. \n",
      "[I 2025-06-05 17:31:51,622] Trial 1087 pruned. \n",
      "[I 2025-06-05 17:31:52,748] Trial 1088 pruned. \n",
      "[I 2025-06-05 17:31:53,262] Trial 1089 pruned. \n",
      "[I 2025-06-05 17:31:53,939] Trial 1090 pruned. \n",
      "[I 2025-06-05 17:31:55,917] Trial 1091 pruned. \n",
      "[I 2025-06-05 17:31:56,394] Trial 1092 pruned. \n",
      "[I 2025-06-05 17:31:57,492] Trial 1093 pruned. \n",
      "[I 2025-06-05 17:31:58,639] Trial 1094 pruned. \n",
      "[I 2025-06-05 17:31:59,043] Trial 1095 pruned. \n",
      "[I 2025-06-05 17:32:02,261] Trial 1096 pruned. \n",
      "[I 2025-06-05 17:32:02,567] Trial 1097 pruned. \n",
      "[I 2025-06-05 17:32:03,756] Trial 1098 pruned. \n",
      "[I 2025-06-05 17:32:04,246] Trial 1099 pruned. \n",
      "[I 2025-06-05 17:32:04,649] Trial 1100 pruned. \n",
      "[I 2025-06-05 17:32:05,729] Trial 1101 pruned. \n",
      "[I 2025-06-05 17:32:06,271] Trial 1102 pruned. \n",
      "[I 2025-06-05 17:32:07,549] Trial 1103 pruned. \n",
      "[I 2025-06-05 17:32:08,644] Trial 1104 pruned. \n",
      "[I 2025-06-05 17:32:09,324] Trial 1105 pruned. \n",
      "[I 2025-06-05 17:32:09,646] Trial 1106 pruned. \n",
      "[I 2025-06-05 17:32:10,055] Trial 1107 pruned. \n",
      "[I 2025-06-05 17:32:15,225] Trial 1108 finished with value: 0.16946686304002892 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 128, 'hiddenUnit2': 48, 'dropoutRate': 0.4, 'learnRate': 0.008882311690513768, 'weightDecay': 2.7632446397519524e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:32:17,408] Trial 1109 pruned. \n",
      "[I 2025-06-05 17:32:17,708] Trial 1110 pruned. \n",
      "[I 2025-06-05 17:32:21,344] Trial 1111 pruned. \n",
      "[I 2025-06-05 17:32:21,966] Trial 1112 pruned. \n",
      "[I 2025-06-05 17:32:22,782] Trial 1113 pruned. \n",
      "[I 2025-06-05 17:32:24,088] Trial 1114 pruned. \n",
      "[I 2025-06-05 17:32:26,422] Trial 1115 pruned. \n",
      "[I 2025-06-05 17:32:27,546] Trial 1116 pruned. \n",
      "[I 2025-06-05 17:32:30,736] Trial 1117 pruned. \n",
      "[I 2025-06-05 17:32:31,594] Trial 1118 pruned. \n",
      "[I 2025-06-05 17:32:32,247] Trial 1119 pruned. \n",
      "[I 2025-06-05 17:32:33,017] Trial 1120 pruned. \n",
      "[I 2025-06-05 17:32:33,474] Trial 1121 pruned. \n",
      "[I 2025-06-05 17:32:33,954] Trial 1122 pruned. \n",
      "[I 2025-06-05 17:32:36,290] Trial 1123 pruned. \n",
      "[I 2025-06-05 17:32:37,951] Trial 1124 pruned. \n",
      "[I 2025-06-05 17:32:38,431] Trial 1125 pruned. \n",
      "[I 2025-06-05 17:32:39,176] Trial 1126 pruned. \n",
      "[I 2025-06-05 17:32:41,535] Trial 1127 pruned. \n",
      "[I 2025-06-05 17:32:42,403] Trial 1128 pruned. \n",
      "[I 2025-06-05 17:32:44,775] Trial 1129 pruned. \n",
      "[I 2025-06-05 17:32:45,277] Trial 1130 pruned. \n",
      "[I 2025-06-05 17:32:50,693] Trial 1131 finished with value: 0.1696784916444806 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00854490667283369, 'weightDecay': 4.3053467247028885e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:32:53,231] Trial 1132 finished with value: 0.1657924676307272 and parameters: {'embeddingDim': 64, 'hiddenUnit1': 256, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009973088287396, 'weightDecay': 4.994405743288107e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:32:56,113] Trial 1133 finished with value: 0.16852638286804034 and parameters: {'embeddingDim': 64, 'hiddenUnit1': 208, 'hiddenUnit2': 64, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009911312492532793, 'weightDecay': 5.085159397368315e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:32:56,595] Trial 1134 pruned. \n",
      "[I 2025-06-05 17:32:56,889] Trial 1135 pruned. \n",
      "[I 2025-06-05 17:32:57,697] Trial 1136 pruned. \n",
      "[I 2025-06-05 17:32:58,185] Trial 1137 pruned. \n",
      "[I 2025-06-05 17:32:58,641] Trial 1138 pruned. \n",
      "[I 2025-06-05 17:32:59,261] Trial 1139 pruned. \n",
      "[I 2025-06-05 17:32:59,803] Trial 1140 pruned. \n",
      "[I 2025-06-05 17:33:00,256] Trial 1141 pruned. \n",
      "[I 2025-06-05 17:33:00,727] Trial 1142 pruned. \n",
      "[I 2025-06-05 17:33:01,211] Trial 1143 pruned. \n",
      "[I 2025-06-05 17:33:02,403] Trial 1144 pruned. \n",
      "[I 2025-06-05 17:33:03,004] Trial 1145 pruned. \n",
      "[I 2025-06-05 17:33:03,326] Trial 1146 pruned. \n",
      "[I 2025-06-05 17:33:05,838] Trial 1147 pruned. \n",
      "[I 2025-06-05 17:33:06,629] Trial 1148 pruned. \n",
      "[I 2025-06-05 17:33:07,108] Trial 1149 pruned. \n",
      "[I 2025-06-05 17:33:07,535] Trial 1150 pruned. \n",
      "[I 2025-06-05 17:33:08,182] Trial 1151 pruned. \n",
      "[I 2025-06-05 17:33:08,753] Trial 1152 pruned. \n",
      "[I 2025-06-05 17:33:09,294] Trial 1153 pruned. \n",
      "[I 2025-06-05 17:33:18,216] Trial 1154 finished with value: 0.16683758886712552 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008522705130470378, 'weightDecay': 3.8684045724105496e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:33:21,753] Trial 1155 pruned. \n",
      "[I 2025-06-05 17:33:23,220] Trial 1156 pruned. \n",
      "[I 2025-06-05 17:33:27,349] Trial 1157 pruned. \n",
      "[I 2025-06-05 17:33:28,458] Trial 1158 pruned. \n",
      "[I 2025-06-05 17:33:30,735] Trial 1159 pruned. \n",
      "[I 2025-06-05 17:33:31,551] Trial 1160 pruned. \n",
      "[I 2025-06-05 17:33:33,784] Trial 1161 pruned. \n",
      "[I 2025-06-05 17:33:34,320] Trial 1162 pruned. \n",
      "[I 2025-06-05 17:33:36,491] Trial 1163 pruned. \n",
      "[I 2025-06-05 17:33:37,363] Trial 1164 pruned. \n",
      "[I 2025-06-05 17:33:38,791] Trial 1165 pruned. \n",
      "[I 2025-06-05 17:33:39,130] Trial 1166 pruned. \n",
      "[I 2025-06-05 17:33:45,379] Trial 1167 finished with value: 0.16570379942763153 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 176, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009102304749782722, 'weightDecay': 1.9606150653554554e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:33:46,537] Trial 1168 pruned. \n",
      "[I 2025-06-05 17:33:47,871] Trial 1169 pruned. \n",
      "[I 2025-06-05 17:33:53,406] Trial 1170 finished with value: 0.1682100233618533 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 192, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.00918766214062551, 'weightDecay': 1.5204522580280288e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:33:56,477] Trial 1171 pruned. \n",
      "[I 2025-06-05 17:33:56,852] Trial 1172 pruned. \n",
      "[I 2025-06-05 17:33:57,948] Trial 1173 pruned. \n",
      "[I 2025-06-05 17:33:59,035] Trial 1174 pruned. \n",
      "[I 2025-06-05 17:34:01,131] Trial 1175 pruned. \n",
      "[I 2025-06-05 17:34:07,931] Trial 1176 finished with value: 0.16862247496950927 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 176, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.008032626489057112, 'weightDecay': 1.5223830948646635e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:34:11,629] Trial 1177 pruned. \n",
      "[I 2025-06-05 17:34:14,947] Trial 1178 pruned. \n",
      "[I 2025-06-05 17:34:18,771] Trial 1179 pruned. \n",
      "[I 2025-06-05 17:34:19,583] Trial 1180 pruned. \n",
      "[I 2025-06-05 17:34:25,852] Trial 1181 finished with value: 0.16728360741147066 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009961041287553882, 'weightDecay': 2.268393521356648e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:34:28,123] Trial 1182 pruned. \n",
      "[I 2025-06-05 17:34:29,464] Trial 1183 pruned. \n",
      "[I 2025-06-05 17:34:30,580] Trial 1184 pruned. \n",
      "[I 2025-06-05 17:34:31,060] Trial 1185 pruned. \n",
      "[I 2025-06-05 17:34:37,554] Trial 1186 finished with value: 0.16767184748331132 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009092629166854091, 'weightDecay': 1.7899238673427728e-05, 'batchSize': 32, 'epochs': 11, 'optimizer': 'RMSprop', 'use_scheduler': True}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:34:38,667] Trial 1187 pruned. \n",
      "[I 2025-06-05 17:34:39,852] Trial 1188 pruned. \n",
      "[I 2025-06-05 17:34:40,640] Trial 1189 pruned. \n",
      "[I 2025-06-05 17:34:42,828] Trial 1190 pruned. \n",
      "[I 2025-06-05 17:34:43,983] Trial 1191 pruned. \n",
      "[I 2025-06-05 17:34:45,307] Trial 1192 pruned. \n",
      "[I 2025-06-05 17:34:47,153] Trial 1193 pruned. \n",
      "[I 2025-06-05 17:34:47,569] Trial 1194 pruned. \n",
      "[I 2025-06-05 17:34:49,759] Trial 1195 pruned. \n",
      "[I 2025-06-05 17:34:50,926] Trial 1196 pruned. \n",
      "[I 2025-06-05 17:34:51,406] Trial 1197 pruned. \n",
      "[I 2025-06-05 17:34:52,720] Trial 1198 pruned. \n",
      "[I 2025-06-05 17:34:53,533] Trial 1199 pruned. \n",
      "[I 2025-06-05 17:34:54,750] Trial 1200 pruned. \n",
      "[I 2025-06-05 17:34:55,879] Trial 1201 pruned. \n",
      "[I 2025-06-05 17:34:57,212] Trial 1202 pruned. \n",
      "[I 2025-06-05 17:34:57,553] Trial 1203 pruned. \n",
      "[I 2025-06-05 17:34:58,686] Trial 1204 pruned. \n",
      "[I 2025-06-05 17:34:59,078] Trial 1205 pruned. \n",
      "[I 2025-06-05 17:34:59,685] Trial 1206 pruned. \n",
      "[I 2025-06-05 17:35:00,475] Trial 1207 pruned. \n",
      "[I 2025-06-05 17:35:02,632] Trial 1208 pruned. \n",
      "[I 2025-06-05 17:35:03,154] Trial 1209 pruned. \n",
      "[I 2025-06-05 17:35:04,355] Trial 1210 pruned. \n",
      "[I 2025-06-05 17:35:05,090] Trial 1211 pruned. \n",
      "[I 2025-06-05 17:35:06,172] Trial 1212 pruned. \n",
      "[I 2025-06-05 17:35:07,260] Trial 1213 pruned. \n",
      "[I 2025-06-05 17:35:08,383] Trial 1214 pruned. \n",
      "[I 2025-06-05 17:35:09,696] Trial 1215 pruned. \n",
      "[I 2025-06-05 17:35:10,089] Trial 1216 pruned. \n",
      "[I 2025-06-05 17:35:10,777] Trial 1217 pruned. \n",
      "[I 2025-06-05 17:35:11,894] Trial 1218 pruned. \n",
      "[I 2025-06-05 17:35:14,987] Trial 1219 pruned. \n",
      "[I 2025-06-05 17:35:15,398] Trial 1220 pruned. \n",
      "[I 2025-06-05 17:35:16,501] Trial 1221 pruned. \n",
      "[I 2025-06-05 17:35:17,202] Trial 1222 pruned. \n",
      "[I 2025-06-05 17:35:20,187] Trial 1223 pruned. \n",
      "[I 2025-06-05 17:35:20,552] Trial 1224 pruned. \n",
      "[I 2025-06-05 17:35:23,641] Trial 1225 pruned. \n",
      "[I 2025-06-05 17:35:24,070] Trial 1226 pruned. \n",
      "[I 2025-06-05 17:35:25,234] Trial 1227 pruned. \n",
      "[I 2025-06-05 17:35:25,844] Trial 1228 pruned. \n",
      "[I 2025-06-05 17:35:26,939] Trial 1229 pruned. \n",
      "[I 2025-06-05 17:35:28,040] Trial 1230 pruned. \n",
      "[I 2025-06-05 17:35:28,840] Trial 1231 pruned. \n",
      "[I 2025-06-05 17:35:30,110] Trial 1232 pruned. \n",
      "[I 2025-06-05 17:35:30,511] Trial 1233 pruned. \n",
      "[I 2025-06-05 17:35:33,749] Trial 1234 finished with value: 0.16758353152860372 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 208, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007285162020316441, 'weightDecay': 3.9425089988210754e-05, 'batchSize': 32, 'epochs': 3, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:35:35,130] Trial 1235 pruned. \n",
      "[I 2025-06-05 17:35:35,562] Trial 1236 pruned. \n",
      "[I 2025-06-05 17:35:36,677] Trial 1237 pruned. \n",
      "[I 2025-06-05 17:35:37,903] Trial 1238 pruned. \n",
      "[I 2025-06-05 17:35:39,200] Trial 1239 pruned. \n",
      "[I 2025-06-05 17:35:41,483] Trial 1240 pruned. \n",
      "[I 2025-06-05 17:35:42,623] Trial 1241 pruned. \n",
      "[I 2025-06-05 17:35:43,781] Trial 1242 pruned. \n",
      "[I 2025-06-05 17:35:44,215] Trial 1243 pruned. \n",
      "[I 2025-06-05 17:35:44,638] Trial 1244 pruned. \n",
      "[I 2025-06-05 17:35:45,345] Trial 1245 pruned. \n",
      "[I 2025-06-05 17:35:48,458] Trial 1246 pruned. \n",
      "[I 2025-06-05 17:35:51,611] Trial 1247 pruned. \n",
      "[I 2025-06-05 17:35:52,068] Trial 1248 pruned. \n",
      "[I 2025-06-05 17:35:54,077] Trial 1249 pruned. \n",
      "[I 2025-06-05 17:35:54,907] Trial 1250 pruned. \n",
      "[I 2025-06-05 17:35:55,669] Trial 1251 pruned. \n",
      "[I 2025-06-05 17:35:56,849] Trial 1252 pruned. \n",
      "[I 2025-06-05 17:35:58,069] Trial 1253 pruned. \n",
      "[I 2025-06-05 17:35:58,804] Trial 1254 pruned. \n",
      "[I 2025-06-05 17:36:00,139] Trial 1255 pruned. \n",
      "[I 2025-06-05 17:36:00,950] Trial 1256 pruned. \n",
      "[I 2025-06-05 17:36:01,539] Trial 1257 pruned. \n",
      "[I 2025-06-05 17:36:02,143] Trial 1258 pruned. \n",
      "[I 2025-06-05 17:36:03,377] Trial 1259 pruned. \n",
      "[I 2025-06-05 17:36:04,463] Trial 1260 pruned. \n",
      "[I 2025-06-05 17:36:05,613] Trial 1261 pruned. \n",
      "[I 2025-06-05 17:36:06,318] Trial 1262 pruned. \n",
      "[I 2025-06-05 17:36:08,539] Trial 1263 pruned. \n",
      "[I 2025-06-05 17:36:08,911] Trial 1264 pruned. \n",
      "[I 2025-06-05 17:36:09,995] Trial 1265 pruned. \n",
      "[I 2025-06-05 17:36:11,169] Trial 1266 pruned. \n",
      "[I 2025-06-05 17:36:12,041] Trial 1267 pruned. \n",
      "[I 2025-06-05 17:36:12,544] Trial 1268 pruned. \n",
      "[I 2025-06-05 17:36:13,805] Trial 1269 pruned. \n",
      "[I 2025-06-05 17:36:14,286] Trial 1270 pruned. \n",
      "[I 2025-06-05 17:36:15,424] Trial 1271 pruned. \n",
      "[I 2025-06-05 17:36:16,264] Trial 1272 pruned. \n",
      "[I 2025-06-05 17:36:17,563] Trial 1273 pruned. \n",
      "[I 2025-06-05 17:36:19,760] Trial 1274 pruned. \n",
      "[I 2025-06-05 17:36:20,930] Trial 1275 pruned. \n",
      "[I 2025-06-05 17:36:23,098] Trial 1276 pruned. \n",
      "[I 2025-06-05 17:36:23,901] Trial 1277 pruned. \n",
      "[I 2025-06-05 17:36:24,807] Trial 1278 pruned. \n",
      "[I 2025-06-05 17:36:26,155] Trial 1279 pruned. \n",
      "[I 2025-06-05 17:36:26,600] Trial 1280 pruned. \n",
      "[I 2025-06-05 17:36:27,135] Trial 1281 pruned. \n",
      "[I 2025-06-05 17:36:27,646] Trial 1282 pruned. \n",
      "[I 2025-06-05 17:36:28,778] Trial 1283 pruned. \n",
      "[I 2025-06-05 17:36:29,962] Trial 1284 pruned. \n",
      "[I 2025-06-05 17:36:30,330] Trial 1285 pruned. \n",
      "[I 2025-06-05 17:36:30,828] Trial 1286 pruned. \n",
      "[I 2025-06-05 17:36:31,523] Trial 1287 pruned. \n",
      "[I 2025-06-05 17:36:33,594] Trial 1288 pruned. \n",
      "[I 2025-06-05 17:36:34,685] Trial 1289 pruned. \n",
      "[I 2025-06-05 17:36:35,195] Trial 1290 pruned. \n",
      "[I 2025-06-05 17:36:38,327] Trial 1291 pruned. \n",
      "[I 2025-06-05 17:36:40,723] Trial 1292 pruned. \n",
      "[I 2025-06-05 17:36:41,067] Trial 1293 pruned. \n",
      "[I 2025-06-05 17:36:41,623] Trial 1294 pruned. \n",
      "[I 2025-06-05 17:36:41,995] Trial 1295 pruned. \n",
      "[I 2025-06-05 17:36:43,098] Trial 1296 pruned. \n",
      "[I 2025-06-05 17:36:45,205] Trial 1297 pruned. \n",
      "[I 2025-06-05 17:36:45,725] Trial 1298 pruned. \n",
      "[I 2025-06-05 17:36:50,606] Trial 1299 finished with value: 0.16581371631002598 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009294380405778459, 'weightDecay': 2.756477023912555e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:36:54,508] Trial 1300 finished with value: 0.16749538233779399 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009223209041472759, 'weightDecay': 1.6675438966274614e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:36:58,520] Trial 1301 finished with value: 0.16969414760059398 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009985415774843293, 'weightDecay': 2.4778534679558606e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:36:59,779] Trial 1302 pruned. \n",
      "[I 2025-06-05 17:37:00,332] Trial 1303 pruned. \n",
      "[I 2025-06-05 17:37:01,008] Trial 1304 pruned. \n",
      "[I 2025-06-05 17:37:03,933] Trial 1305 pruned. \n",
      "[I 2025-06-05 17:37:05,983] Trial 1306 pruned. \n",
      "[I 2025-06-05 17:37:06,260] Trial 1307 pruned. \n",
      "[I 2025-06-05 17:37:06,651] Trial 1308 pruned. \n",
      "[I 2025-06-05 17:37:07,328] Trial 1309 pruned. \n",
      "[I 2025-06-05 17:37:08,443] Trial 1310 pruned. \n",
      "[I 2025-06-05 17:37:13,302] Trial 1311 finished with value: 0.16923352564930486 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009262791953931563, 'weightDecay': 2.6167444139975728e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:37:13,693] Trial 1312 pruned. \n",
      "[I 2025-06-05 17:37:14,198] Trial 1313 pruned. \n",
      "[I 2025-06-05 17:37:16,256] Trial 1314 pruned. \n",
      "[I 2025-06-05 17:37:17,352] Trial 1315 pruned. \n",
      "[I 2025-06-05 17:37:17,867] Trial 1316 pruned. \n",
      "[I 2025-06-05 17:37:18,180] Trial 1317 pruned. \n",
      "[I 2025-06-05 17:37:20,233] Trial 1318 pruned. \n",
      "[I 2025-06-05 17:37:21,337] Trial 1319 pruned. \n",
      "[I 2025-06-05 17:37:22,209] Trial 1320 pruned. \n",
      "[I 2025-06-05 17:37:25,217] Trial 1321 pruned. \n",
      "[I 2025-06-05 17:37:26,348] Trial 1322 pruned. \n",
      "[I 2025-06-05 17:37:26,788] Trial 1323 pruned. \n",
      "[I 2025-06-05 17:37:27,491] Trial 1324 pruned. \n",
      "[I 2025-06-05 17:37:28,573] Trial 1325 pruned. \n",
      "[I 2025-06-05 17:37:28,922] Trial 1326 pruned. \n",
      "[I 2025-06-05 17:37:30,018] Trial 1327 pruned. \n",
      "[I 2025-06-05 17:37:31,089] Trial 1328 pruned. \n",
      "[I 2025-06-05 17:37:31,591] Trial 1329 pruned. \n",
      "[I 2025-06-05 17:37:32,689] Trial 1330 pruned. \n",
      "[I 2025-06-05 17:37:33,050] Trial 1331 pruned. \n",
      "[I 2025-06-05 17:37:35,109] Trial 1332 pruned. \n",
      "[I 2025-06-05 17:37:35,609] Trial 1333 pruned. \n",
      "[I 2025-06-05 17:37:36,700] Trial 1334 pruned. \n",
      "[I 2025-06-05 17:37:37,806] Trial 1335 pruned. \n",
      "[I 2025-06-05 17:37:38,697] Trial 1336 pruned. \n",
      "[I 2025-06-05 17:37:39,120] Trial 1337 pruned. \n",
      "[I 2025-06-05 17:37:39,464] Trial 1338 pruned. \n",
      "[I 2025-06-05 17:37:44,342] Trial 1339 finished with value: 0.1695525833953589 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007992307152932306, 'weightDecay': 2.510811371676021e-05, 'batchSize': 32, 'epochs': 13, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:37:45,069] Trial 1340 pruned. \n",
      "[I 2025-06-05 17:37:45,497] Trial 1341 pruned. \n",
      "[I 2025-06-05 17:37:48,495] Trial 1342 pruned. \n",
      "[I 2025-06-05 17:37:49,007] Trial 1343 pruned. \n",
      "[I 2025-06-05 17:37:51,940] Trial 1344 pruned. \n",
      "[I 2025-06-05 17:37:53,168] Trial 1345 pruned. \n",
      "[I 2025-06-05 17:37:53,873] Trial 1346 pruned. \n",
      "[I 2025-06-05 17:37:54,369] Trial 1347 pruned. \n",
      "[I 2025-06-05 17:37:56,422] Trial 1348 pruned. \n",
      "[I 2025-06-05 17:37:57,517] Trial 1349 pruned. \n",
      "[I 2025-06-05 17:37:58,054] Trial 1350 pruned. \n",
      "[I 2025-06-05 17:37:58,349] Trial 1351 pruned. \n",
      "[I 2025-06-05 17:37:59,460] Trial 1352 pruned. \n",
      "[I 2025-06-05 17:38:02,426] Trial 1353 pruned. \n",
      "[I 2025-06-05 17:38:03,096] Trial 1354 pruned. \n",
      "[I 2025-06-05 17:38:03,375] Trial 1355 pruned. \n",
      "[I 2025-06-05 17:38:04,498] Trial 1356 pruned. \n",
      "[I 2025-06-05 17:38:05,620] Trial 1357 pruned. \n",
      "[I 2025-06-05 17:38:06,737] Trial 1358 pruned. \n",
      "[I 2025-06-05 17:38:08,690] Trial 1359 finished with value: 0.16962687364554146 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 144, 'hiddenUnit2': 32, 'dropoutRate': 0.2, 'learnRate': 0.007564403807574033, 'weightDecay': 6.132603119820411e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:38:09,261] Trial 1360 pruned. \n",
      "[I 2025-06-05 17:38:10,409] Trial 1361 pruned. \n",
      "[I 2025-06-05 17:38:11,584] Trial 1362 pruned. \n",
      "[I 2025-06-05 17:38:12,098] Trial 1363 pruned. \n",
      "[I 2025-06-05 17:38:13,212] Trial 1364 pruned. \n",
      "[I 2025-06-05 17:38:13,424] Trial 1365 pruned. \n",
      "[I 2025-06-05 17:38:13,835] Trial 1366 pruned. \n",
      "[I 2025-06-05 17:38:15,108] Trial 1367 pruned. \n",
      "[I 2025-06-05 17:38:15,597] Trial 1368 pruned. \n",
      "[I 2025-06-05 17:38:16,291] Trial 1369 pruned. \n",
      "[I 2025-06-05 17:38:19,270] Trial 1370 pruned. \n",
      "[I 2025-06-05 17:38:20,371] Trial 1371 pruned. \n",
      "[I 2025-06-05 17:38:20,882] Trial 1372 pruned. \n",
      "[I 2025-06-05 17:38:22,965] Trial 1373 pruned. \n",
      "[I 2025-06-05 17:38:23,646] Trial 1374 pruned. \n",
      "[I 2025-06-05 17:38:24,378] Trial 1375 pruned. \n",
      "[I 2025-06-05 17:38:25,507] Trial 1376 pruned. \n",
      "[I 2025-06-05 17:38:26,010] Trial 1377 pruned. \n",
      "[I 2025-06-05 17:38:26,534] Trial 1378 pruned. \n",
      "[I 2025-06-05 17:38:26,950] Trial 1379 pruned. \n",
      "[I 2025-06-05 17:38:28,912] Trial 1380 pruned. \n",
      "[I 2025-06-05 17:38:29,435] Trial 1381 pruned. \n",
      "[I 2025-06-05 17:38:30,563] Trial 1382 pruned. \n",
      "[I 2025-06-05 17:38:31,111] Trial 1383 pruned. \n",
      "[I 2025-06-05 17:38:33,089] Trial 1384 pruned. \n",
      "[I 2025-06-05 17:38:33,591] Trial 1385 pruned. \n",
      "[I 2025-06-05 17:38:34,676] Trial 1386 pruned. \n",
      "[I 2025-06-05 17:38:35,815] Trial 1387 pruned. \n",
      "[I 2025-06-05 17:38:36,185] Trial 1388 pruned. \n",
      "[I 2025-06-05 17:38:36,753] Trial 1389 pruned. \n",
      "[I 2025-06-05 17:38:37,173] Trial 1390 pruned. \n",
      "[I 2025-06-05 17:38:37,882] Trial 1391 pruned. \n",
      "[I 2025-06-05 17:38:39,046] Trial 1392 pruned. \n",
      "[I 2025-06-05 17:38:40,179] Trial 1393 pruned. \n",
      "[I 2025-06-05 17:38:40,702] Trial 1394 pruned. \n",
      "[I 2025-06-05 17:38:41,108] Trial 1395 pruned. \n",
      "[I 2025-06-05 17:38:42,186] Trial 1396 pruned. \n",
      "[I 2025-06-05 17:38:43,264] Trial 1397 pruned. \n",
      "[I 2025-06-05 17:38:43,714] Trial 1398 pruned. \n",
      "[I 2025-06-05 17:38:45,716] Trial 1399 finished with value: 0.16870332000918337 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 224, 'hiddenUnit2': 64, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009242008918241965, 'weightDecay': 6.486716951715295e-05, 'batchSize': 32, 'epochs': 15, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:38:47,796] Trial 1400 pruned. \n",
      "[I 2025-06-05 17:38:51,691] Trial 1401 finished with value: 0.16794924174405176 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 240, 'hiddenUnit2': 48, 'dropoutRate': 0.2, 'learnRate': 0.008570966496950681, 'weightDecay': 2.440679680848692e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 587 with value: 0.1653921995244732.\n",
      "[I 2025-06-05 17:38:52,187] Trial 1402 pruned. \n",
      "[I 2025-06-05 17:38:53,297] Trial 1403 pruned. \n",
      "[I 2025-06-05 17:38:53,825] Trial 1404 pruned. \n",
      "[I 2025-06-05 17:38:54,353] Trial 1405 pruned. \n",
      "[I 2025-06-05 17:38:54,880] Trial 1406 pruned. \n",
      "[I 2025-06-05 17:38:55,971] Trial 1407 pruned. \n",
      "[I 2025-06-05 17:38:57,071] Trial 1408 pruned. \n",
      "[I 2025-06-05 17:38:58,223] Trial 1409 pruned. \n",
      "[I 2025-06-05 17:38:58,665] Trial 1410 pruned. \n",
      "[I 2025-06-05 17:38:59,268] Trial 1411 pruned. \n",
      "[I 2025-06-05 17:38:59,980] Trial 1412 pruned. \n",
      "[I 2025-06-05 17:39:00,406] Trial 1413 pruned. \n",
      "[I 2025-06-05 17:39:01,504] Trial 1414 pruned. \n",
      "[I 2025-06-05 17:39:01,857] Trial 1415 pruned. \n",
      "[I 2025-06-05 17:39:02,675] Trial 1416 pruned. \n",
      "[I 2025-06-05 17:39:03,743] Trial 1417 pruned. \n",
      "[I 2025-06-05 17:39:04,885] Trial 1418 pruned. \n",
      "[I 2025-06-05 17:39:05,794] Trial 1419 pruned. \n",
      "[I 2025-06-05 17:39:06,535] Trial 1420 pruned. \n",
      "[I 2025-06-05 17:39:07,660] Trial 1421 pruned. \n",
      "[I 2025-06-05 17:39:08,080] Trial 1422 pruned. \n",
      "[I 2025-06-05 17:39:11,071] Trial 1423 pruned. \n",
      "[I 2025-06-05 17:39:13,003] Trial 1424 finished with value: 0.1637196369765037 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009164863480051992, 'weightDecay': 2.3282435688968944e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 1424 with value: 0.1637196369765037.\n",
      "[I 2025-06-05 17:39:15,903] Trial 1425 finished with value: 0.1669107635744212 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009259412807073986, 'weightDecay': 1.4111229930908571e-05, 'batchSize': 64, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 1424 with value: 0.1637196369765037.\n",
      "[I 2025-06-05 17:39:19,046] Trial 1426 finished with value: 0.1690474054658456 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009981709622198926, 'weightDecay': 9.976526750821558e-06, 'batchSize': 64, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 1424 with value: 0.1637196369765037.\n",
      "[I 2025-06-05 17:39:19,783] Trial 1427 pruned. \n",
      "[I 2025-06-05 17:39:20,112] Trial 1428 pruned. \n",
      "[I 2025-06-05 17:39:20,529] Trial 1429 pruned. \n",
      "[I 2025-06-05 17:39:21,244] Trial 1430 pruned. \n",
      "[I 2025-06-05 17:39:21,968] Trial 1431 pruned. \n",
      "[I 2025-06-05 17:39:22,301] Trial 1432 pruned. \n",
      "[I 2025-06-05 17:39:22,710] Trial 1433 pruned. \n",
      "[I 2025-06-05 17:39:23,508] Trial 1434 pruned. \n",
      "[I 2025-06-05 17:39:23,976] Trial 1435 pruned. \n",
      "[I 2025-06-05 17:39:24,352] Trial 1436 pruned. \n",
      "[I 2025-06-05 17:39:24,677] Trial 1437 pruned. \n",
      "[I 2025-06-05 17:39:25,414] Trial 1438 pruned. \n",
      "[I 2025-06-05 17:39:26,696] Trial 1439 pruned. \n",
      "[I 2025-06-05 17:39:27,066] Trial 1440 pruned. \n",
      "[I 2025-06-05 17:39:28,333] Trial 1441 pruned. \n",
      "[I 2025-06-05 17:39:28,633] Trial 1442 pruned. \n",
      "[I 2025-06-05 17:39:29,339] Trial 1443 pruned. \n",
      "[I 2025-06-05 17:39:29,818] Trial 1444 pruned. \n",
      "[I 2025-06-05 17:39:30,521] Trial 1445 pruned. \n",
      "[I 2025-06-05 17:39:30,863] Trial 1446 pruned. \n",
      "[I 2025-06-05 17:39:31,968] Trial 1447 pruned. \n",
      "[I 2025-06-05 17:39:32,694] Trial 1448 pruned. \n",
      "[I 2025-06-05 17:39:33,034] Trial 1449 pruned. \n",
      "[I 2025-06-05 17:39:33,493] Trial 1450 pruned. \n",
      "[I 2025-06-05 17:39:34,193] Trial 1451 pruned. \n",
      "[I 2025-06-05 17:39:34,507] Trial 1452 pruned. \n",
      "[I 2025-06-05 17:39:35,224] Trial 1453 pruned. \n",
      "[I 2025-06-05 17:39:35,558] Trial 1454 pruned. \n",
      "[I 2025-06-05 17:39:36,645] Trial 1455 pruned. \n",
      "[I 2025-06-05 17:39:42,449] Trial 1456 finished with value: 0.16808416611020746 and parameters: {'embeddingDim': 512, 'hiddenUnit1': 224, 'hiddenUnit2': 32, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.009198914275038163, 'weightDecay': 1.729739441018028e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 1424 with value: 0.1637196369765037.\n",
      "[I 2025-06-05 17:39:42,734] Trial 1457 pruned. \n",
      "[I 2025-06-05 17:39:43,425] Trial 1458 pruned. \n",
      "[I 2025-06-05 17:39:45,435] Trial 1459 pruned. \n",
      "[I 2025-06-05 17:39:46,589] Trial 1460 pruned. \n",
      "[I 2025-06-05 17:39:47,309] Trial 1461 pruned. \n",
      "[I 2025-06-05 17:39:47,818] Trial 1462 pruned. \n",
      "[I 2025-06-05 17:39:48,236] Trial 1463 pruned. \n",
      "[I 2025-06-05 17:39:48,635] Trial 1464 pruned. \n",
      "[I 2025-06-05 17:39:49,377] Trial 1465 pruned. \n",
      "[I 2025-06-05 17:39:50,510] Trial 1466 pruned. \n",
      "[I 2025-06-05 17:39:51,014] Trial 1467 pruned. \n",
      "[I 2025-06-05 17:39:53,060] Trial 1468 pruned. \n",
      "[I 2025-06-05 17:39:53,425] Trial 1469 pruned. \n",
      "[I 2025-06-05 17:39:54,245] Trial 1470 pruned. \n",
      "[I 2025-06-05 17:39:54,745] Trial 1471 pruned. \n",
      "[I 2025-06-05 17:39:55,857] Trial 1472 pruned. \n",
      "[I 2025-06-05 17:39:56,575] Trial 1473 pruned. \n",
      "[I 2025-06-05 17:39:59,572] Trial 1474 pruned. \n",
      "[I 2025-06-05 17:39:59,944] Trial 1475 pruned. \n",
      "[I 2025-06-05 17:40:02,007] Trial 1476 pruned. \n",
      "[I 2025-06-05 17:40:03,286] Trial 1477 pruned. \n",
      "[I 2025-06-05 17:40:03,822] Trial 1478 pruned. \n",
      "[I 2025-06-05 17:40:04,314] Trial 1479 pruned. \n",
      "[I 2025-06-05 17:40:05,031] Trial 1480 pruned. \n",
      "[I 2025-06-05 17:40:05,473] Trial 1481 pruned. \n",
      "[I 2025-06-05 17:40:06,606] Trial 1482 pruned. \n",
      "[I 2025-06-05 17:40:07,702] Trial 1483 pruned. \n",
      "[I 2025-06-05 17:40:08,221] Trial 1484 pruned. \n",
      "[I 2025-06-05 17:40:10,252] Trial 1485 pruned. \n",
      "[I 2025-06-05 17:40:11,371] Trial 1486 pruned. \n",
      "[I 2025-06-05 17:40:11,684] Trial 1487 pruned. \n",
      "[I 2025-06-05 17:40:12,173] Trial 1488 pruned. \n",
      "[I 2025-06-05 17:40:13,269] Trial 1489 pruned. \n",
      "[I 2025-06-05 17:40:13,975] Trial 1490 pruned. \n",
      "[I 2025-06-05 17:40:15,910] Trial 1491 finished with value: 0.16939329466234476 and parameters: {'embeddingDim': 128, 'hiddenUnit1': 208, 'hiddenUnit2': 48, 'dropoutRate': 0.30000000000000004, 'learnRate': 0.007496121487190223, 'weightDecay': 2.7528729518343478e-05, 'batchSize': 32, 'epochs': 9, 'optimizer': 'RMSprop', 'use_scheduler': False}. Best is trial 1424 with value: 0.1637196369765037.\n",
      "[I 2025-06-05 17:40:16,737] Trial 1492 pruned. \n",
      "[I 2025-06-05 17:40:17,177] Trial 1493 pruned. \n",
      "[I 2025-06-05 17:40:17,572] Trial 1494 pruned. \n",
      "[I 2025-06-05 17:40:18,692] Trial 1495 pruned. \n",
      "[I 2025-06-05 17:40:19,402] Trial 1496 pruned. \n",
      "[I 2025-06-05 17:40:20,538] Trial 1497 pruned. \n",
      "[I 2025-06-05 17:40:21,065] Trial 1498 pruned. \n",
      "[I 2025-06-05 17:40:21,702] Trial 1499 pruned. \n"
     ]
    }
   ],
   "source": [
    "study.optimize(_objective, n_trials = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a72360d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optuna Best Trial:\n",
      "Validation Loss: 0.1637\n",
      "  embeddingDim: 128\n",
      "  hiddenUnit1: 224\n",
      "  hiddenUnit2: 32\n",
      "  dropoutRate: 0.30000000000000004\n",
      "  learnRate: 0.009164863480051992\n",
      "  weightDecay: 2.3282435688968944e-05\n",
      "  batchSize: 32\n",
      "  epochs: 9\n",
      "  optimizer: RMSprop\n",
      "  use_scheduler: False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOptuna Best Trial:\")\n",
    "best = study.best_trial\n",
    "print(f\"Validation Loss: {best.value:.4f}\")\n",
    "for key, val in best.params.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "best_embeddingDim = best.params[\"embeddingDim\"]\n",
    "best_hiddenUnit1 = best.params[\"hiddenUnit1\"]\n",
    "best_hiddenUnit2 = best.params[\"hiddenUnit2\"]\n",
    "best_dropoutRate = best.params[\"dropoutRate\"]\n",
    "best_learnRate = best.params[\"learnRate\"]\n",
    "best_weightDecay = best.params[\"weightDecay\"]\n",
    "best_batchSize = best.params[\"batchSize\"]\n",
    "best_epochs = best.params[\"epochs\"]\n",
    "best_optimizer = best.params[\"optimizer\"]\n",
    "best_use_scheduler = best.params[\"use_scheduler\"]\n",
    "if best_optimizer == \"SGD\":\n",
    "    best_momentum = best.params[\"momentum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffa75612",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTrainDataset = TextDataset(trainEncode, yTrain)\n",
    "finalValDataset = TextDataset(valEncode, yVal)\n",
    "\n",
    "finalTrainLoader = DataLoader(finalTrainDataset, batch_size = best_batchSize, shuffle = True)\n",
    "finalValLoader = DataLoader(finalValDataset, batch_size = best_batchSize, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = feedforwardNeuralNetwork(\n",
    "    vocabSize = vocabSize,\n",
    "    embeddingDim = best_embeddingDim,\n",
    "    hiddenUnit1 = best_hiddenUnit1,\n",
    "    hiddenUnit2 = best_hiddenUnit2,\n",
    "    dropoutRate = best_dropoutRate,\n",
    "    numLabels = numLabels,\n",
    "    padIndex = padIndex\n",
    ").to(userDevice)\n",
    "\n",
    "if best_optimizer == \"Adam\":\n",
    "    finalOptimizer = optim.Adam(finalModel.parameters(), lr = best_learnRate, weight_decay = best_weightDecay)\n",
    "elif best_optimizer == \"RMSprop\":\n",
    "    finalOptimizer = optim.RMSprop(finalModel.parameters(), lr = best_learnRate, weight_decay = best_weightDecay)\n",
    "else:\n",
    "    finalOptimizer = optim.SGD(finalModel.parameters(), lr = best_learnRate, momentum = best_momentum, weight_decay = best_weightDecay)\n",
    "\n",
    "finalCriterion = nn.BCEWithLogitsLoss(pos_weight = weight_tensor)\n",
    "\n",
    "if best_use_scheduler:\n",
    "    finalScheduler = optim.lr_scheduler.ReduceLROnPlateau(finalOptimizer, mode = \"min\", factor = 0.5, patience = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95b65981",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestValLossFinal = float(\"inf\")\n",
    "patienceCtr = 0\n",
    "bestStateFinal = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9edb7821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Epoch 01 | Train Loss: 0.1956 | Val Loss: 0.1778\n",
      "Final Epoch 02 | Train Loss: 0.1729 | Val Loss: 0.1734\n",
      "Final Epoch 03 | Train Loss: 0.1566 | Val Loss: 0.1702\n",
      "Final Epoch 04 | Train Loss: 0.1418 | Val Loss: 0.1694\n",
      "Final Epoch 05 | Train Loss: 0.1285 | Val Loss: 0.1768\n",
      "Final Epoch 06 | Train Loss: 0.1185 | Val Loss: 0.1821\n",
      "Final Epoch 07 | Train Loss: 0.1148 | Val Loss: 0.1856\n",
      "Early stopping at epoch 7\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, best_epochs + 1):\n",
    "    trainLoss = epochTrain(finalModel, finalTrainLoader, finalOptimizer, finalCriterion, userDevice)\n",
    "    valLoss = evaluateModel(finalModel, finalValLoader,   finalCriterion, userDevice)\n",
    "    print(f\"Final Epoch {epoch:02d} | Train Loss: {trainLoss:.4f} | Val Loss: {valLoss:.4f}\")\n",
    "\n",
    "    if best_use_scheduler:\n",
    "        finalScheduler.step(valLoss)\n",
    "\n",
    "    if valLoss < bestValLossFinal:\n",
    "        bestValLossFinal = valLoss\n",
    "        patienceCtr = 0\n",
    "        bestStateFinal = {k: v.cpu() for k, v in finalModel.state_dict().items()}\n",
    "    else:\n",
    "        patienceCtr += 1\n",
    "        if patienceCtr >= 3:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3afce23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.load_state_dict(bestStateFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cb71edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model -> Val Loss: 0.1856, Val Accuracy: 0.6996\n"
     ]
    }
   ],
   "source": [
    "finalModel.eval()\n",
    "runningLoss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batchInputs, batchLabels in finalValLoader:\n",
    "        batchInputs = batchInputs.to(userDevice)\n",
    "        batchLabels = batchLabels.to(userDevice)\n",
    "\n",
    "        logits = finalModel(batchInputs)\n",
    "        loss = finalCriterion(logits, batchLabels)\n",
    "        runningLoss += loss.item() * batchInputs.size(0)\n",
    "\n",
    "        preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "        correct += (preds == batchLabels).sum().item()\n",
    "        total += batchLabels.numel()\n",
    "\n",
    "finalValLoss = runningLoss / len(finalValDataset)\n",
    "finalValAcc  = correct / total\n",
    "print(f\"\\nFinal Model -> Val Loss: {finalValLoss:.4f}, Val Accuracy: {finalValAcc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2db283fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final model + vocab to savedModel/ffnn_emotion_classifier_optuna.pth\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"savedModel\", exist_ok = True)\n",
    "torch.save({\n",
    "    \"model_state_dict\": finalModel.state_dict(),\n",
    "    \"wordtoindex\": wordtoindex,\n",
    "    \"indextoword\": indextoword,\n",
    "    \"padIndex\": padIndex,\n",
    "    \"max_sequence_length\": MAX_SEQUENCE_LENGTH\n",
    "}, \"savedModel/ffnn_emotion_classifier_optuna.pth\")\n",
    "print(\"Saved final model + vocab to savedModel/ffnn_emotion_classifier_optuna.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
