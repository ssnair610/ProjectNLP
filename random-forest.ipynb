{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca2025a",
   "metadata": {},
   "source": [
    "# Random Forest - Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cf4234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tushar/_main/uni/sem-3/nlp/Project/ProjectNLP/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import optuna\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74225cf",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"Data\", \"track-a.csv\")\n",
    "dataframe = pd.read_csv(file_path)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb59e57",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830e598",
   "metadata": {},
   "source": [
    "### Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d347afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "dataframe['text'] = dataframe['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd43d6",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "# TODO: Lot of punctuations (remove)\n",
    "\n",
    "def lemmatize_text(txt):\n",
    "    out = \"\"\n",
    "    for word in word_tokenizer.tokenize(txt):\n",
    "        out = out + lemmatizer.lemmatize(word) + \" \"\n",
    "    return out\n",
    "\n",
    "dataframe[\"text\"] = dataframe.text.apply(lemmatize_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6728b7b",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12150869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "X_texts = dataframe['text']\n",
    "vectorizer = CountVectorizer()\n",
    "X_texts_vec = vectorizer.fit_transform(X_texts)\n",
    "\n",
    "\n",
    "emotions = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "Y_emotions = dataframe[emotions]\n",
    "\n",
    "\n",
    "X_train_text, X_test_text, Y_train_labels, Y_test_labels = train_test_split(X_texts_vec, Y_emotions, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8be120",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23362638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 25, 500, step = 25)\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 64, step = 2)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "    random_state = trial.suggest_int(\"random_state\", 0, 100, step = 20)\n",
    "    warm_start = trial.suggest_categorical(\"warm_state\", [False, True])\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators = n_estimators, \n",
    "                                   criterion = criterion, \n",
    "                                   max_depth = max_depth, \n",
    "                                   max_features = max_features, \n",
    "                                   random_state = random_state, \n",
    "                                   warm_start = warm_start)\n",
    "\n",
    "    model.fit(X_train_text,Y_train_labels)\n",
    "\n",
    "    yPred = model.predict(X_test_text)\n",
    "    \n",
    "    f1score = f1_score(Y_test_labels, yPred, average = \"samples\", zero_division = 0)\n",
    "    \n",
    "    bestf1score = float(0.0)\n",
    "\n",
    "    if f1score > bestf1score: #type: ignore\n",
    "        bestf1score = f1score\n",
    "\n",
    "    return bestf1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b926ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyRFC = optuna.create_study(study_name = \"RFC\", direction = \"maximize\", sampler = optuna.samplers.TPESampler(seed = 42), storage = \"sqlite:///db.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2138e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.delete_study(study_name=\"RFC\", storage = \"sqlite:///db.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _objective(trial):\n",
    "    return objective(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyRFC.optimize(_objective, n_trials = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOptuna Best Trial:\")\n",
    "best = studyRFC.best_trial\n",
    "print(f\"Validation Loss: {best.value:.4f}\")\n",
    "for key, val in best.params.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "best_n_estimators = best.params[\"n_estimators\"]\n",
    "best_criterion = best.params[\"criterion\"]\n",
    "best_max_depth = best.params[\"max_depth\"]\n",
    "best_max_features = best.params[\"max_features\"]\n",
    "best_random_state = best.params[\"random_state\"]\n",
    "best_warm_start = best.params[\"warm_start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd594af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = RandomForestClassifier(n_estimators = best_n_estimators,\n",
    "                                    criterion = best_criterion,\n",
    "                                    max_depth = best_max_depth,\n",
    "                                    max_features = best_max_features,\n",
    "                                    random_state = best_random_state, \n",
    "                                    warm_start = best_warm_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987999a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(finalModel, \"savedModel/rfcmodel.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators = 10, max_features = 4, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ca57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train_text,Y_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3153ac",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27162e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = multilabel_confusion_matrix(Y_test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tp, tn, fp, fn):\n",
    "    return (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "\n",
    "def precision(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(tp,fp,fn):\n",
    "    precision_val = precision(tp,fp)\n",
    "    recall_val = recall(tp,fn)\n",
    "    return 2 * (precision_val * recall_val) / (precision_val + recall_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(title, accuracy, precision, recall, f1_score):\n",
    "    print(f\"{title}\\n\")\n",
    "    print(f\"accuracy: {round(accuracy,2)}\")\n",
    "    print(f\"precision: {round(precision,2)}\")\n",
    "    print(f\"recall: {round(recall,2)}\")\n",
    "    print(f\"f1 Score: {round(f1_score,2)}\")\n",
    "    print(\"=======\\n\")\n",
    "\n",
    "\n",
    "def present_data(log_level):\n",
    "    total_accuracy = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "\n",
    "    for i in range(0, len(confusion_mat)):\n",
    "        tp, fp = confusion_mat[i][0]\n",
    "        fn, tn = confusion_mat[i][1]\n",
    "\n",
    "        accuracy_val = accuracy(tp, tn, fp, fn)\n",
    "        precision_val = precision(tp, fp)\n",
    "        recall_val = recall(tp, fn)\n",
    "        f1_score_val = f1_score(tp, fp, fn)\n",
    "\n",
    "        total_accuracy += accuracy_val\n",
    "        total_precision += precision_val\n",
    "        total_recall += recall_val\n",
    "        total_f1_score += f1_score_val\n",
    "\n",
    "        if(log_level == \"emotions\"):\n",
    "            print_eval(\n",
    "            f\"Emotion: {emotions[i]}\",\n",
    "                accuracy_val,\n",
    "                precision_val,\n",
    "                recall_val,\n",
    "                f1_score_val,\n",
    "            )\n",
    "\n",
    "    avg_accuracy = total_accuracy / len(confusion_mat)\n",
    "    avg_precision = total_precision / len(confusion_mat)\n",
    "    avg_recall = total_recall / len(confusion_mat)\n",
    "    avg_f1_score = total_f1_score / len(confusion_mat)\n",
    "\n",
    "    if(log_level==\"macro\"):\n",
    "        print_eval(\"Macro Average:\", avg_accuracy, avg_precision, avg_recall, avg_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_data(\"emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca845a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_data(\"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
