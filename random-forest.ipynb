{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca2025a",
   "metadata": {},
   "source": [
    "# Random Forest - Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3cf4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74225cf",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"Data\", \"track-a.csv\")\n",
    "dataframe = pd.read_csv(file_path)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb59e57",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830e598",
   "metadata": {},
   "source": [
    "### Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d347afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "dataframe['text'] = dataframe['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd43d6",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "# TODO: Lot of punctuations (remove)\n",
    "\n",
    "def lemmatize_text(txt):\n",
    "    out = \"\"\n",
    "    for word in word_tokenizer.tokenize(txt):\n",
    "        out = out + lemmatizer.lemmatize(word) + \" \"\n",
    "    return out\n",
    "\n",
    "dataframe[\"text\"] = dataframe.text.apply(lemmatize_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6728b7b",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12150869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "X_texts = dataframe['text']\n",
    "vectorizer = CountVectorizer()\n",
    "X_texts_vec = vectorizer.fit_transform(X_texts)\n",
    "\n",
    "\n",
    "emotions = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "Y_emotions = dataframe[emotions]\n",
    "\n",
    "\n",
    "X_train_text, X_test_text, Y_train_labels, Y_test_labels = train_test_split(X_texts_vec, Y_emotions, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8be120",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23362638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 500, step = 10)\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 64, step = 2)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "    random_state = trial.suggest_int(\"random_state\", 0, 1000, step = 20)\n",
    "    warm_start = trial.suggest_categorical(\"warm_state\", [False, True])\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators = n_estimators, \n",
    "                                   criterion = criterion, \n",
    "                                   max_depth = max_depth, \n",
    "                                   max_features = max_features, \n",
    "                                   random_state = random_state, \n",
    "                                   warm_start = warm_start)\n",
    "\n",
    "    model.fit(X_train_text,Y_train_labels)\n",
    "\n",
    "    yPred = model.predict(X_test_text)\n",
    "    \n",
    "    f1score = f1_score(Y_test_labels, yPred, average = \"samples\", zero_division = 0)\n",
    "    \n",
    "    bestf1score = float(\"inf\")\n",
    "\n",
    "    if f1score < bestf1score: #type: ignore\n",
    "        bestf1score = f1score\n",
    "\n",
    "    return bestf1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b926ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyRFC = optuna.create_study(study_name = \"RFC\", direction = \"minimize\", sampler = optuna.samplers.TPESampler(seed = 42), storage = \"sqlite:///db.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138e326",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Record does not exist.'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43moptuna\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdelete_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRFC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msqlite:///db.sqlite3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\_convert_positional_args.py:134\u001b[39m, in \u001b[36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    129\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m     )\n\u001b[32m    132\u001b[39m kwargs.update(inferred_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:1445\u001b[39m, in \u001b[36mdelete_study\u001b[39m\u001b[34m(study_name, storage)\u001b[39m\n\u001b[32m   1402\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Delete a :class:`~optuna.study.Study` object.\u001b[39;00m\n\u001b[32m   1403\u001b[39m \n\u001b[32m   1404\u001b[39m \u001b[33;03mExample:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1441\u001b[39m \n\u001b[32m   1442\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1444\u001b[39m storage = storages.get_storage(storage)\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m study_id = \u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_study_id_from_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m storage.delete_study(study_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py:107\u001b[39m, in \u001b[36m_CachedStorage.get_study_id_from_name\u001b[39m\u001b[34m(self, study_name)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_study_id_from_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, study_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_study_id_from_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:331\u001b[39m, in \u001b[36mRDBStorage.get_study_id_from_name\u001b[39m\u001b[34m(self, study_name)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_study_id_from_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, study_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _create_scoped_session(\u001b[38;5;28mself\u001b[39m.scoped_session) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         study = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStudyModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_or_raise_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m         study_id = study.study_id\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m study_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\storages\\_rdb\\models.py:87\u001b[39m, in \u001b[36mStudyModel.find_or_raise_by_name\u001b[39m\u001b[34m(cls, study_name, session)\u001b[39m\n\u001b[32m     85\u001b[39m study = \u001b[38;5;28mcls\u001b[39m.find_by_name(study_name, session)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m study \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(NOT_FOUND_MSG)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "\u001b[31mKeyError\u001b[39m: 'Record does not exist.'"
     ]
    }
   ],
   "source": [
    "# optuna.delete_study(study_name=\"RFC\", storage = \"sqlite:///db.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _objective(trial):\n",
    "    return objective(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyRFC.optimize(_objective, n_trials = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOptuna Best Trial:\")\n",
    "best = studyRFC.best_trial\n",
    "print(f\"Validation Loss: {best.value:.4f}\")\n",
    "for key, val in best.params.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "n_estimators = best.params[\"n_estimators\"]\n",
    "criterion = best.params[\"criterion\"]\n",
    "max_depth = best.params[\"max_depth\"]\n",
    "max_features = best.params[\"max_features\"]\n",
    "random_state = best.params[\"random_state\"]\n",
    "warm_start = best.params[\"warm_start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd594af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators = 10, max_features = 4, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ca57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train_text,Y_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3153ac",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27162e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = multilabel_confusion_matrix(Y_test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tp, tn, fp, fn):\n",
    "    return (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "\n",
    "def precision(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(tp,fp,fn):\n",
    "    precision_val = precision(tp,fp)\n",
    "    recall_val = recall(tp,fn)\n",
    "    return 2 * (precision_val * recall_val) / (precision_val + recall_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(title, accuracy, precision, recall, f1_score):\n",
    "    print(f\"{title}\\n\")\n",
    "    print(f\"accuracy: {round(accuracy,2)}\")\n",
    "    print(f\"precision: {round(precision,2)}\")\n",
    "    print(f\"recall: {round(recall,2)}\")\n",
    "    print(f\"f1 Score: {round(f1_score,2)}\")\n",
    "    print(\"=======\\n\")\n",
    "\n",
    "\n",
    "def present_data(log_level):\n",
    "    total_accuracy = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "\n",
    "    for i in range(0, len(confusion_mat)):\n",
    "        tp, fp = confusion_mat[i][0]\n",
    "        fn, tn = confusion_mat[i][1]\n",
    "\n",
    "        accuracy_val = accuracy(tp, tn, fp, fn)\n",
    "        precision_val = precision(tp, fp)\n",
    "        recall_val = recall(tp, fn)\n",
    "        f1_score_val = f1_score(tp, fp, fn)\n",
    "\n",
    "        total_accuracy += accuracy_val\n",
    "        total_precision += precision_val\n",
    "        total_recall += recall_val\n",
    "        total_f1_score += f1_score_val\n",
    "\n",
    "        if(log_level == \"emotions\"):\n",
    "            print_eval(\n",
    "            f\"Emotion: {emotions[i]}\",\n",
    "                accuracy_val,\n",
    "                precision_val,\n",
    "                recall_val,\n",
    "                f1_score_val,\n",
    "            )\n",
    "\n",
    "    avg_accuracy = total_accuracy / len(confusion_mat)\n",
    "    avg_precision = total_precision / len(confusion_mat)\n",
    "    avg_recall = total_recall / len(confusion_mat)\n",
    "    avg_f1_score = total_f1_score / len(confusion_mat)\n",
    "\n",
    "    if(log_level==\"macro\"):\n",
    "        print_eval(\"Macro Average:\", avg_accuracy, avg_precision, avg_recall, avg_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_data(\"emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca845a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_data(\"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
