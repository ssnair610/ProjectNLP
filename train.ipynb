{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1ff056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb3b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"Data\\\\track-a.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe28511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34521e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpModel = spacy.load(\"en_core_web_sm\", disable=[\"parser\",\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75bc303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanerFunction(text):\n",
    "    tempDoc = nlpModel(text)\n",
    "    token = [\n",
    "        tok.lemma_.lower()\n",
    "        for tok in tempDoc\n",
    "        if not tok.is_stop and not tok.is_punct and tok.lemma_ != \"-PRON-\"\n",
    "    ]\n",
    "    return \" \".join(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f22031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Spacy_text\"] = dataFrame[\"text\"].astype(str).apply(cleanerFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb565f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelColumns = [col for col in [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"] if col in dataFrame]\n",
    "y = dataFrame[labelColumns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0572efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b9a7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(dataFrame[\"Spacy_text\"], y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b31ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfModel = TfidfVectorizer(max_features = 5000, ngram_range = (1, 2))\n",
    "Xtr = tfidfModel.fit_transform(xTrain)\n",
    "Xv = tfidfModel.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f0fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orClassifier = OneVsRestClassifier(LogisticRegression(max_iter = 1500))\n",
    "orClassifier.fit(Xtr, yTrain)\n",
    "yPred = orClassifier.predict(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9637e15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        34\n",
      "        fear       0.67      0.85      0.75       168\n",
      "         joy       1.00      0.12      0.22        48\n",
      "     sadness       0.74      0.17      0.27        84\n",
      "    surprise       0.79      0.13      0.23        83\n",
      "\n",
      "   micro avg       0.69      0.41      0.52       417\n",
      "   macro avg       0.64      0.25      0.29       417\n",
      "weighted avg       0.69      0.41      0.43       417\n",
      " samples avg       0.55      0.40      0.44       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest, yPred, target_names = labelColumns, zero_division = 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1f17ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import optuna\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn.functional import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "903283ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "textTrain, textValue, labelTrain, labelValue = train_test_split(dataFrame[\"Spacy_text\"], y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97148e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "textTrain = textTrain.reset_index(drop = True)\n",
    "textValue = textValue.reset_index(drop = True)\n",
    "\n",
    "textValue = textValue.tolist()\n",
    "textTrain = textTrain.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eca4b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "251ebef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentDetect(Dataset):\n",
    "    def __init__(self, text, label, token, maxLength = 128):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.token = token\n",
    "        self.maxLength = maxLength\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        textchanged = self.text.iloc[i]\n",
    "\n",
    "        enc = self.token(\n",
    "            textchanged, max_length = self.maxLength, truncation = True, padding = \"max_length\", return_tensors = \"pt\"\n",
    "        )\n",
    "        chosenItem = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        chosenItem[\"label\"] = torch.FloatTensor(self.label[i])\n",
    "        return chosenItem\n",
    "    \n",
    "trainSD = sentDetect(xTrain, yTrain, tokenizer)\n",
    "testSD = sentDetect(xTest, yTest, tokenizer)\n",
    "trainDL = DataLoader(trainSD, batch_size = 16, shuffle = True)\n",
    "testDL = DataLoader(testSD, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8d276d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "userDevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22008d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tensorModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    problem_type = \"multi_label_classification\",\n",
    "    num_labels = len(labelColumns)\n",
    ").to(userDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bdf520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.BCEWithLogitsLoss()\n",
    "\n",
    "steps = len(trainDL) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ab2389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optPara = AdamW(tensorModel.parameters(), lr = 1e-5, weight_decay = 0.01)\n",
    "# optPara1 = AdamW(tensorModel.parameters(), lr = 3e-5, weight_decay = 0.01)\n",
    "# optPara2 = AdamW(tensorModel.parameters(), lr = 5e-5, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a11b01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup_steps = int(0.1 * steps)\n",
    "# warmup_steps1 = int(0.3 * steps)\n",
    "# warmup_steps2 = int(0.5 * steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efefd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedule = get_linear_schedule_with_warmup(optPara, warmup_steps, steps)\n",
    "# schedule1 = get_linear_schedule_with_warmup(optPara1, warmup_steps1, steps)\n",
    "# schedule2 = get_linear_schedule_with_warmup(optPara2, warmup_steps2, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5a8f2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.clip_grad_norm_(tensorModel.parameters(), max_norm = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39ae542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def epochTrain(oPara, selectSch):\n",
    "#     tensorModel.train()\n",
    "#     total = 0\n",
    "#     for batch in trainDL:\n",
    "#         oPara.zero_grad()\n",
    "#         id = batch[\"input_ids\"].to(userDevice)\n",
    "#         mask = batch[\"attention_mask\"].to(userDevice)\n",
    "#         labs = batch[\"label\"].to(userDevice)\n",
    "#         outs = tensorModel(id, attention_mask = mask).logits\n",
    "#         loss = lossFunction(outs, labs)\n",
    "#         loss.backward()\n",
    "#         oPara.step()\n",
    "#         selectSch.step()\n",
    "#         total += loss.item()\n",
    "    \n",
    "#     return total / len(trainDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85e7a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def epochEvaluate():\n",
    "#     tensorModel.eval()\n",
    "#     total = 0\n",
    "#     logits = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch in testDL:\n",
    "#             id = batch[\"input_ids\"].to(userDevice)\n",
    "#             mask = batch[\"attention_mask\"].to(userDevice)\n",
    "#             labs = batch[\"label\"].to(userDevice)\n",
    "#             outs = tensorModel(id, attention_mask = mask).logits\n",
    "#             total += lossFunction(outs, labs).item()\n",
    "#             logits.append(outs.cpu().numpy())\n",
    "#     return total / len(testDL), numpy.vstack(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "291bc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochTrain(optimizer, scheduler, use_amp = False):\n",
    "    tensorModel.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in trainDL:\n",
    "        tensorModel.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in trainDL:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[\"input_ids\"].to(userDevice)\n",
    "            attention_mask = batch[\"attention_mask\"].to(userDevice)\n",
    "            labels = batch[\"label\"].to(userDevice)\n",
    "\n",
    "            with autocast(userDevice.type):\n",
    "                logits = tensorModel(input_ids, attention_mask=attention_mask).logits\n",
    "                loss   = lossFunction(logits, labels)\n",
    "\n",
    "            GradScaler.scale(loss).backward()\n",
    "            GradScaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(tensorModel.parameters(), max_norm = 1.0)\n",
    "\n",
    "            GradScaler.step(optimizer)\n",
    "            GradScaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(trainDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f979090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochEvaluate():\n",
    "    tensorModel.eval()\n",
    "    total_loss = 0.0\n",
    "    all_logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in testDL:\n",
    "            input_ids = batch[\"input_ids\"].to(userDevice)\n",
    "            attention_mask = batch[\"attention_mask\"].to(userDevice)\n",
    "            labels = batch[\"label\"].to(userDevice)\n",
    "\n",
    "            outputs = tensorModel(input_ids, attention_mask = attention_mask)\n",
    "            logits  = outputs.logits\n",
    "\n",
    "            total_loss += lossFunction(logits, labels).item()\n",
    "\n",
    "            all_logits.append(logits.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(testDL)\n",
    "    all_logits = numpy.vstack(all_logits)\n",
    "\n",
    "    return avg_loss, all_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0087fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Combination 1:\\n\")\n",
    "# for e in range(5):\n",
    "#     start_time = time.time()\n",
    "#     tl = epochTrain(optPara, schedule)\n",
    "#     vl, lg = epochEvaluate()\n",
    "#     end_time = time.time() - start_time\n",
    "#     print(f\"Epoch: {e + 1}: train_loss = {tl : .4f}, value_loss = {vl : .4f}, time_taken = {end_time : .4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "607b4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Combination 2:\\n\")\n",
    "# for e in range(5):\n",
    "#     start_time = time.time()\n",
    "#     tl = epochTrain(optPara1, schedule1)\n",
    "#     vl, lg = epochEvaluate()\n",
    "#     end_time = time.time() - start_time\n",
    "#     print(f\"Epoch: {e + 1}: train_loss = {tl : .4f}, value_loss = {vl : .4f}, time_taken = {end_time : .4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bbaf023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Combination 3:\\n\")\n",
    "# for e in range(5):\n",
    "#     start_time = time.time()\n",
    "#     tl = epochTrain(optPara2, schedule2)\n",
    "#     vl, lg = epochEvaluate()\n",
    "#     end_time = time.time() - start_time\n",
    "#     print(f\"Epoch: {e + 1}: train_loss = {tl : .4f}, value_loss = {vl : .4f}, time_taken = {end_time : .4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61a8d5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 17:17:08,706] A new study created in memory with name: no-name-157e8dbb-7b0e-4d31-841a-08d4f80b12e0\n",
      "C:\\Users\\sshre\\AppData\\Local\\Temp\\ipykernel_4044\\2907694361.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learnRate = trial.suggest_loguniform(\"lr\", 5e-6, 1e-5)\n",
      "C:\\Users\\sshre\\AppData\\Local\\Temp\\ipykernel_4044\\2907694361.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weightDecay = trial.suggest_loguniform(\"wd\", 1e-4, 1e-1)\n",
      "C:\\Users\\sshre\\AppData\\Local\\Temp\\ipykernel_4044\\2907694361.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  warmup_steps = trial.suggest_loguniform(\"wup\", (0.1 * steps), (0.5 * steps))\n",
      "[W 2025-05-23 17:17:08,724] Trial 0 failed with parameters: {'lr': 7.4885917921086435e-06, 'wd': 0.0014306173787849757, 'wup': 68.68924922140474} because of the following error: TypeError(\"autocast.__init__() missing 1 required positional argument: 'device_type'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshre\\AppData\\Local\\Temp\\ipykernel_4044\\2907694361.py\", line 13, in objective\n",
      "    tl = epochTrain(optimizer, scheduler, True)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshre\\AppData\\Local\\Temp\\ipykernel_4044\\2912083821.py\", line 15, in epochTrain\n",
      "    with autocast():\n",
      "         ^^^^^^^^^^\n",
      "TypeError: autocast.__init__() missing 1 required positional argument: 'device_type'\n",
      "[W 2025-05-23 17:17:08,725] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "autocast.__init__() missing 1 required positional argument: 'device_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: train_loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtl\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m .4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, value_loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvl\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m .4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, time_taken = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m .4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m study = optuna.create_study(direction = \u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest Parameters:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m     12\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     tl = \u001b[43mepochTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     vl, lg = epochEvaluate()\n\u001b[32m     15\u001b[39m     end_time = time.time() - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mepochTrain\u001b[39m\u001b[34m(optimizer, scheduler, use_amp)\u001b[39m\n\u001b[32m     12\u001b[39m attention_mask = batch[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m].to(userDevice)\n\u001b[32m     13\u001b[39m labels = batch[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m].to(userDevice)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     16\u001b[39m     logits = tensorModel(input_ids, attention_mask=attention_mask).logits\n\u001b[32m     17\u001b[39m     loss   = lossFunction(logits, labels)\n",
      "\u001b[31mTypeError\u001b[39m: autocast.__init__() missing 1 required positional argument: 'device_type'"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "\n",
    "def objective(trial):\n",
    "    learnRate = trial.suggest_loguniform(\"lr\", 5e-6, 1e-5)\n",
    "    weightDecay = trial.suggest_loguniform(\"wd\", 1e-4, 1e-1)\n",
    "    warmup_steps = trial.suggest_loguniform(\"wup\", (0.1 * steps), (0.5 * steps))\n",
    "    optimizer = AdamW(tensorModel.parameters(), lr = learnRate, weight_decay = weightDecay)\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps, num_training_steps = steps)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        start_time = time.time()\n",
    "        tl = epochTrain(optimizer, scheduler, True)\n",
    "        vl, lg = epochEvaluate()\n",
    "        end_time = time.time() - start_time\n",
    "        print(f\"Epoch: {epoch + 1}: train_loss = {tl : .4f}, value_loss = {vl : .4f}, time_taken = {end_time : .4f} seconds\")\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 20)\n",
    "print(\"Best Parameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69661bff",
   "metadata": {},
   "source": [
    "# Below model performs worse than the one above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65affeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalerFunction = GradScaler()\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     start_time = time.time()\n",
    "#     tensorModel.train()\n",
    "#     total_loss = 0.0\n",
    "\n",
    "#     for batch in trainDL:\n",
    "#         inputids = batch[\"input_ids\"].to(userDevice)\n",
    "#         masks = batch[\"attention_mask\"].to(userDevice)\n",
    "#         labels = batch[\"label\"].to(userDevice)\n",
    "\n",
    "#         optPara.zero_grad()\n",
    "\n",
    "#         with autocast(device_type = \"cuda\"):\n",
    "#             logits = tensorModel(inputids, attention_mask = masks).logits\n",
    "#             loss = lossFunction(logits, labels)\n",
    "\n",
    "#         scalerFunction.scale(loss).backward()\n",
    "\n",
    "#         scalerFunction.unscale_(optPara)\n",
    "#         torch.nn.utils.clip_grad_norm_(tensorModel.parameters(), max_norm = 1.0)\n",
    "\n",
    "#         scalerFunction.step(optPara)\n",
    "#         scalerFunction.update()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     averageLoss = total_loss / len(trainDL)\n",
    "#     end_time = time.time() - start_time\n",
    "#     print(f\"Epoch {epoch + 1} ; train_loss: {averageLoss : .4f} ; time_taken: {end_time : .4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
