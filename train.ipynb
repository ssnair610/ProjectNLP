{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d1ff056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9bb3b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"Data\\\\track-a.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe28511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34521e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m nlpModel = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men_core_web_sm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mner\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     28\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     29\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     35\u001b[39m ) -> Language:\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\util.py:465\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name.replace(\u001b[33m\"\u001b[39m\u001b[33mblank:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))()\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Path(name).exists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), **kwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\util.py:501\u001b[39m, in \u001b[36mload_model_from_package\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[32m    485\u001b[39m \n\u001b[32m    486\u001b[39m \u001b[33;03mname (str): The package name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    498\u001b[39m \u001b[33;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    500\u001b[39m \u001b[38;5;28mcls\u001b[39m = importlib.import_module(name)\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\en_core_web_sm\\__init__.py:10\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(**overrides)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(**overrides):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\util.py:682\u001b[39m, in \u001b[36mload_model_from_init_py\u001b[39m\u001b[34m(init_file, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path.exists():\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E052.format(path=data_path))\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\util.py:547\u001b[39m, in \u001b[36mload_model_from_path\u001b[39m\u001b[34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    538\u001b[39m config = load_config(config_path, overrides=overrides)\n\u001b[32m    539\u001b[39m nlp = load_model_from_config(\n\u001b[32m    540\u001b[39m     config,\n\u001b[32m    541\u001b[39m     vocab=vocab,\n\u001b[32m   (...)\u001b[39m\u001b[32m    545\u001b[39m     meta=meta,\n\u001b[32m    546\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\language.py:2246\u001b[39m, in \u001b[36mLanguage.from_disk\u001b[39m\u001b[34m(self, path, exclude, overrides)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (path / \u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m).exists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m   2244\u001b[39m     \u001b[38;5;66;03m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[32m   2245\u001b[39m     exclude = \u001b[38;5;28mlist\u001b[39m(exclude) + [\u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m2246\u001b[39m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeserializers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   2247\u001b[39m \u001b[38;5;28mself\u001b[39m._path = path  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   2248\u001b[39m \u001b[38;5;28mself\u001b[39m._link_components()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\util.py:1390\u001b[39m, in \u001b[36mfrom_disk\u001b[39m\u001b[34m(path, readers, exclude)\u001b[39m\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers.items():\n\u001b[32m   1388\u001b[39m     \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m         \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\language.py:2222\u001b[39m, in \u001b[36mLanguage.from_disk.<locals>.deserialize_vocab\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m   2220\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeserialize_vocab\u001b[39m(path: Path) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m path.exists():\n\u001b[32m-> \u001b[39m\u001b[32m2222\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\vocab.pyx:550\u001b[39m, in \u001b[36mspacy.vocab.Vocab.from_disk\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\spacy\\strings.pyx:339\u001b[39m, in \u001b[36mspacy.strings.StringStore.from_disk\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\Uni Marburg\\ProjectNLP\\.venv\\Lib\\site-packages\\srsly\\_json_api.py:52\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ujson.loads(data)\n\u001b[32m     51\u001b[39m file_path = force_path(path)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mujson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "nlpModel = spacy.load(\"en_core_web_sm\", disable=[\"parser\",\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanerFunction(text):\n",
    "    tempDoc = nlpModel(text)\n",
    "    token = [\n",
    "        tok.lemma_.lower()\n",
    "        for tok in tempDoc\n",
    "        if not tok.is_stop and not tok.is_punct and tok.lemma_ != \"-PRON-\"\n",
    "    ]\n",
    "    return \" \".join(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Spacy_text\"] = dataFrame[\"text\"].astype(str).apply(cleanerFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb565f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelColumns = [col for col in [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"] if col in dataFrame]\n",
    "y = dataFrame[labelColumns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(dataFrame[\"Spacy_text\"], y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfModel = TfidfVectorizer(max_features = 5000, ngram_range = (1, 2))\n",
    "Xtr = tfidfModel.fit_transform(xTrain)\n",
    "Xv = tfidfModel.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orClassifier = OneVsRestClassifier(LogisticRegression(max_iter = 1500))\n",
    "orClassifier.fit(Xtr, yTrain)\n",
    "yPred = orClassifier.predict(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(yTest, yPred, target_names = labelColumns, zero_division = 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f17ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903283ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "textTrain, textValue, labelTrain, labelValue = train_test_split(dataFrame[\"Spacy_text\"], y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97148e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "textTrain = textTrain.reset_index(drop = True)\n",
    "textValue = textValue.reset_index(drop = True)\n",
    "\n",
    "textValue = textValue.tolist()\n",
    "textTrain = textTrain.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ebef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentDetect(Dataset):\n",
    "    def __init__(self, text, label, token, maxLength = 128):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.token = token\n",
    "        self.maxLength = maxLength\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        textchanged = self.text.iloc[i]\n",
    "\n",
    "        enc = self.token(\n",
    "            textchanged, max_length = self.maxLength, truncation = True, padding = \"max_length\", return_tensors = \"pt\"\n",
    "        )\n",
    "        chosenItem = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        chosenItem[\"label\"] = torch.FloatTensor(self.label[i])\n",
    "        return chosenItem\n",
    "    \n",
    "trainSD = sentDetect(xTrain, yTrain, tokenizer)\n",
    "testSD = sentDetect(xTest, yTest, tokenizer)\n",
    "trainDL = DataLoader(trainSD, batch_size = 16, shuffle = True)\n",
    "testDL = DataLoader(testSD, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d276d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "userDevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22008d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    problem_type = \"multi_label_classification\",\n",
    "    num_labels = len(labelColumns)\n",
    ").to(userDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.BCEWithLogitsLoss()\n",
    "\n",
    "steps = len(trainDL) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optPara = AdamW(tensorModel.parameters(), lr = 1e-5, weight_decay = 0.01)\n",
    "optPara1 = AdamW(tensorModel.parameters(), lr = 2e-5, weight_decay = 0.01)\n",
    "optPara2 = AdamW(tensorModel.parameters(), lr = 5e-5, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = int(0.1 * steps)\n",
    "warmup_steps1 = int(0.3 * steps)\n",
    "warmup_steps2 = int(0.5 * steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = get_linear_schedule_with_warmup(optPara, warmup_steps, steps)\n",
    "schedule1 = get_linear_schedule_with_warmup(optPara1, warmup_steps1, steps)\n",
    "schedule2 = get_linear_schedule_with_warmup(optPara2, warmup_steps2, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.clip_grad_norm_(tensorModel.parameters(), max_norm = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochTrain(oPara, selectSch):\n",
    "    tensorModel.train()\n",
    "    total = 0\n",
    "    for batch in trainDL:\n",
    "        oPara.zero_grad()\n",
    "        id = batch[\"input_ids\"].to(userDevice)\n",
    "        mask = batch[\"attention_mask\"].to(userDevice)\n",
    "        labs = batch[\"label\"].to(userDevice)\n",
    "        outs = tensorModel(id, attention_mask = mask).logits\n",
    "        loss = lossFunction(outs, labs)\n",
    "        loss.backward()\n",
    "        oPara.step()\n",
    "        selectSch.step()\n",
    "        total += loss.item()\n",
    "    \n",
    "    return total / len(trainDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f979090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochEvaluate():\n",
    "    tensorModel.eval()\n",
    "    total = 0\n",
    "    logits = []\n",
    "    with torch.no_grad():\n",
    "        for batch in testDL:\n",
    "            id = batch[\"input_ids\"].to(userDevice)\n",
    "            mask = batch[\"attention_mask\"].to(userDevice)\n",
    "            labs = batch[\"label\"].to(userDevice)\n",
    "            outs = tensorModel(id, attention_mask = mask).logits\n",
    "            total += lossFunction(outs, labs).item()\n",
    "            logits.append(outs.cpu().numpy())\n",
    "    return total / len(testDL), numpy.vstack(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0087fbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m      3\u001b[39m     start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     tl = \u001b[43mepochTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptPara\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     vl, lg = epochEvaluate()\n\u001b[32m      6\u001b[39m     end_time = time.time() - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mepochTrain\u001b[39m\u001b[34m(oPara, selectSch)\u001b[39m\n\u001b[32m     12\u001b[39m     oPara.step()\n\u001b[32m     13\u001b[39m     selectSch.step()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     total += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total / \u001b[38;5;28mlen\u001b[39m(trainDL)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"Combination 1:\\n\")\n",
    "for e in range(5):\n",
    "    start_time = time.time()\n",
    "    tl = epochTrain(optPara, schedule)\n",
    "    vl, lg = epochEvaluate()\n",
    "    end_time = time.time() - start_time\n",
    "    print(f\"Epoch: {e + 1}: train_loss = {tl : .4f}, value_loss = {vl : .4f}, time_taken = {end_time : .4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Combination 2:\\n\")\n",
    "for e in range(5):\n",
    "    start_time = time.time()\n",
    "    tl = epochTrain(optPara1, schedule1)\n",
    "    vl, lg = epochEvaluate()\n",
    "    end_time = time.time() - start_time\n",
    "    print(f\"Epoch: {e + 1}: train_loss = {tl : .4f}, value_loss = {vl : .4f}, time_taken = {end_time : .4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbaf023",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Combination 3:\\n\")\n",
    "for e in range(5):\n",
    "    start_time = time.time()\n",
    "    tl = epochTrain(optPara2, schedule2)\n",
    "    vl, lg = epochEvaluate()\n",
    "    end_time = time.time() - start_time\n",
    "    print(f\"Epoch: {e + 1}: train_loss = {tl : .4f}, value_loss = {vl : .4f}, time_taken = {end_time : .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69661bff",
   "metadata": {},
   "source": [
    "# Below model performs worse than the one above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65affeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalerFunction = GradScaler()\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     start_time = time.time()\n",
    "#     tensorModel.train()\n",
    "#     total_loss = 0.0\n",
    "\n",
    "#     for batch in trainDL:\n",
    "#         inputids = batch[\"input_ids\"].to(userDevice)\n",
    "#         masks = batch[\"attention_mask\"].to(userDevice)\n",
    "#         labels = batch[\"label\"].to(userDevice)\n",
    "\n",
    "#         optPara.zero_grad()\n",
    "\n",
    "#         with autocast(device_type = \"cuda\"):\n",
    "#             logits = tensorModel(inputids, attention_mask = masks).logits\n",
    "#             loss = lossFunction(logits, labels)\n",
    "\n",
    "#         scalerFunction.scale(loss).backward()\n",
    "\n",
    "#         scalerFunction.unscale_(optPara)\n",
    "#         torch.nn.utils.clip_grad_norm_(tensorModel.parameters(), max_norm = 1.0)\n",
    "\n",
    "#         scalerFunction.step(optPara)\n",
    "#         scalerFunction.update()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     averageLoss = total_loss / len(trainDL)\n",
    "#     end_time = time.time() - start_time\n",
    "#     print(f\"Epoch {epoch + 1} ; train_loss: {averageLoss : .4f} ; time_taken: {end_time : .4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
